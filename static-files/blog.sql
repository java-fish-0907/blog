/*
 Navicat Premium Data Transfer

 Source Server         : 测试服
 Source Server Type    : MySQL
 Source Server Version : 80022
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 80022
 File Encoding         : 65001

 Date: 30/09/2021 16:42:27
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for generator_test
-- ----------------------------
DROP TABLE IF EXISTS `generator_test`;
CREATE TABLE `generator_test` (
  `id` bigint NOT NULL AUTO_INCREMENT COMMENT 'id',
  `test` varchar(100) NOT NULL COMMENT '测试字段',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Table structure for jdbc_test
-- ----------------------------
DROP TABLE IF EXISTS `jdbc_test`;
CREATE TABLE `jdbc_test` (
  `type` varchar(100) DEFAULT NULL COMMENT '类型',
  `name` varchar(100) DEFAULT NULL COMMENT '名称'
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of jdbc_test
-- ----------------------------
BEGIN;
INSERT INTO `jdbc_test` VALUES ('com.zaxxer.hikari.HikariDataSource', 'hikari数据源');
INSERT INTO `jdbc_test` VALUES ('org.apache.commons.dbcp2.BasicDataSource', 'dbcp2数据源');
INSERT INTO `jdbc_test` VALUES ('test', '测试类');
INSERT INTO `jdbc_test` VALUES ('类别2', '测试类2');
COMMIT;

-- ----------------------------
-- Table structure for tb_admin_user
-- ----------------------------
DROP TABLE IF EXISTS `tb_admin_user`;
CREATE TABLE `tb_admin_user` (
  `admin_user_id` int NOT NULL AUTO_INCREMENT COMMENT '管理员id',
  `login_user_name` varchar(50) NOT NULL COMMENT '管理员登陆名称',
  `login_password` varchar(50) NOT NULL COMMENT '管理员登陆密码',
  `nick_name` varchar(50) NOT NULL COMMENT '管理员显示昵称',
  `locked` tinyint DEFAULT '0' COMMENT '是否锁定 0未锁定 1已锁定无法登陆',
  PRIMARY KEY (`admin_user_id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_admin_user
-- ----------------------------
BEGIN;
INSERT INTO `tb_admin_user` VALUES (1, 'admin', 'e10adc3949ba59abbe56e057f20f883e', 'Java程序鱼', 0);
COMMIT;

-- ----------------------------
-- Table structure for tb_blog
-- ----------------------------
DROP TABLE IF EXISTS `tb_blog`;
CREATE TABLE `tb_blog` (
  `blog_id` bigint NOT NULL AUTO_INCREMENT COMMENT '博客表主键id',
  `blog_title` varchar(200) NOT NULL COMMENT '博客标题',
  `blog_sub_url` varchar(200) NOT NULL COMMENT '博客自定义路径url',
  `blog_cover_image` varchar(200) NOT NULL COMMENT '博客封面图',
  `blog_content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '博客内容',
  `blog_category_id` int NOT NULL COMMENT '博客分类id',
  `blog_category_name` varchar(50) NOT NULL COMMENT '博客分类(冗余字段)',
  `blog_tags` varchar(200) NOT NULL COMMENT '博客标签',
  `blog_status` tinyint NOT NULL DEFAULT '0' COMMENT '0-草稿 1-发布',
  `blog_views` bigint NOT NULL DEFAULT '0' COMMENT '阅读量',
  `enable_comment` tinyint NOT NULL DEFAULT '0' COMMENT '0-允许评论 1-不允许评论',
  `is_deleted` tinyint NOT NULL DEFAULT '0' COMMENT '是否删除 0=否 1=是',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '添加时间',
  `update_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`blog_id`)
) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_blog
-- ----------------------------
BEGIN;
INSERT INTO `tb_blog` VALUES (1, '我把面试问烂了的⭐MySQL面试题⭐总结了一下（带答案，万字总结，精心打磨，建议收藏）', 'mysql_interview', 'http://localhost:8888/upload/20210929_18144911.png', '个人主页:[Java程序鱼](href=\"https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n\n| 序号 |  内容| 链接地址|\n|--|--|--|\n|  1| [Java基础知识面试题](https://blog.csdn.net/qq_35620342/article/details/119636436) |https://blog.csdn.net/qq_35620342/article/details/119636436|\n|2|[Java集合容器面试题](https://blog.csdn.net/qq_35620342/article/details/119947254)|https://blog.csdn.net/qq_35620342/article/details/119947254|\n|3|[Java并发编程面试题](https://blog.csdn.net/qq_35620342/article/details/119977224)|https://blog.csdn.net/qq_35620342/article/details/119977224|\n|4|[Java异常面试题](https://blog.csdn.net/qq_35620342/article/details/119977051)|https://blog.csdn.net/qq_35620342/article/details/119977051|\n|5|[JVM面试题](https://blog.csdn.net/qq_35620342/article/details/119948989)|https://blog.csdn.net/qq_35620342/article/details/119948989|\n|6|[Java Web面试题](https://blog.csdn.net/qq_35620342/article/details/119642114)|https://blog.csdn.net/qq_35620342/article/details/119642114|\n|7|[Spring面试题](https://blog.csdn.net/qq_35620342/article/details/119956512)|https://blog.csdn.net/qq_35620342/article/details/119956512|\n|8|[Spring MVC面试题](https://blog.csdn.net/qq_35620342/article/details/119965560)|https://blog.csdn.net/qq_35620342/article/details/119965560|\n|9|[Spring Boot面试题](https://blog.csdn.net/qq_35620342/article/details/120333717)|https://blog.csdn.net/qq_35620342/article/details/120333717|\n|10|[MyBatis面试题](https://blog.csdn.net/qq_35620342/article/details/119956541)|https://blog.csdn.net/qq_35620342/article/details/119956541|\n|11|Spring Cloud面试题|待分享|\n|12|[Redis面试题](https://blog.csdn.net/qq_35620342/article/details/119575020)|https://blog.csdn.net/qq_35620342/article/details/119575020|\n|13|[MySQL数据库面试题](https://blog.csdn.net/qq_35620342/article/details/119930887)|https://blog.csdn.net/qq_35620342/article/details/119930887|\n|14|RabbitMQ面试题|待分享|\n|15|Dubbo面试题|待分享|\n|16|Linux面试题|待分享|\n|17|Tomcat面试题|待分享|\n|18|ZooKeeper面试题|待分享|\n|19|Netty面试题|待分享|\n|20|数据结构与算法面试题|待分享|\n\n[MySQL技术体系思维导图](https://www.processon.com/view/link/61298f676376895796300547)\n\n# 1. MySQL 索引使用有哪些注意事项呢？\n可以从两个维度回答这个问题：索引哪些情况会失效，索引不适合哪些场景\n## 索引哪些情况会失效\n* 查询条件包含or，会导致索引失效。\n* 隐式类型转换，会导致索引失效，例如age字段类型是int，我们where age = \"1\"，这样就会触发隐式类型转换。\n* like通配符会导致索引失效。注意：\"ABC%\"会走range索引，\"%ABC\"索引才会失效。\n* 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。\n* 对索引字段进行函数运算。\n* 对索引列运算（如，+、-、*、/），索引失效。\n* 索引字段上使用（!= 或者 < >，not in）时，会导致索引失效。\n* 索引字段上使用is null， is not null，可能导致索引失效。\n* 相join的两个表的字符编码不同，不能命中索引，会导致笛卡尔积的循环计算\n* mysql估计使用全表扫描要比使用索引快,则不使用索引。\n\n## 索引不适合哪些场景\n* 数据量少的不适合加索引\n* 更新比较频繁的也不适合加索引\n* 离散性低的字段不适合加索引（如性别）\n\n# 2. MySQL 遇到过死锁问题吗，你是如何解决的？\n排查死锁的步骤：\n* 查看死锁日志show engine innodb status;\n* 找出死锁Sql\n* 分析sql加锁情况\n* 模拟死锁案发\n* 分析死锁日志\n* 分析死锁结果\n# 3. 日常工作中你是怎么优化SQL的？\n可以从这几个维度回答这个问题：\n* 加索引\n* 避免返回不必要的数据\n* 适当分批量进行\n* 优化sql结构\n* 主从架构，提升读性能\n* 分库分表\n# 4. 分库分表的设计\n分库分表方案，分库分表中间件，分库分表可能遇到的问题\n## 分库分表方案\n* 水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。\n* 水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。\n* 垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。\n* 垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。\n## 常用的分库分表中间件\n* sharding-jdbc\n* Mycat\n## 分库分表可能遇到的问题\n* 事务问题：需要用分布式事务啦\n* 跨节点Join的问题：解决这一问题可以分两次查询实现\n* 跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。\n* 数据迁移，容量规划，扩容等问题\n* ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID\n* 跨分片的排序分页问题（后台加大pagesize处理？）\n# 5. InnoDB与MyISAM的区别\n* InnoDB支持事务，MyISAM不支持事务\n* InnoDB支持外键，MyISAM不支持外键\n* InnoDB 支持 MVCC(多版本并发控制)，MyISAM 不支持\n* select count(*) from table时，MyISAM更快，因为它有一个变量保存了整个表的总行数，可以直接读取，InnoDB就需要全表扫描。\n* Innodb不支持全文索引，而MyISAM支持全文索引（5.7以后的InnoDB也支持全文索引）\n* InnoDB支持表、行级锁，而MyISAM支持表级锁。\n* InnoDB表必须有主键，而MyISAM可以没有主键\n* Innodb表需要更多的内存和存储，而MyISAM可被压缩，存储空间较小，。\n* Innodb按主键大小有序插入，MyISAM记录插入顺序是，按记录插入顺序保存。\n* InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引\n* InnoDB 属于索引组织表，使用共享表空间和多表空间储存数据。MyISAM用.frm、.MYD、.MTI来储存表定义，数据和索引。\n# 6. 数据库索引的原理，为什么要用 B+树，为什么不用二叉树？\n可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？\n## 为什么不是一般二叉树？\n1）当数据量大时，树的高度会比较高（树的高度决定着它的IO操作次数，IO操作耗时大），查询会比较慢。\n2）每个磁盘块（节点/页）保存的数据太小（IO本来是耗时操作，每次IO只能读取到一个关键字，显然不合适），没有很好的利用操作磁盘IO的数据交换特性，也没有利用好磁盘IO的预读能力（空间局部性原理），从而带来频繁的IO操作。\n\n## 为什么不是平衡二叉树呢？\n我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。\n## 那为什么不是B树而是B+树呢？\n1）B+Tree范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯\n2）B+Tree磁盘读写能力更强（叶子节点不保存真实数据，因此一个磁盘块能保存的关键字更多，因此每次加载的关键字越多）\n3）B+Tree扫表和扫库能力更强（B-Tree树需要扫描整颗树，B+Tree树只需要扫描叶子节点）\n\n详细参考：[索引原理](https://blog.csdn.net/qq_35620342/article/details/119797039)\n\n# 7. 聚集索引与非聚集索引的区别\n* 一个表中只能拥有一个聚集索引，而非聚集索引一个表可以存在多个。\n* 聚集索引，索引中键值的逻辑顺序决定了表中相应行的物理顺序；非聚集索引，索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。\n* 索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。\n* 聚集索引：物理存储按照索引排序；非聚集索引：物理存储不按照索引排序；\n## 何时使用聚集索引或非聚集索引？\n![聚集索引](https://img-blog.csdnimg.cn/img_convert/07596c40e8f22b104fd0ce20dd52fa6b.png)\n# 8. limit 1000000 加载很慢的话，你是怎么解决的呢？\n方案一：如果id是连续的，可以这样，返回上次查询的最大记录(偏移量)，再往下limit\n```\nselect id，name from employee where id>1000000 limit 10.\n```\n方案二：在业务允许的情况下限制页数：\n建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。\n\n方案三：order by + 索引（id为索引）\n```\nselect id，name from employee order by id  limit 1000000，10\nSELECT a.* FROM employee a, (select id from employee where 条件 LIMIT 1000000,10 ) b where a.id=b.id\n```\n方案四：利用延迟关联或者子查询优化超多分页场景。（先快速定位需要获取的id段，然后再关联）\n\n# 9. 如何选择合适的分布式主键方案呢？\n* 数据库自增长序列或字段。\n* UUID\n* 雪花算法\n* Redis生成ID\n* 利用zookeeper生成唯一ID\n\n# 10. 事务的隔离级别有哪些？MySQL的默认隔离级别是什么？\n什么是事务的隔离性？ \n\n隔离性是指，多个用户的并发事务访问同一个数据库时，一个用户的事务不应该被其他用户的事务干扰，多个并发事务之间要相互隔离。 \n\n咱们举例子来说明：\n\n建表语句：\n```mysql\nCREATE TABLE `T`  (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE = INNODB;\n```\n数据列表：\n\n| id   | name     |\n| ---- | -------- |\n| 1    | xiaohong |\n| 2    | zhangsan |\n| 3    | lisi     |\n\n案例一：\n\n事务A，先执行，处于未提交的状态： \n\n```mysql\ninsert into T values(4, wangwu); \n```\n\n事务B，后执行，也未提交： \n```mysql\nselect * from T; \n```\n\n如果事务B能够读取到(4, wangwu)这条记录，事务A就对事务B产生了影响，这个影响叫做“读脏”，读到了未提交事务操作的记录。 \n\n案例二：\n\n事务A，先执行： \n```mysql\nselect * from T where id=1; \n```\n结果集为：1, xiaohong \n\n事务B，后执行，并且提交： \n```\nupdate T set name=hzy where id=1; \n```\ncommit; \n\n事务A，再次执行相同的查询： \n```mysql\nselect * from T where id=1; \n```\n\n结果集为：1, hzy \n\n这次是已提交事务B对事务A产生的影响，这个影响叫做“不可重复读”，一个事务内相同的查询，得到了不同的结果。\n\n案例三：\n\n事务A，先执行： \n```mysql\nselect * from T where id>3; \n```\n结果集为： NULL \n\n事务B，后执行，并且提交： \n```mysql\ninsert into T values(4, wangwu); \ncommit; \n```\n\n事务A，首次查询了id>3的结果为NULL，于是想插入一条为4的记录： \n```mysql\ninsert into T values(4, hzy); \n```\n结果集为： Error : duplicate key! \n\n这次是已提交事务B对事务A产生的影响，这个影响叫做“幻读”。 \n\n可以看到，并发的事务可能导致其他事务： \n\n- 读脏 \n\n- 不可重复读 \n\n- 幻读 \n\nInnoDB实现了四种不同事务的隔离级别： \n\n- 读未提交(Read Uncommitted) \n- 读提交(Read Committed, RC) \n- 可重复读(Repeated Read, RR) \n- 串行化(Serializable) \n\n不同事务的隔离级别，实际上是一致性与并发性的一个权衡与折衷。 \n\nInnoDB的四种事务的隔离级别，分别是怎么实现的？ \n\nInnoDB使用不同的锁策略(Locking Strategy)来实现不同的隔离级别。 \n\n## 读未提交(Read Uncommitted) \n这种事务隔离级别下，select语句不加锁。 \n\n此时，可能读取到不一致的数据，即“读脏”。这是并发最高，一致性最差的隔离级别。 \n\n## 串行化(Serializable) \n这种事务的隔离级别下，所有select语句都会被隐式的转化为select ... in share mode. \n\n这可能导致，如果有未提交的事务正在修改某些行，所有读取这些行的select都会被阻塞住。 \n\n这是一致性最好的，但并发性最差的隔离级别。 在互联网大数据量，高并发量的场景下，几乎不会使用上述两种隔离级别。 \n\n## 可重复读(Repeated Read, RR) 这是InnoDB默认的隔离级别，在RR下：\n\n①普通的select使用快照读(snapshot read)，这是一种不加锁的一致性读(Consistent Nonlocking Read)，底层使用MVCC来实现；\n\n②加锁的select(select ... in share mode / select ... for update), update, delete等语句，它们的锁，依赖于它们是否在唯一索引(unique index)上使用了唯一的查询条件(unique search condition)，或者范围查询条件(range-type search condition)： \n\n- 在唯一索引上使用唯一的查询条件，会使用记录锁(record lock)，而不会封锁记录之间的间隔，即不会使用间隙锁(gap lock)与临键锁(next-key lock) \n- 范围查询条件，会使用间隙锁与临键锁，锁住索引记录之间的范围，避免范围间插入记录，以避免产生幻影行记录，以及避免不可重复的读 \n\n## 读提交(Read Committed, RC) 这是互联网最常用的隔离级别，在RC下：\n\n①普通读是快照读； \n\n②加锁的select, update, delete等语句，除了在外键约束检查(foreign-key constraint checking)以及重复键检查(duplicate-key checking)时会封锁区间，其他时刻都只使用记录锁； \n\n此时，其他事务的插入依然可以执行，就可能导致，读取到幻影记录。 \n\n# 11. 在高并发情况下，如何做到安全的修改同一行数据？\n要安全的修改同一行数据，就要保证一个线程在修改时其它线程无法更新这行记录。一般有悲观锁和乐观锁两种方案\n## 使用悲观锁\n悲观锁思想就是，当前线程要进来修改数据时，别的线程都得拒之门外~ 比如，可以使用select…for update\n```\nselect * from User where name=‘jay’ for update\n```\n以上这条sql语句会锁定了User表中所有符合检索条件（name=‘jay’）的记录。本次事务提交之前，别的线程都无法修改这些记录。\n## 使用乐观锁\n乐观锁思想就是，有线程过来，先放过去修改，如果看到别的线程没修改过，就可以修改成功，如果别的线程修改过，就修改失败或者重试。实现方式：乐观锁一般会使用版本号机制或CAS算法实现。\n\n# 12. 数据库的乐观锁和悲观锁\n## 悲观锁\n悲观锁她专一且缺乏安全感了，她的心只属于当前事务，每时每刻都担心着它心爱的数据可能被别的事务修改，所以一个事务拥有（获得）悲观锁后，其他任何事务都不能对数据进行修改啦，只能等待锁被释放才可以执行。\n \n## 乐观锁\n乐观锁的“乐观情绪”体现在，它认为数据的变动不会太频繁。因此，它允许多个事务同时对数据进行变动。实现方式：乐观锁一般会使用版本号机制或CAS算法实现。\n \n# 13. SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义？\n* show status 命令了解各种 sql 的执行频率\n* 通过慢查询日志定位那些执行效率较低的 sql 语句\n* explain 分析低效 sql 的执行计划（这点非常重要，日常开发中用它分析Sql，会大大降低Sql导致的线上事故）\n\n# 14. select for update有什么含义，会锁表还是锁行还是其他？\nselect for update 含义\n\nselect查询语句是不会加锁的，但是select for update除了有查询的作用外，还会加锁呢，而且它是悲观锁哦。至于加了是行锁还是表锁，这就要看是不是用了索引/主键啦。 没用索引/主键的话就是表锁，否则就是是行锁。\n\n# 15. MySQL事务得四大特性以及实现原理\n \n* 原子性： 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。\n* 一致性： 指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。\n* 隔离性： 多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果。简言之，就是事务之间是进水不犯河水的。\n* 持久性： 表示事务完成以后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。\n## 事务ACID特性的实现思想\n* 原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。\n* 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。\n* 隔离性：通过锁以及MVCC,使事务相互隔离开。\n* 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。\n\n# 16. 如果某个表有近千万数据，CRUD比较慢，如何优化？\n## 分库分表\n某个表有近千万数据，可以考虑优化表结构，分表（水平分表，垂直分表），当然，你这样回答，需要准备好面试官问你的分库分表相关问题呀，如\n* 分表方案（水平分表，垂直分表，切分规则hash等）\n* 分库分表中间件（Mycat，sharding-jdbc等）\n* 分库分表一些问题（事务问题？跨节点Join的问题）\n* 解决方案（分布式事务等）\n## 索引优化\n除了分库分表，优化表结构，当然还有所以索引优化等方案~\n\n# 17. 如何写sql能够有效的使用到复合索引？\n复合索引，也叫组合索引，用户可以在多个列上建立索引,这种索引叫做复合索引。\n\n当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。\n```\nselect * from table where k1=A AND k2=B AND k3=D\n```\n有关于复合索引，我们需要关注查询Sql条件的顺序，确保最左匹配原则有效，同时可以删除不必要的冗余索引。\n\n# 18. mysql中in 和exists的区别\n假设表A表示某企业的员工表，表B表示部门表，查询所有部门的所有员工，很容易有以下SQL:\n```\nselect * from A where deptId in (select deptId from B);\n```\n这样写等价于：\n\n先查询部门表B select deptId from B 再由部门deptId，查询A的员工 select * from A where A.deptId = B.deptId\n\n可以抽象成这样的一个循环：\n\n```\nList<> resultSet ;\n    for(int i=0;i<B.length;i++) {\n          for(int j=0;j<A.length;j++) {\n          if(A[i].id==B[j].id) {\n             resultSet.add(A[i]);\n             break;\n          }\n       }\n    }\n```\n显然，除了使用in，我们也可以用exists实现一样的查询功能，如下：\n```\nselect * from A where exists (select 1 from B where A.deptId = B.deptId);\n```\n因为exists查询的理解就是，先执行主查询，获得数据后，再放到子查询中做条件验证，根据验证结果（true或者false），来决定主查询的数据结果是否得意保留。\n\n那么，这样写就等价于：\n\nselect * from A,先从A表做循环 select * from B where A.deptId = B.deptId,再从B表做循环.\n\n同理，可以抽象成这样一个循环：\n```\nList<> resultSet ;\n    for(int i=0;i<A.length;i++) {\n          for(int j=0;j<B.length;j++) {\n          if(A[i].deptId==B[j].deptId) {\n             resultSet.add(A[i]);\n             break;\n          }\n       }\n    }\n```\n数据库最费劲的就是跟程序链接释放。假设链接了两次，每次做上百万次的数据集查询，查完就走，这样就只做了两次；相反建立了上百万次链接，申请链接释放反复重复，这样系统就受不了了。即mysql优化原则，就是小表驱动大表，小的数据集驱动大的数据集，从而让性能更优。 因此，我们要选择最外层循环小的，也就是，如果B的数据量小于A，适合使用in，如果B的数据量大于A，即适合选择exists，这就是in和exists的区别。\n\n# 19. 数据库自增主键可能遇到什么问题？\n使用自增主键对数据库做分库分表，可能出现诸如主键重复等的问题。解决方案的话，简单点的话可以考虑使用UUID哈 自增主键会产生表锁，从而引发问题 自增主键可能用完问题。\n\n# 20. MVCC底层原理\n我们聊下MySQL是如何实现Read Repeatable的吧，因为一般我们都不修改这个隔离级别，但是你得清楚是怎么回事儿，MySQL是通过MVCC机制来实现的，就是多版本并发控制，multi-version concurrency control。\n\ninnodb存储引擎，会在每行数据的最后加两个隐藏列，一个保存行的创建时间，一个保存行的删除时间，但是这儿存放的不是时间，而是事务id，事务id是mysql自己维护的自增的，全局唯一。\n\n事务id，在mysql内部是全局唯一递增的，事务id=1，事务id=2，事务id=3\n\n| id   | name | 创建事务id | 删除事务id |\n| ---- | ---- | ---------- | ---------- |\n| 1    | 张三 | 120        | 空         |\n\n事务ID=121的事务，查询ID=1的这一行数据，一定会找到创建事务ID<=当前事务ID的那一行，select * from table where id = 1，就可以查到上面那一行。\n\n事务ID=122的事务，将ID=1的这一行删除了，此时就会将ID=1的行的删除事务ID设置成122\n\n| id   | name | 创建事务id | 删除事务id |\n| ---- | ---- | ---------- | ---------- |\n| 1    | 张三 | 120        | 122        |\n\n事务ID=121的事务，再次查询ID=1的那一行，能查到，创建事务ID<=当前事务ID，当前事务ID < 删除事务ID\n\n| id   | name | 创建事务id | 删除事务id |\n| ---- | ---- | ---------- | ---------- |\n| 1    | 张三 | 120        | 122        |\n| 2    | 李四 | 119        | 空         |\n\n事务id=121的事务，查询id=2的那一行，查到name=李四\n\n| id   | name   | 创建事务id | 删除事务id |\n| ---- | ------ | ---------- | ---------- |\n| 1    | 张三   | 120        | 122        |\n| 2    | 李四   | 119        | 空         |\n| 2    | 小李四 | 122        | 空         |\n\n事务id=122的事务，将id=2的那一行的name修改成name=小李四\n\n**Innodb存储引擎，对于同一个ID，不同的事务创建或修改，每个事务都有自己的快照**（会插入一条记录）\n\n事务id=121的事务，查询id=2的那一行，答案是：李四，创建事务id <= 当前事务id，当前事务id < 删除事务id.\n\n在一个事务内查询的时候，mysql只会查询创建事务id <= 当前事务id的行，这样可以确保这个行是在当前事务中创建，或者是之前创建的；同时一个行的删除事务id要么没有定义（就是没删除），要么是比当前事务id大（在事务开启之后才被删除）；满足这两个条件的数据都会被查出来。\n\n那么如果某个事务执行期间，别的事务更新了一条数据呢？这个很关键的一个实现，其实就是在innodb中，是**插入了一行记录**，然后将新插入的记录的创建时间设置为新的事务的id，同时将这条记录之前的那个版本的删除时间设置为新的事务的id。\n\n现在get到这个点了吧？这样的话，你的这个事务其实对某行记录的查询，始终都是查找的之前的那个快照，因为之前的那个快照的创建时间小于等于自己事务id，然后删除时间的事务id比自己事务id大，所以这个事务运行期间，会一直读取到这条数据的同一个版本。\n\n# 21. 数据库中间件了解过吗，sharding jdbc，mycat？\nsharding-jdbc目前是基于jdbc驱动，无需额外的proxy，因此也无需关注proxy本身的高可用。 Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以 jar 包的形式提供轻量级服务的。\n# 22. MySQL的主从延迟，你怎么解决？\n![主从](https://img-blog.csdnimg.cn/img_convert/7da751bb28a48bdc7fd5694911b7b87a.png)\n## 主从复制分了五个步骤进行：\n* 步骤一：主库的更新事件(update、insert、delete)被写到binlog\n* 步骤二：从库发起连接，连接到主库。\n* 步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。\n* 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log\n* 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db\n## 主从同步延迟的原因\n一个服务器开放Ｎ个链接给客户端来连接的，这样有会有大并发的更新操作, 但是从服务器的里面读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。\n## 主从同步延迟的解决办法\n可以参考沈剑老师的文章：[数据库主从不一致怎么解决？](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961330&idx=1&sn=4bdbada3b26d4fc2fc505f7a0f2ad7c4&chksm=bd2d022e8a5a8b38e59f0dfffba7ca407fe8711644b3794832572dd822c665205bb820cdddf7&scene=21#wechat_redirect)\n\n# 23. 说一下大表查询的优化方案\n* 优化shema、sql语句+索引；\n* 可以考虑加缓存，memcached, redis，或者JVM本地缓存；\n* 主从复制，读写分离；\n* 分库分表；\n\n# 24. 什么是数据库连接池?为什么需要数据库连接池呢?\n连接池基本原理：\n\n数据库连接池原理：在内部对象池中，维护一定数量的数据库连接，并对外暴露数据库连接的获取和返回方法。\n\n## 应用程序和数据库建立连接的过程\n* 通过TCP协议的三次握手和数据库服务器建立连接\n* 发送数据库用户账号密码，等待数据库验证用户身份\n* 完成身份验证后，系统可以提交SQL语句到数据库执行\n* 把连接关闭，TCP四次挥手告别。\n## 数据库连接池好处\n* 资源重用 (连接复用)\n* 更快的系统响应速度\n* 新的资源分配手段 统一的连接管理，避免数据库连接泄漏\n\n# 25. 一条SQL语句在MySQL中如何执行的？\n## MySQL逻辑架构图\n\nMySQL分为Server层和存储引擎层两个部分，不同的存储引擎共用一个Server层。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/ff272fe853bf4ef2a588d5cb57d4139e.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_28,color_FFFFFF,t_70,g_se,x_16#pic_center)\n\n\nServer层：大多数MySQL的核心服务功能都在这一层，包括连接处理、授权认证、查询解析、分析、优化、缓存以及所有的内置函数（例如，日期、时间、数学和加密函数），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n存储引擎层：存储引擎负责MySQL中数据的存储和提取。服务器通过API与存储引擎进行通信。这些接口屏蔽了不同存储引擎之间的差异，使得这些差异对上层的查询过程透明。\n\nMySQL客户端与服务端的通信方式是“**半双工**”，客户端一旦开始发送消息另一端要接收完整这个消息才能响应，客户端一旦开始接收数据就没法停下来发送指令，一请求一响应。\n\n## 连接器\n\n第一步，先连接到数据库上，当客户端（应用）连接到MySQL服务器时，服务器需要对其进行认证，认证基于用户名、原始主机信息和密码，一旦客户端连接成功，服务器会继续验证客户端是否具有执行某个特定查询的权限（例如，是否允许客户端对某一数据库的某一表执行SELECT语句）\n\n\n\n连接命令：\n\n\n```bash\nmysql -h$ip -p$port -u$user -p\n```\n\n\n输完命令之后，需要在交互对话里面输入密码，密码不建议在-p后面直接输入，这样会导致密码泄露。\n\n## 查询缓存\n\n第二步，查询缓存，每次MySQL执行过的语句及其结果会以key-value形式缓存在内存中，key是查询语句，value是查询结果。如果查询能够在缓存中找到key，那么这个value就会被直接返回客户端。\n\n但是大多数情况下我会建议不要使用缓存，因为查询缓存的失效非常频繁，只要对一个表的更新，即便是更新一些与缓存无关的字段，这个表所有的缓存都会被清空，因此很可能会费劲地把结果存起来，还没使用就被一个更新全部清空，对于更新压力的数据库来说，查询缓存的命中率会非常低，除非业务就一张静态表，很长时间才会更新一次。（例如系统配置表）\n\nMySQL提供了按需使用的方式，可以将参数query_cache_type设置为DEMAND，这对于默认的SQL不使用查询缓存，而对于确定要使用查询缓存的语句，可以使用SQL_CACHE显示指定。（SELECT SQL_CACHE * FROM TAB）\n\n通过查询语句做哈希算法得到一个哈希值，因此这里要想命中缓存，查询SQL和缓存SQL必须完全一致，每次检查缓存是否命中时都会对缓存加锁，对于一个读写频繁的系统使用查询缓存很有可能降低查询\n\n注意：MySQL8.0版本直接将缓存的整个功能模块删掉了\n\n## 分析器\n\n第三步，分析器，如果没有命中缓存，就会执行SQL语句，首先让MySQL知道我们需要做什么，因此需要对SQL语句解析，MySQL从输入的“select”关键字识别出来，这是一条查询语句，把字符串“TAB”识别成表名TAB，检查查询中涉及的表和数据列是否存在或别名是否有歧义\n\n解析器的工作：语法分析（生成句子），语义分析（确保这些句子讲得通），以及代码生成（为编译准备）\n\n注意：分析器和解析器是一个东西，有些书叫分析器，有些书叫解析器，就是不同的叫法而已\n\n## 优化器\n\n第四步，优化器，经过分析器MySQL知道我们需要什么了，在开始执行前，还要经过优化器进行处理，优化器是在表里面有多个索引时，决定使用哪个索引，或者在一个语句有多表关联（join）时，决定各个表的连接顺序。\n\n优化器会生成执行计划\n\n## 执行器\n\n第五步，执行器，MySQL通过分析器知道要做什么，通过优化器知道怎么做，开始执行前，要先判断一下是否有表TABLE查询权限，如果有打开表，根据表的引擎定义，去使用这个引擎提供的接口。\n\n根据执行计划，调用存储引擎API来查询数据\n\n# 26. InnoDB引擎中的索引策略，了解过吗？\n\n只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是有效的。对于非常小的表，大部分情况下简单的全表扫描更高效，对于中到大型的表，索引就非常有效。\n\n正确地创建和使用索引是实现高性能查询的基础。\n\n## 独立的列\n\n如果查询中的列不是独立的，则MySQL就不会使用索引，’独立的列’是指索引列不能是表达式的一部分，也不是函数的参数。\n\nselect actor_id from skill.actor where actor_id + 1 = 5,这个查询无法使用actor_id列的索引;\nselect actor_id from skill.actor where to_days(current_date) - to_days(date_col) <= 10,这个也不会使用索引。\n\n## 前缀索引和索引选择性\n\n有时候需要索引很长的字符列，这会让索引变得大且慢，通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率，但这样也会降低索引的选择性，索引的选择性是指，不重复的索引值和数据表的记录总数（#T）的比值，范围从1/#T到1之间，索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行，唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。\n\n一般情况下某个列前缀的选择性也是足够高的，足以满足查询性能，对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整程度。\n\n诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。\n</br>\n\n如何选择合适的前缀？\n\n①我们可以通过left函数\n\n②计算完整列的选择性，并使前缀的选择性接近于完整列的选择性；\nselect count(distinct city)/count(*) from skill.city_demo，选择性0.0312\n\nselect count(distinct left(city,6))/count(*) from skill.city_demo，选择性0.0309\n\nselect count(distinct left(city,7))/count(*) from skill.city_demo，选择性0.0310\n\n前缀索引是一种能使索引更小、更快的有效方法，但另一方面也有其缺点：MySQL无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。\n\n有时候后缀索引也有用途，MySQL原声不支持反向索引，但是可以把字符串反转后存储，并基于此建立前缀索引。\n\n## 多列索引\n\n一个常见的错误就是，为每个列创建一个独立的索引或者按照错误的顺序创建多列索引。\n\n当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引。\n\n当服务器需要对多个索引做联合操作时（通常有多个OR条件），通常需要耗费大量CPU和内存资源在算法的缓存、排序合并操作上，特别是当其中有些索引的选择性不高，需要合并扫描返回的大量数据的时候，导致该执行计划还不如直接走全表扫描，这样做不但会消耗更多的CPU和内存资源，还可能会影响查询的并发性。\n\n单列索引：节点中关键字【name】\n\n联合索引：节点中关键字【name，phoneNum】\n\n</br>\n\n联合索引列选择原则：\n\n①经常用的列优先【最左匹配原则】\n\n②选择性（离散性）高的优先【离散度高原则】\n\n③宽度小的列优先【最少空间原则】\n\n优先级1>2>3\n\nselect * from t_user where name = ?\n\nselect * from t_user where name = ? and phoneNum = ?\n\ncreate index index_name on t_user(name)\n\ncreate index index_name_phoneNum on t_user(name,phoneNum)\n\n这种做法是错误的，根据最左匹配原则，两条查询都可以走index_name_phoneNum索引，**index_name索引就是冗余索引**。\n\n## 选择合适的索引列顺序\n\n当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的，这时索引的作用只是用于优化WHERE条件的查找，在这种情况下，这种设计的索引确实能够最快地过滤出需要的行，对于在WHERE字句中只使用了索引部分前缀列的查询来说选择性也更高，然而，性能不只是依赖于所有索引列的选择性，也和查询条件的具体值有关，也就是和值的分布有关，可能需要根据那些运行频率最高的查询来调整索引列的顺序，让这种情况下索引的选择性最高。\n\n## 聚簇索引\n\n聚簇索引**并不是一种单独的索引类型**，而**是一种数据存储方式**，具体的细节依赖于其实现方式，但InnoDB的聚簇索引实际上在同一个结构中保存了B+Tree索引和数据行。\n\n当表有聚簇索引时，它的数据行实际上存放在索引的叶子页中，术语“聚簇”表示数据行和相邻的键值紧凑地存储在一起（这并非总成立），因为无法同时把数据行存在两个不同的地方，所以一个表只能有一个聚簇索引（不过，覆盖索引可以模拟多个聚簇索引的情况）。\n\n因为是存储引擎负责实现索引，因此不是所有的存储引擎都支持聚簇索引，这里只关注InnoDB。\n\n## 列的离散性\n\n找出离散性好的列，离散性越高，可选择性就越好。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/d3cb2b283bf34cefa42eb95571376b90.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_24,color_FFFFFF,t_70,g_se,x_16#pic_center)\n例如：sex字段，只有男和女，离散性很差，因此选择性很差\n\n# 27. 数据库存储日期格式时，如何考虑时区转换问题？\n* datetime类型适合用来记录数据的原始的创建时间，修改记录中其他字段的值，datetime字段的值不会改变，除非手动修改它。\n* timestamp类型适合用来记录数据的最后修改时间，只要修改了记录中其他字段的值，timestamp字段的值都会被自动更新。\n\n# 28. 一条sql执行过长的时间，你如何优化，从哪些方面入手？\n* 查看是否涉及多表和子查询，优化Sql结构，如去除冗余字段，是否可拆表等\n* 优化索引结构，看是否可以适当添加索引\n* 数量大的表，可以考虑进行分离/分表（如交易流水表）\n* 数据库主从分离，读写分离\n* explain分析sql语句，查看执行计划，优化sql\n* 查看mysql执行日志，分析是否有其他方面的问题\n\n# 29. Blob和text有什么区别？\n* Blob用于存储二进制数据，而Text用于存储大字符串。\n* Blob值被视为二进制字符串（字节字符串）,它们没有字符集，并且排序和比较基于列值中的字节的数值。\n* text值被视为非二进制字符串（字符字符串）。它们有一个字符集，并根据字符集的排序规则对值进行排序和比较。\n\n\n# 30. MySQL里记录货币用什么字段类型比较好？\n* 货币在数据库中MySQL常用Decimal和Numric类型表示，这两种类型被MySQL实现为同样的类型。他们被用于保存与金钱有关的数据。\n* salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。存储在salary列中的值的范围是从-9999999.99到9999999.99。\n* DECIMAL和NUMERIC值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小数精度。\n\n\n# 31. InnoDB有哪几种锁？\n如何使用普通锁保证一致性？\n\n①操作数据前，加锁，实施互斥，不允许其他的并发任务操作；\n\n②操作完成后，释放锁，让其他任务执行；如此这般，来保证一致性。\n\n普通锁存在什么问题？\n\n简单的锁住太过粗暴，连“读任务”也无法并行，任务执行过程本质上是串行的。\n\n## 共享/排它锁(Shared and Exclusive Locks) \n\n简单的锁住太过粗暴，连“读任务”也无法并行，任务执行过程本质上是串行的。于是出现了共享锁与排他锁：\n\n- 共享锁（Share Locks，记为S锁），读取数据时加S锁 \n\n- 排他锁（eXclusive Locks，记为X锁），修改数据时加X锁 \n\n共享锁与排他锁： \n\n- 共享锁之间不互斥，读读可以并行 \n\n- 排他锁与任何锁互斥，写读，写写不可以并行\n\n可以看到，一旦写数据的任务没有完成，数据是不能被其他任务读取的，这对并发度有较大的影响。\n\n有没有可能，进一步提高并发呢？\n\n即使写任务没有完成，其他读任务也可能并发，MySQL通过多版本控制解决此问题。（快照读）\n\n## 意向锁(Intention Locks) \n\nInnoDB支持多粒度锁(multiple granularity locking)，它允许行级锁与表级锁共存，实际应用中，InnoDB使用的是意向锁。\n\n意向锁是指，未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。\n\n意向锁的特点：\n\n①首先，意向锁，是一个表级别的锁(table-level locking)； \n\n②意向锁分为： \n\n- 意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁 \n\n- 意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁\n\n举个例子： \n\nselect ... lock in share mode，要设置IS锁； \n\nselect ... for update，要设置IX锁； \n\n③意向锁协议(intention locking protocol)并不复杂： \n\n事务要获得某些行的S锁，必须先获得表的IS锁 \n\n事务要获得某些行的X锁，必须先获得表的IX锁\n\n④由于意向锁仅仅表明意向，它其实是比较弱的锁，意向锁之间并不相互互斥，而是可以并行，其兼容互斥表如下：\n\n|      | IS   | IX   |\n| ---- | ---- | ---- |\n| IS   | 兼容 | 兼容 |\n| IX   | 兼容 | 兼容 |\n\n </br>\n\n⑤既然意向锁之间都相互兼容，那其意义在哪里呢？它会与共享锁/排它锁互斥，其兼容互斥表如下：\n\n|      | S    | X    |\n| ---- | ---- | ---- |\n| IS   | 兼容 | 互斥 |\n| IX   | 互斥 | 互斥 |\n\n补充：排它锁是很强的锁，不与其他类型的锁兼容。这也很好理解，修改和删除某一行的时候，必须获得强锁，禁止这一行上的其他并发，以保障数据的一致性。\n\n</br>\n\n意向锁解决什么问题？\n\n事务 A 获取了某一行的排它锁，并未提交： select * from table where id = 6 from update \n\n事务 B 想要获取 table 表的表锁： LOCK TABLES table READ; \n\n因为共享锁与排它锁互斥，所以事务 B 在视图对 table 表加共享锁的时候，必须保证： \n\n①当前没有其他事务持有 table 表的排它锁。\n\n②当前没有其他事务持有 table 表中任意一行的排它锁 。 \n\n为了检测是否满足第二个条件，事务 B 必须在确保 table表不存在任何排它锁的前提下，去检测表中的每一行是否存在排它锁。很明显这是一个效率很差的做法，但是有了意向锁之后，事务A持有了table表的意向排它锁，就可得知事务A必然持有该表中某些数据行的排它锁，而<font style=\"color: rgb(255, 76, 0);\">**无需去检测表中每一行是否存在排它锁**</font>\n\n意向锁之间为什么互相兼容？\n\n事务 A 先获取了某一行的排他锁，并未提交： select * from users where id = 6 for update\n\n①事务 A 获取了 users 表上的意向排他锁。 \n\n②事务 A 获取了 id 为 6 的数据行上的排他锁。 \n\n之后事务 B 想要获取 users 表的共享锁： LOCK TABLES users READ; \n\n事务 B 检测到事务 A 持有 users 表的意向排他锁。 事务 B 对 users 表的加锁请求被阻塞（排斥）。 \n\n最后事务 C 也想获取 users 表中某一行的排他锁： select * from users where id = 5 for update; \n\n①事务 C 申请 users 表的意向排他锁。\n\n②事务 C 检测到事务 A 持有 users 表的意向排他锁。 \n\n③因为意向锁之间并不互斥，所以事务 C 获取到了 users 表的意向排他锁。\n\n④因为id 为 5 的数据行上不存在任何排他锁，最终事务 C 成功获取到了该数据行上的排他锁。\n\n **如果意向锁之间互斥，行级锁的意义将会失去**\n\n## 记录锁(Record Locks) \n\n记录锁，它封锁索引记录，例如： \n\nselect * from t where id=1 for update; 它会在id=1的索引记录上加锁，以阻止其他事务插入，更新，删除id=1的这一行。 \n\n需要说明的是： select * from t where id=1; 则是快照读(SnapShot Read)，它并不加锁，具体在《17.什么是快照读？》中做了详细阐述。\n\n## 间隙锁(Gap Locks) \n\n间隙锁，它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。 \n\n存储引擎：InnoDB\n\n隔离级别：可重复读隔离级别\n\n\n建表语句：\n```mysql\nmysql> CREATE TABLE `T`  (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE = INNODB;\n```\n\n\n\n数据列表：\n\n| id   | name     |\n| ---- | -------- |\n| 1    | xiaohong |\n| 3    | zhangsan |\n| 5    | lisi     |\n| 9    | wangwu   |\n\n\n这个SQL语句 select * from T where id between 8 and 15 for update; 会封锁区间，以阻止其他事务id=10的记录插入。 \n\n为什么要阻止id=10的记录插入？ 如果能够插入成功，头一个事务执行相同的SQL语句，会发现结果集多出了一条记录，即幻影数据。 \n\n\n间隙锁的主要目的，就是**为了防止其他事务在间隔中插入数据**，以导致“不可重复读”。 \n\n\n\n如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。\n\n## 临键锁(Next-key Locks) \n\n临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。\n\n\n\n更具体的，临键锁会封锁索引记录本身，以及索引记录之前的区间。\n\n\n\n如果一个会话占有了索引记录R的共享/排他锁，其他会话不能立刻在R之前的区间插入新的索引记录。\n\n\n\n存储引擎：InnoDB\n\n隔离级别：可重复读隔离级别\n\n\n\n建表语句：\n\n```mysql\nmysql> CREATE TABLE `T`  (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE = INNODB;\n```\n\n\n\n数据列表：\n\n| id   | name     |\n| ---- | -------- |\n| 1    | xiaohong |\n| 3    | zhangsan |\n| 5    | lisi     |\n| 9    | wangwu   |\n\n </br>\n\nPK上潜在的临键锁为：\n\n(-infinity, 1]\n\n(1, 3]\n\n(3, 5]\n\n(5, 9]\n\n(9, +infinity]\n\n \n\n临键锁的主要目的，也是<font style=\"color: rgb(255, 76, 0);\"> **为了避免幻读(Phantom Read)** </font>。如果把事务的隔离级别降级为RC，临键锁则也会失效。\n\n\n\n## 插入意向锁(Insert Intention Locks) \n\n对已有数据行的修改与删除，必须加强互斥锁X锁，那对于数据的插入，是否还需要加这么强的锁，来实施互斥呢？插入意向锁，孕育而生。 \n\n\n\n插入意向锁，是间隙锁(Gap Locks)的一种（所以，也是实施在索引上的），它是专门针对insert操作的。 \n\n\n\n多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。 \n\n\n\n存储引擎：InnoDB\n\n隔离级别：可重复读隔离级别\n\n\n\n建表语句：\n\n```mysql\nmysql> CREATE TABLE `T`  (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE = INNODB;\n```\n\n\n\n数据列表：\n\n| id   | Name     |\n| ---- | -------- |\n| 10   | xiaohong |\n| 20   | zhangsan |\n| 30   | lisi     |\n\n\n\n事务A先执行，在10与20两条记录中插入了一行，还未提交： \n\ninsert into t values(11, xxx); \n\n\n\n事务B后执行，也在10与20两条记录中插入了一行： \n\ninsert into t values(12, ooo); \n\n\n\n会使用什么锁？事务B会不会被阻塞呢？ 回答：虽然事务隔离级别是RR，虽然是同一个索引，虽然是同一个区间，但插入的记录并不冲突，故这里： 使用的是插入意向锁，并不会阻塞事务B\n\n\n\n## 自增锁(Auto-inc Locks) \n\n案例说明：\n\n\n\n存储引擎：InnoDB\n\n隔离级别：可重复读隔离级别\n\n\n\n建表语句：\n\n```mysql\nmysql> CREATE TABLE `T`  (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE = INNODB;\n```\n\n\n\n数据列表：\n\n| id   | name     |\n| ---- | -------- |\n| 1    | xiaohong |\n| 2    | zhangsan |\n| 3    | lisi     |\n\n\n\n事务A先执行，还未提交： insert into t(name) values(xxx); \n\n事务B后执行： insert into t(name) values(ooo); \n\n事务B会不会被阻塞？ \n\n</br>\n\n案例分析：\n\n InnoDB在RR隔离级别下，能解决幻读问题，上面这个案例中：\n\n①事务A先执行insert，会得到一条(4, xxx)的记录，由于是自增列，故不用显示指定id为4，InnoDB会自动增长，注意此时事务并未提交；\n\n②事务B后执行insert，假设不会被阻塞，那会得到一条(5, ooo)的记录； \n\n此时，并未有什么不妥，但如果，\n\n③事务A继续insert： \n\ninsert into t(name) values(xxoo); \n\n会得到一条(6, xxoo)的记录。\n\n④事务A再select： \n\nselect * from t where id>3; \n\n\n\n得到的结果是： \n\n4, xxx \n\n6, xxoo \n\n补充：不可能查询到5的记录，再RR的隔离级别下，不可能读取到还未提交事务生成的数据。 \n\n\n\n这对于事务A来说，就很奇怪了，对于AUTO_INCREMENT的列，连续插入了两条记录，一条是4，接下来一条变成了6，就像莫名其妙的幻影。 \n\n\n\n自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。 \n\n\n\n与此同时，InnoDB提供了innodb_autoinc_lock_mode配置，可以调节与改变该锁的模式与行为。 \n\n\n# 32. Hash索引和B+树区别是什么？你在设计索引是怎么抉择的？\n* B+树可以进行范围查询，Hash索引不能。\n* B+树支持联合索引的最左侧原则，Hash索引不支持。\n* B+树支持order by排序，Hash索引不支持。\n* Hash索引在等值查询上比B+树效率更高。\n* B+树使用like 进行模糊查询的时候，like后面（比如%开头）的话可以起到优化的作用，Hash索引根本无法进行模糊查询。\n\n\n# 33. mysql 的内连接、左连接、右连接有什么区别？\n* Inner join 内连接，在两张表进行连接查询时，只保留两张表中完全匹配的结果集\n* left join 在两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录。\n* right join 在两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。\n\n# 34. 什么是内连接、外连接、交叉连接、笛卡尔积呢？\n* 内连接（inner join）：取得两张表中满足存在连接匹配关系的记录。\n* 外连接（outer join）：取得两张表中满足存在连接匹配关系的记录，以及某张表（或两张表）中不满足匹配关系的记录。\n* 交叉连接（cross join）：显示两张表所有记录一一对应，没有匹配关系进行筛选，也被称为：笛卡尔积。\n\n# 35. 说一下数据库的三大范式\n* 第一范式：数据表中的每一列（每个字段）都不可以再拆分。\n* 第二范式：在第一范式的基础上，分主键列完全依赖于主键，而不能是依赖于主键的一部分。\n* 第三范式：在满足第二范式的基础上，表中的非主键只依赖于主键，而不依赖于其他非主键。\n\n# 36. mysql有关权限的表有哪几个呢？\nMySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysql_install_db脚本初始化。这些权限表分别user，db，table_priv，columns_priv和host。\n* user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。\n* db权限表：记录各个帐号在各个数据库上的操作权限。\n* table_priv权限表：记录数据表级的操作权限。\n* columns_priv权限表：记录数据列级的操作权限。\n* host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。\n\n## 主从复制binlog格式有哪几种？有什么区别？\n①STATEMENT，基于语句的日志记录，把所有写操作的sql语句写入 binlog （默认）\n例如update xxx set  update_time = now() where pk_id = 1，这时，主从的 update_time 不一致\n优点：\n成熟的技术。 \n更少的数据写入日志文件。当更新或删除影响许多行时，这将导致 日志文件所需的存储空间大大减少。这也意味着从备份中获取和还原可以更快地完成。 \n日志文件包含所有进行了任何更改的语句，因此它们可用于审核数据库。\n\n缺点：\n有很多函数不能复制，例如now()、random()、uuid()等\n\n②ROW，基于行的日志记录，把每一行的改变写入binlog，假设一条sql语句影响100万行，从节点需要执行100万次，效率低。\n优点：可以复制所有更改，这是最安全的复制形式\n缺点：如果该SQL语句更改了许多行，则基于行的复制可能会向二进制日志中写入更多的数据。即使对于回滚的语句也是如此。这也意味着制作和还原备份可能需要更多时间。此外，二进制日志被锁定更长的时间以写入数据，这可能会导致并发问题。\n\n③MIXED，混合模式，如果 sql 里有函数，自动切换到 ROW 模式，如果 sql 里没有会造成主从复制不一致的函数，那么就使用STATEMENT模式。（存在问题：解决不了系统变量问题，例如@@host name，主从的主机名不一致）\n\n# 38. Mysql主从复制方式？有什么区别？\n①异步复制\n网络或机器故障时，会造成数据不一致 \n\n数据不一致缓解方案：半同步，插入主库时，不会及时返回给我们的web端，他会进行等待，等待从库的I/OThread从主节点Binary log读取二进制文件并拷贝到从节点的relaybinlog之后，在进行返回。（不是等待所有，一个从节点复制过去就行了）\n\n数据强一致性了但是性能低：可以设置超时时间（多个Slave，或者Slave非常卡，会导致响应非常慢？不会，有保护机制，超过时间就直接返回，一般情况下设置1秒）\n\n注意：不是等待所有从节点同步从主节点Binary log读取二进制文件并拷贝到从节点的relaybinlog之后才返回，而是只要有一个节点拷贝成功就返回\n\n根据业务场景选择同步和半同步\n\n注意：半同步只会缓解数据不一致问题，并不能完全解决\n\n②半同步复制（MySQL 8.0还支持通过插件实现的半同步复制接口）\n\n默认情况下，MySQL复制是异步的。Master将事件写入其二进制日志，Slave将在事件就绪时请求它们。Master不知道Slave是否或何时检索和处理了事务，并且不能保证任何事件都会到达Slave。使用异步复制，如果Master崩溃，则它提交的事务可能不会传输到任何Slave。在这种情况下，从Master到Slave的故障转移可能会导致故障转移到缺少相对于Master的事务的服务器。\n\n在完全同步复制的情况下，当Master提交事务时，所有Slave也都已提交事务，然后Master才返回执行该事务的会话。完全同步复制意味着可以随时从Master故障转移到任何Slave。完全同步复制的缺点是完成事务可能会有很多延迟。\n\n半同步复制介于异步复制和完全同步复制之间。Master等待直到至少一个Slave接收并记录了事件（所需数量的Slave是可配置的），然后提交事务。Master不等待所有Slave都确认收到，它仅需要Slave的确认，而不是事件已在Slave端完全执行并提交。因此，半同步复制可确保如果Master崩溃，则它已提交的所有事务都已传输到至少一个Slave。\n\n与异步复制相比，半同步复制提供了改进的数据完整性，因为众所周知，当提交成功返回时，数据至少存在两个位置。在半同步Master收到所需数量的Slave的确认之前，该事务处于暂挂状态且未提交。\n\n与完全同步复制相比，半同步复制更快，因为半同步复制可以配置为平衡对数据完整性（确认已收到事务的Slave数）与提交速度的需求，提交速度较慢，因为需要等待Slave。\n\n与异步复制相比，半同步复制对性能的影响是增加数据完整性的权衡。减慢量至少是将提交发送到Slave并等待Slave确认接收的TCP / IP往返时间。这意味着半同步复制最适合通过快速网络通信的关闭服务器，而最不适合通过慢速网络通信的远程服务器。半同步复制还通过限制二进制日志事件从Master发送到Slave的速度，对繁忙的会话设置了速率限制。当一个用户太忙时，这会减慢速度，这在某些部署情况下很有用。\n\nMaster及其Slave之间的半同步复制操作如下：\nSlave表示连接到Master时是否具有半同步功能。\n如果在Master端启用了半同步复制，并且至少有一个半同步Slave，则在Master块上执行事务提交的线程将等待直到至少一个半同步Slave确认已接收到该事务的所有事件，或者直到发生超时。\n仅在事件已被写入其中继日志并刷新到磁盘之后，Slave才确认接收到事务事件。\n如果在没有任何Slave确认事务的情况下发生超时，则Master将恢复为异步复制。赶上至少一个半同步Slave时，Master将返回到半同步复制。\n必须在Master端和Slave端都启用半同步复制。如果在Master上禁用了半同步复制，或者在Master上启用了半同步复制但没有任何Slave，则Master使用异步复制。\n\n③延迟复制\nMySQL 8.0还支持延迟复制，以使副本故意在源之后至少指定的时间量\n\n# 39. InnoDB内存结构包含四大核心组件\n* 缓冲池(Buffer Pool)，可以参考沈健老师文章[缓冲池(buffer pool)，这次彻底懂了！！！\n](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962450&idx=1&sn=ce17c4da8d20ce275f75d0f2ef5e40c9&chksm=bd2d098e8a5a809834aaa07da0d7546555385543fb6d687a7cf94d183ab061cd301a76547411&scene=21#wechat_redirect)\n* 写缓冲(Change Buffer)，可以参考沈健老师文章[写缓冲(change buffer)，这次彻底懂了！！！\n](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962467&idx=1&sn=899ea157b0fc6f849ec80a4d055a309b&chksm=bd2d09bf8a5a80a972a2e16a190ed7dffe03f89015ead707bdfcc5aeb8388fb278f397c125f1&scene=21#wechat_redirect)\n* 自适应哈希索引(Adaptive Hash Index)，可以参考沈健老师文章[自适应哈希索引](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962875&idx=1&sn=c6b3e7dc8a41609cfe070026bd27b71d&chksm=bd2d08278a5a813108b1f4116341ff31170574b9098e2708cbc212b008a1fac8dfd1ffeabc6b&scene=21#wechat_redirect)\n* 日志缓冲(Log Buffer)，可以参考沈健老师文章[事务已提交，数据却丢了，赶紧检查下这个配置！！！ | 数据库系列\n](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962887&idx=1&sn=4806f481448b1c3ddfbbd53e732a7bb5&chksm=bd2d0bdb8a5a82cd50bc155ed2ba57f105bfd76ff78992823ed85214b5c767eef17e691a2255&scene=21#wechat_redirect)\n\n# 40. 索引有哪些优缺点？\n## 优点\n* 唯一索引可以保证数据库表中每一行的数据的唯一性\n* 索引可以加快数据查询速度，减少查询时间\n## 缺点\n* 创建索引和维护索引要耗费时间\n* 索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间\n* 以表中的数据进行增、删、改的时候，索引也要动态的维护。\n\n# 41. 索引有哪几种类型？\n* 主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。\n* 唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。\n* 普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。\n* 全文索引：是目前搜索引擎使用的一种关键技术，对文本的内容进行分词、搜索。\n* 覆盖索引：查询列要被所建的索引覆盖，不必读取数据行\n* 组合索引：多列值组成一个索引，用于组合搜索，效率大于索引合并\n\n\n# 42. 创建索引的三种方式\n## 在执行CREATE TABLE时创建索引\n```\nCREATE TABLE `employee` (\n  `id` int(11) NOT NULL,\n  `name` varchar(255) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `date` datetime DEFAULT NULL,\n  `sex` int(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_name` (`name`) USING BTREE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n## 使用ALTER TABLE命令添加索引\n```\nALTER TABLE table_name ADD INDEX index_name (column);\n```\n## 使用CREATE INDEX命令创建\n```\nCREATE INDEX index_name ON table_name (column);\n```\n\n# 43. 百万级别或以上的数据，你是如何删除的？\n* 我们想要删除百万数据的时候可以先删除索引\n* 然后批量删除其中无用数据\n* 删除完成后重新创建索引。\n\n# 44. 覆盖索引、回表等这些，了解过吗？\n* 覆盖索引： 查询列要被所建的索引覆盖，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。\n* 回表：二级索引无法直接查询所有列的数据，所以通过二级索引查询到聚簇索引后，再查询到想要的数据，这种通过二级索引查询出来的过程，就叫做回表。\n\n# 45. B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据？\n* 在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。 在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。\n* 当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。\n# 46. 何时使用聚簇索引与非聚簇索引\n![聚簇索引](https://img-blog.csdnimg.cn/img_convert/07596c40e8f22b104fd0ce20dd52fa6b.png)\n\n# 47. 非聚簇索引一定会回表查询吗？\n不一定，如果查询语句的字段全部命中了索引，那么就不必再进行回表查询（哈哈，覆盖索引就是这么回事）。\n\n举个简单的例子，假设我们在学生表的上建立了索引，那么当进行select age from student where age < 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。\n\n# 48. 组合索引是什么？为什么需要注意组合索引中的顺序？\n组合索引，用户可以在多个列上建立索引,这种索引叫做组合索引。 因为InnoDB引擎中的索引策略的最左原则，所以需要注意组合索引中的顺序。\n\n# 49. 什么是死锁？怎么解决？\n死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。看图形象一点，如下：\n![事务.png](https://img-blog.csdnimg.cn/img_convert/1003588057cb2f6ebf194c4b7a3cbff0.png)\n\n死锁有四个必要条件：互斥条件，请求和保持条件，环路等待条件，不剥夺条件。 解决死锁思路，一般就是切断环路，尽量避免并发形成环路。\n* 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。\n* 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；\n* 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；\n* 如果业务处理不好可以用分布式事务锁或者使用乐观锁\n* 死锁与索引密不可分，解决索引问题，需要合理优化你的索引，\n\n# 50. 你是如何监控你们的数据库的？你们的慢日志都是怎么查询的？\n监控的工具有很多，例如zabbix，lepus，我这里用的是lepus', 2, '面试题专栏', 'MySQL,面试题', 1, 0, 0, 0, '2021-09-29 18:14:52', '2021-09-29 18:14:52');
INSERT INTO `tb_blog` VALUES (2, '我把面试问烂了的⭐JVM⭐总结了一下（带答案，万字总结，精心打磨，建议收藏）', 'jvm_interview', 'http://localhost:8888/upload/20210929_1818168.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容| 链接地址|\n|--|--|--|\n|  1| [Java基础知识面试题](https://blog.csdn.net/qq_35620342/article/details/119636436) |https://blog.csdn.net/qq_35620342/article/details/119636436|\n|2|[Java集合容器面试题](https://blog.csdn.net/qq_35620342/article/details/119947254)|https://blog.csdn.net/qq_35620342/article/details/119947254|\n|3|[Java并发编程面试题](https://blog.csdn.net/qq_35620342/article/details/119977224)|https://blog.csdn.net/qq_35620342/article/details/119977224|\n|4|[Java异常面试题](https://blog.csdn.net/qq_35620342/article/details/119977051)|https://blog.csdn.net/qq_35620342/article/details/119977051|\n|5|[JVM面试题](https://blog.csdn.net/qq_35620342/article/details/119948989)|https://blog.csdn.net/qq_35620342/article/details/119948989|\n|6|[Java Web面试题](https://blog.csdn.net/qq_35620342/article/details/119642114)|https://blog.csdn.net/qq_35620342/article/details/119642114|\n|7|[Spring面试题](https://blog.csdn.net/qq_35620342/article/details/119956512)|https://blog.csdn.net/qq_35620342/article/details/119956512|\n|8|[Spring MVC面试题](https://blog.csdn.net/qq_35620342/article/details/119965560)|https://blog.csdn.net/qq_35620342/article/details/119965560|\n|9|[Spring Boot面试题](https://blog.csdn.net/qq_35620342/article/details/120333717)|https://blog.csdn.net/qq_35620342/article/details/120333717|\n|10|[MyBatis面试题](https://blog.csdn.net/qq_35620342/article/details/119956541)|https://blog.csdn.net/qq_35620342/article/details/119956541|\n|11|Spring Cloud面试题|待分享|\n|12|[Redis面试题](https://blog.csdn.net/qq_35620342/article/details/119575020)|https://blog.csdn.net/qq_35620342/article/details/119575020|\n|13|[MySQL数据库面试题](https://blog.csdn.net/qq_35620342/article/details/119930887)|https://blog.csdn.net/qq_35620342/article/details/119930887|\n|14|RabbitMQ面试题|待分享|\n|15|Dubbo面试题|待分享|\n|16|Linux面试题|待分享|\n|17|Tomcat面试题|待分享|\n|18|ZooKeeper面试题|待分享|\n|19|Netty面试题|待分享|\n|20|数据结构与算法面试题|待分享|\n\n# 前言\n\n目前内存的动态分配与内存回收技术已经相当成熟，一切看起来都进入了\"自动化\"时代，那么为什么我们还要去了解GC和内存分配呢？\n当需要排查各种内存溢出、内存泄露问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们就需要对这些\"自动化\"的技术进行必要的监控和调节。 要想实现性能调优，得具备相关工具监控程序性能，有了监控信息，才能进行调优。\n\n# 一、虚拟机类加载机制\nClass文件中描述的各种信息，最终都是要加载到虚拟机中之后才能运行和使用。\n\nJVM把Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被JVM直接使用的Java类型，这个过程被称作虚拟机的类加载机制。与那些在编译时需要进行连接的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略让Java语言进行提前编译会面临额外的困难，也会让类加载时稍微增加一些性能开销，但是却为Java应用提供了极高的扩展性和灵活性，Java天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。（例如Java多态、动态代理）\n\nJava虚拟机中的类加载（JVM把class文件加载到内存），按先后顺序需要经过加载、链接、初始化三个步骤。其中，链接过程中同样需要验证；而内存中的类没有经过初始化，同样不能使用。\n\nClassLoader只负责class文件的加载，至于它是否可以运行，则由ExecutionEngine决定。\n\n## 1.虚拟机类加载过程\n![在这里插入图片描述](https://img-blog.csdnimg.cn/a1adc5f34ca84e9a80afaab1dfac7ca9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/27b3653b40ac467aafd684aeaf4b99c2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n### 加载阶段\n什么情况下需要开始类加载过程的加载阶段？这个「 Java虚拟机规范」中没有强制约束，这点可以交给虚拟机的具体实现来自由把握。但是对于初始化阶段，「 Java虚拟机规范」则是严格规定了有且只有六种情况必须对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）\n\n- 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。能够生成这四条指令的典型Java代码场景有：\n\n	（1）使用new关键字实例化对象的时候。（new）\n	（2）读取或设置一个类型的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候。\n	（3）调用一个类型的静态方法的时候。（invokestatic）\n\n- 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。\n- 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n- 当虚拟机启动时，被标明为启动类的类（用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类）。\n- 当使用JDK 7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。\n- 当一个接口中定义了JDK 8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。\n\nJava程序对类的使用方式分为：主动使用和被动使用。\n除了上述6种方式，其他使用Java类的方式都被看作为是对类的被动使用，都不会导致类的初始化。\n\n加载、验证、准备、初始化、卸载这5个阶段顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。\n\n加载阶段，Java虚拟机需要完成三件事：\n- 通过类的全限定名（例如：org.apache.commons.lang3.StringUtils）来获取定义此类的二进制字节流（Class文件字节流）\n- 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构\n- 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据访问入口\n\n### 连接阶段\n（1）验证\n验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。\n\n主要包括四种验证：文件格式验证、元数据验证、字节码验证、符合引用验证。\n\n（2）准备\n准备阶段是正式为类变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值（即0）的阶段，从概念上讲，这些变量所使用的内存都应当在方法区中进行分配，但必须注意到方法区本身是一个逻辑上的区域，在JDK 7及之前，HotSpot使用永久代来实现方法区时，实现是完全符合这种逻辑概念的；而在JDK 8及之后，类变量则会随着Class对象一起存放在Java堆中，这时候“类变量在方法区”就完全是一种对逻辑概念的表述了。\n\n> public static int value = 123，那么value在准备阶段过后的初始值为0，而不是123，因为这时尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放在类构造器`<clinit>()`方法之中，所以把value赋值为123的动作要到类的初始化阶段才会被执行。\n\n> public static final int value = 123456，final在编译的时候就会分配了，准备阶段会显示初始化，编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123456。\n\n（3）解析\n\n解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程。\n\n### 初始化阶段\n进行准备阶段时，变量已经赋过一次系统要求的初始零值，而在初始化阶段，则会根据程序员通过程序编码制定的主观计划去初始化类变量和其他资源。我们也可以从另外一种更直接的形式来表达：初始化阶段就是执行类构造器`<clinit>()`方法的过程。`<clinit>()`并不是程序员在Java代码中直接编写的方法，它是Javac编译器的自动生成物，但我们非常有必要了解这个方法具体是如何产生的，以及`<clinit>()`方法执行过程中各种可能会影响程序运行行为的细节，这部分比起其他类加载过程更贴近于普通的程序开发人员的实际工作\n\n（1）`<clinit>()`方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问，如下所示。\n```java\npublic class StaticTest {\n    static {\n        i = 0; //  给变量复制可以正常编译通过\n        System.out.println(i); // 这句编译器会报错“非法向前引用” \n    }\n    static int i = 1;\n}\n\npublic class StaticTest {\n    static {\n        i = 2; //  给变量复制可以正常编译通过\n    }\n    static int i = 1;\n\n    public static void main(String[] args) {\n        System.out.println(StaticTest.i);\n    }\n}\n```\n答案：1，为什么可以呢？在linking阶段的准备阶段，已经把i加载到内存，并且赋初始值（零值）了。\n\n> 如果没有静态变量赋值动作和静态语句块，就不会生成<clinit>\n\n（2）`<clinit>()`方法与类的构造函数（即在虚拟机视角中的实例构造器<init>()方法）不同，它不需要显式地调用父类构造器，Java虚拟机会保证在子类的`<clinit>()`方法执行前，父类的`<clinit>()`方法已经执行完毕。因此在Java虚拟机中第一个被执行的`<clinit>()`方法的类型肯定是java.lang.Object。 \n\n由于父类的`<clinit>()`方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作，如下所示，字段B的值将会是2而不是0。\n```\npublic class TestDemo {\n\n    static class Parent{\n        public static int A = 1;\n\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent{\n        public static int B  = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n```\n（3）Java虚拟机必须保证一个类的`<clinit>()`方法在多线程环境中被正确地加锁同步，如果多个线程同时去初始化一个类，那么只会有其中一个线程去执行这个类的`<clinit>()`方法，其他线程都需要阻塞等待，直到活动线程执行完毕`<clinit>()`方法。如果在一个类的`<clinit>()`方法中有耗时很长的操作，那就可能造成多个进程阻塞，在实际应用中这种阻塞往往是很隐蔽的。代下所示：\n\n```java\npublic class DeadThreadTest {\n    public static void main(String[] args) {\n        Runnable r = () -> {\n            System.out.println(Thread.currentThread().getName()+\"开始\");\n            DeadThread deadThread = new DeadThread();\n            System.out.println(Thread.currentThread().getName()+\"结束\");\n        };\n\n        Thread t1 = new Thread(r,\"线程1\");\n        Thread t2 = new Thread(r,\"线程2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n\nclass DeadThread{\n    static{\n        if(true){\n            System.out.println(Thread.currentThread().getName()+\"初始化当前类\");\n            while(true){\n                \n            }\n        }\n    }\n}\n```\n\n\n结果:\n线程2开始\n线程1开始\n线程2初始化当前类\n\n线程2在初始化当前类时死循环了，会造成后面所有的线程全部阻塞。\n\n## 2.类加载器（ClassLoader）\nJava虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（Class Loader）\n\n目前类加载器在类层次划分、OSGi、程序热部署、代码加密等领域大放异彩。\n\n类加载器：把我们硬盘上编译好的.Class文件，通过类装载器将字节码文件加载到内存中，生成一个Class对象。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/c36a332849ba458980d2855c6333a2db.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/4dea889153344d688f12fc9aafa71bd1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n这里的四者是包含关系，不是上下层，也不是子父类的继承关系\n\nClassLoader：是一个抽象类，我们可以继承它实现自定义加载器。\n\n### 启动类加载器（Bootstrap）\n启动类加载器（Bootstrap）：主要加载jre/lib/rt.jar(Java核心API )，getClassLoader为null。（C++实现的）\n\n> 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类\n\n```java\nObject object = new Object();\nobject.getClass().getClassLoader();//null\n\nString string = new String();\nstring.getClass().getClassLoader();//null\n```\n\n并不继承自java.lang.ClassLoader，没有父加载器\n\n### 扩展类加载器（Extension）\n扩展类加载器（Extension）：通过反射创建Class实例，而这个类在jre/lib/ext的jar包中，这时加载器就是Extension ClassLoader,加载jre/lib/ext里的类。\n\ngetClassLoader：sun.misc.Launcher$ExtensionLoader@HashCode\n\n直接继承自URLClassLoader，间接继承ClassLoader\n\n### 应用程序类加载器（APP）\n应用程序类加载器（APP）：它负责加载用户类路径（ClassPath）上所有的类库。\n\ngetClassLoader：sun.misc.Launcher$AppLoader@HashCode\n\n直接继承自URLClassLoader，间接继承ClassLoader\n\n对于用户自定义的类，如果没有自定义过自己的类加载器，默认使用应用程序类加载器加载\n\n可以通过ClassLoader.getSystemClassLoader();获取应用程序类加载器\n\n### 自定义类加载器\n自定义类加载器的父类是应用程序类加载器\n\nsun.misc.Launcher：它是一个Java虚拟机的入口应用\n\n获取父类加载器：classLoader.getParent()\n\n扩展类加载器和应用程序类加载器都继承了ClassLoader.\n\n获取ClassLoader方法：\n方式一：获取当前类的ClassLoader\nclazz.getClassLoader();\n方式二：获取当前线程上下文的ClassLoader\nThread.currentThread().getContextClassLoader()\n方式三：获取系统的ClassLoader\nClassLoader.getSystemClassLoader()\n方式四：获取调用者的ClassLoader\nDriverManager.getCallerClassLoader()\n\n## 3.用户自定义加载器\n为什么要自定义类加载器？\n- 隔离加载类（通过类加载器实现类的隔离、重载等功能）\n- 修改类加载的方式\n- 扩展加载源（增加除了磁盘位置之外的Class文件来源）\n- 防止源码泄露\n\n用户自定义类加载器实现步骤：\n（1）开发人员通过继承抽象类java.lang.ClassLoader类的方式，实现自己的类加载器，以满足一些特殊的需求。\n（2）在JDK1.2之前，在自定义类加载器时，总会去继承ClassLoader类并重写loadClass()方法，从而实现自定义的类加载，但是在JDK1.2之后，已不再建议用户去覆盖loadClass()方法，而是建议把自定义类的加载逻辑写在findClass()中。\n（3）在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()发放及其获取字节码流的方式，使自定义类加载器编写更加简洁。\n\n举例：\n防止源码泄露实现步骤：\n（1）继承ClassLoader，重写findClass()\n（2）在findClass()中，传入的name是加密的，先写解密逻辑，然后在获取字节码二进制流\n```java\nprotected Class<?> findClass(String name) throws ClassNotFoundException {\n    throw new ClassNotFoundException(name);\n}\n```\n（3）调用defineClass()把二进制流字节转化为Class\n```java\nprotected final Class<?> defineClass(String name, byte[] b, int off, int len)\n    throws ClassFormatError\n{\n    return defineClass(name, b, off, len, null);\n}\n```\n\n> 比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。 这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括了使用instanceof关键字做对象所属关系判定等各种情况。\n\n## 4.双亲委派机制\n双亲委派模型的工作原理：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。\n\n为什么根类加载器为NULL?\n根类加载器并不是Java实现的，而且由于程序通常须访问根加载器，因此访问扩展类加载器的父类加载器时返回null。\n\n> 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类\n\n> 自定义一个包java.lang，自定义Java核心类库没有的类，运行时报错。\njava.lang.SecurityException：prohibited package name：java.lang\n\n举例：自定义一个包java.lang，自定义一个类String，然后里面声明main方法，运行时报错。（沙箱机制）\n```java\npackage java.lang;\n\npublic class String {\n	public static void main(String[] args) {\n		System.out.println(1);\n	}\n}\n```\n```\n错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为:\n   public static void main(String[] args)\n否则 JavaFX 应用程序类必须扩展javafx.application.Application\n```\n\n加载String时，使用的是BootstrapClassLoader，加载的是Java核心类库的String，并非我们自定义的String，核心类库的String类，没有main方法，因此报错。\n\n沙箱机制：是由基于双亲委派机制上采取的一种JVM的自我保护机制,假设你要写一个java.lang.String 的类,由于双亲委派机制的原理,此请求会先交给Bootstrap试图进行加载,但是Bootstrap在加载类时首先通过包和类名查找rt.jar中有没有该类,有则优先加载rt.jar包中的类,因此就保证了java的运行机制不会被破坏.（安全特性，防止恶意代码对Java的破坏）\n\n双亲委派优势：\n- 避免类的重复加载\n- 保护程序安全，防止核心API被篡改\n\n# 二、Java运行时数据区\n\nJVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。不同的JVM对于内存的划分方式和管理机制存在着部分差异。\n\nJava虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。\n\nJVM运行时数据区：Java代码运行的时候每个数据区的区块存的是什么用来干什么怎么存的\n\n需提前理解的概念：\n一个类可以看成三类，数据（int i = 0等....）、指令（int c = i....代码）、控制（if else switch…）\n\nJava 虚拟机运行时数据区：Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域，这些区域有各自的用途，以及创建和消耗的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则是依赖用户线程的启动和结束而建立和消耗。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/6e4d75c6e3a94208b6cd35e825cb9e31.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_19,color_FFFFFF,t_70,g_se,x_16)\n\n## 1.Program Counter Register（程序计数器）\nProgram Counter Register：程序计数器\n\n作用：程序计数器用来存储指向下一条指令的地址，也就是将要执行的指令代码。由执行引擎读取下一条指令。\n\n它是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。\n\n由于Java虚拟机的多线程是通过线程轮流切换、分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令，因此，为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。\n\n比如我A()方法调用了B()方法，执行完B之后怎么恢复，这时就需要程序计数器，字节码解释器就是通过改变计数器的值来选取下一条执行的字节码指令。\n\n如果线程执行的是Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址，如果执行的是native方法，这个计数器的值为undefined。\n\n## 2.Java虚拟机栈\n栈是运行时的单位，而堆是存储的单位。\n\n即：栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪儿。\n\n作用：主管Java程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。\n\n它描述的是Java方法执行的线程内存模型，每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态连接、方法出口等信息，每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n> 在线程上执行的每一个方法都对应着一个栈桢\n\n假如执行A方法创建一个A栈帧，A栈帧入栈，A方法调用B方法，需要为B方法创建一个B栈帧，然后入栈，B方法执行到方法出口之后，B栈帧出栈，然后A方法执行到方法出口之后，A栈帧出栈，这就是方法执行过程。\n\n栈帧伴随着方法从创建到执行完成。\n\nJava虚拟机规范允许Java栈的大小是动态或者是固定不变的。\n- 如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将抛出一个StackOverflowError异常。\n- 如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个OutOfMemoryError异常。\n> 栈没有GC\n\n设置栈内存大小\n我们可以使用参数-Xss（stack size）选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。\n默认值：\nLinux/x64（64-bit）：1024KB\nmacOs（64-bit）：1024KB\n\nJVM直接对Java栈的操作只有两个，就是对栈桢的压栈和出栈，遵循先进后出原则。\n\n在一条活动线程中，一个时间点上，只会有一个活动的栈桢，即只有当前正在执行的方法的栈桢（栈顶栈桢）是有效的，这个栈桢被称为当前栈桢，与当前栈桢对应的方法就是当前方法，定义这个方法的类就是当前类\n\nJava方法有两种返回函数的方式，一种是正常的函数返回，使用return指令，另一种是抛出异常。不管使用哪种方式，都会导致栈桢被弹出.\n\n栈桢内部结构：\n### 局部变量表（Local Variables）\n\n局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，他不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。\n\n由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题。\n\n局部变量所需的容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。\n\n其中64位长度的long和double类型的数据会占用2个Slot，其余的数据类型只占用1个Slot，局部变量所需的内存空间在编译期间分配完成，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。\n注意：虚拟机栈的大小会变，因为不停的创建和销毁栈帧，还有别的操作都会改变虚拟机栈大小。\n\n局部变量表最基本的存储单元是Slot（变量槽），32位一个变量槽\n\nJVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中的指定局部变量值。（如果占两个槽，使用起始索引）\n\n补充：0槽位放this，所以从1开始\n\n注意：局部变量必须显式赋值\n\n1）boolean——1byte 0为false 非0为true \n2）byte——1 byte\n3）short——2 bytes\n4）int——4 bytes\n5）long——8 bytes\n6）float——4 bytes\n7）double——8 bytes\n8）char——2 bytes\n\n### 操作数栈（Operand Stack）\n在方法执行过程中，根据字节码指令，往栈中写入数据（ipush）或提取数据（iload），即入栈/出栈。\n\n注意：这里栈不是指栈桢，指的是操作数栈\n\n作用：用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。\n\n某些字节码指令值压入操作数栈，其余的字节码指令将操作数取出栈，使用它们后再把结果压入栈。\n\n### 动态连接（Dynamic Linking）\n\n### 方法返回地址（Return Address）\n存储调用该方法的程序计数器的值\n无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的程序计数器的值作为返回地址。而通过异常退出的，返回地址是要通过异常表来确定，栈桢中一般不会保存这部分信息。\n\n### 一些附加信息\n\n在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常（死循环递归）；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可以动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。\n\n> 递归死循环调用，会一直创建栈帧，从而导致栈内存溢出，假如我们不限制栈深度，无法申请到足够的内存就会抛出内存溢出\n\n方法中定义局部变量是否线程安全？\n- 内部定义内部消亡，是线程安全的。\n- 内部产生，但是没有在内部消亡，返回到方法外，这是线程不安全的。（逃逸）\n\n## 3.本地方法栈（线程私有）\n本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则为虚拟机使用到的Native方法服务，在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构没有强制规定，因此具体的虚拟机可以自由实现它，甚至有的虚拟机（Sun公司的HotSpot虚拟机）直接把本地方法栈和虚拟机栈合二为一，与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常\n\n## 4.Java堆\n在虚拟机启动时创建，其空间大小也就确定了，是JVM管理的最大一块内存空间（堆内存的大小可调节）。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。\n注意：这里不是所有的对象实例都分配在堆内存。\n\nJava堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”（Garbage Collected Heap），从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代，再细致一点的有Eden空间（伊甸园）、From Survivor（幸存者0区）空间、To Survivor（幸存者1区）空间等，从内存分配角度来看，线程共享的Java堆中可能划分多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），不过无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都仍然是对象实例，进一步划分目的是为了更好地回收内存，或者更快地分配内存。\n\n根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间，只要逻辑上连续即可，就像我们的磁盘空间一样，在实现时，既可以实现成固定大小的，也可以是可扩展的，不过目前主流的虚拟机都是按照可扩展的来实现的，通过-Xmx和-Xms控制，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常（OutOfMemoryError: Java Heap space）。\n\n-XX:SurvivorRatio，设置新生代中Eden和S0/S1空间的比例，默认-XX:SurvivorRatio=8，Eden:S0:S1=8:1:1，假设设置成-XX:SurvivorRatio=4，Eden:S0:S1=4:1:1\n总结：SurvivorRatio值就是设置Eden区的比例占多少，S0/S1相同\n\n-XX:NewRatio，配置年轻代与老年代堆结构的占比，默认-XX:NewRatio=2新生代占1，老年代占2，年轻代占整个堆的1/3，假如-XX:NewRatio=4新生代占1，老年代占4，年轻代占整个堆的1/5\n总结：NewRatio值就是设置老年代的占比，剩下的1给新生代\n\n（1）new的对象先放伊甸园区。此区有大小限制\n（2）当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃\n圾回收(Minor GC)， 将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区\n![在这里插入图片描述](https://img-blog.csdnimg.cn/df2c699f9c6d459a9c2e6114071b948b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n（3）然后将伊甸园中的剩余对象移动到幸存者0区\n![在这里插入图片描述](https://img-blog.csdnimg.cn/b15ee20ea3094315b6f7114af7071ce8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n（4）如果再次触发垃圾回收，【本次存活对象】 和 【上次幸存下来的放到幸存者0区的且本次没有被回收的对象】，都会被放到幸存者1区。\n\n（5）如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区（form/to）\n![在这里插入图片描述](https://img-blog.csdnimg.cn/6fbed23da6bc446aa5b1be7c98ff93ba.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n（6）啥时候能去养老区呢?可以设置次数。默认是15次。\n补充：可以设置参数: -XX:MaxTenuringThreshold=<N>进行设置。\n\n> 针对幸存者 S0，S1区总结：复制之后有交换，谁空谁是 to\n关于垃圾回收：频繁在新生区收集，很少在养老区收集，几乎不在永久区/元空间收集\n\n注意：Eden 区满时，会触发 Minor GC，此时会回收 Eden 区和幸存者区，但是幸存者区满了不会触发Minor GC，那怎么办？\n\n当Survivor空间不足以容纳一次 Minor GC之后存活的对象时，就需要依赖其他内存区域(实际上大多就是老年代) 进行分配担保(Handle Promotion)。 （Serial、ParNew等新生代收集器均采用这种策略来设计新生代的内存布局）（来源JVM深入理解虚拟机）\n\n内存的分配担保就好比我们去银行借款，如果我们信誉很好，在98%的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了，内存的分配担保也一样，如果另外一块Survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。这对虚拟机来说就是安全的。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/e1bcb02cc7d441f48527f9d636b29a94.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n如果Survivor 区中相同年龄的存活对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。\n理由：相同年龄对象占Survivor空间的一半，每次复制算法都要从form到to，非常耗时\n\n堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据\n\n为什么有TLAB（Thread Local Allocation Buffer）？\n- 由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的\n- 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。\n\n什么是TLAB（Thread Local Allocation Buffer）？\n- 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。\n- 多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略。\n- 据我所知所有OpenJDK衍生出来的JVM都提供了TLAB的设计。\n\n> ①尽管不是所有的对象实例都能够在TLAB中成功分配内存，但JVM确实是将TLAB作为内存分配的首选。\n②在程序中，开发人员可以通过选项“-Xx :UseTLAB” 设置是否开启TLAB空间。\n③默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%，当然我们可以通\n过选项“-XX:TLABWasteTargetPercent”设置TLAB空间所占用Eden空间的百分比大小。\n④一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用加锁机制确保数据操\n作的原子性，从而直接在Eden空间中分配内存。\n\n一个JVM实例只存在一个堆内存， 堆内存的大小是可以调节的。 类加载器读取了类文件后，需要把类、方法、常变量放到堆内存中，保存所有引用类型的真实信息，以方便执行器执行。\n堆内存逻辑上分为三部分：新生代+老年代+元数据（JDK8）\n新生代包含：伊甸园区、幸存0区、幸存1区\n\n\n堆：\n优点：运行时的数据区，可以动态的分配内存大小，生存期也不必事先告诉编译器，因为它是运行时动态分配内存空间，垃圾收集器会自动收走不再使用的数据\n缺点：运行时动态时分配内存空间，因此存取速度慢些\n\n栈：（线程私有）\n优点：存取速度比堆快，仅次于计算机里的寄存器，栈的数据可以共享。\n缺点：大小和生存期是确定的，缺乏灵活性。\n\n> 对象的引用存放在栈中，对象本身存放在堆中。\n\n## 5.方法区\n方法区(Method Area)是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息（类的版本、字段、方法、接口）、常量、静态变量、即时编译器编译后的代码缓存等数据。虽然《Java虚拟机规范》中把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫作“非堆”(Non Heap)，目的是与Java堆区分开来。\n\n例如java核心java，会加载到方法区\n\n（1）栈、堆、方法区关系\n![在这里插入图片描述](https://img-blog.csdnimg.cn/ccb169cc45134e9393d5bf46b6d207dc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n虽然《Java虚拟机规范》中把方法区描述为堆的一个逻辑部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。”但对于HotSpot JVM而言，方法区还有一个别名叫做Non-Heap (非堆)，目的就是要和堆分开。\n\n（2）方法区基本理解：\n- 方法区(Method Area) 与Java堆一样，是各个线程共享的内存区域。\n- 方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。\n- 方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展\n- 方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区\n溢出，虚拟机同样会抛出内存溢出错误: java.lang .OutOfMemoryError: PermGen space 或者java.lang.OutOfMemoryError: Metaspace。\n- 关闭JVM就会释放这个区域的内存。\n\n（3）Hotspot中方法区的演进\n在JDK7及之前，习惯上把方法区称为永久代。JDK8开始，使用元空间取代了永久代\n补充：可以把方法区理解为Java接口，永久代是Java接口实现类\n\n本质上，方法区和永久代并不等价，仅是对HotSpot而言。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEA JRockit / IBM J9 中不存在永久代的概念。\n\n现在看来，当年使用永久代，不是好的idea，导致Java程序更容易OOM（超过-XX:MaxPermSize上限）\n\n到了JDK8时，HotSpot终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替\n\n元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存。\n\n根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常（OutOfMemoryError: Metaspace）\n\n> 当Oracle收购BEA获得了JRockit的所有权后，准备把JRockit中的优秀功能，譬如Java Mission Control管理工具，移植到HotSpot虚拟机时，但因为两者对方法区实现的差异而面临诸多困难。考虑到HotSpot未来的发展，在JDK 6的时候HotSpot开发团队就有放弃永久代，逐步改为采用本地内存(Native Memory)来实现方法区的计划了，到了JDK 7的HotSpot,已经把原本放在永久代的字符串常量池、静态变量等移出，而到了JDK8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间(Metaspace) 来代替，把JDK 7中永久代还剩余的内容(主要是类型信息)全部移到元空间中。\n\n（4）设置方法区大小\n方法区的大小不必是固定的，JVM可以根据应用的需要动态调整\n①JDK7及之前：\n通过-XX:PermSize来设置永久代初始分配空间。默认值是20.75M\n-XX:MaxPermSize来设置永久代最大可分配空间。32位机器默认是64M，64机器默认是82M\n当JVM加载的类信息容量超过了这个值，会报异常OutOfMemoryError: PermGenspace\n②JDK8及以后：\n元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定，替代上述原有的两个参数\n\n默认值依赖于平台。Windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是-1，即没有限制\n补充：-XXMaxMetaspaceSize一般不会改\n\n与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError: Metaspace\n \n-XX:MetaspaceSize: 设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的-XX:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类( 即这些类对应的类加载器不再存活) ,然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。\n\n如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX :MetaspaceSize设置为一个相对较高的值。\n\nJDK1.6及之前：有永久代，静态变量存放在永久代上\nJDK1.7：有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中\nJDK1.8及之后：无永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆\n\n## 6.运行时常量池\n运行时常量池（Runtime Constant Pool）是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。\n\nJava虚拟机对Class文件每一部分（自然也包括常量池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的需求才会被虚拟机认可、装载和执行，但对于运行时常量池，Java虚拟机规范没有做任何细节的要求，不同的提供商实现的虚拟机可以按照自己的需要来实现这个内存区域，不过，一般来说，除了保持Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。\n补充：String.intern()：用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后返回引用。\n案例：String a = “abc”; String b = new String(‘abc’), a==b.intern();//true\n\n既然运行时常量池也是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。\n\n## 7.直接内存\n直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现。\n\nJDK1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作，这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n\n显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制，服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常\n\n# 三、对象内存布局\n在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/ddb16d030d3740aaa316cd002930ac80.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n## 1.对象头\n对象头，HotSpot虚拟机的对象头包括两部分信息。\n- 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，\n- 另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身，\n\n另外，如果对象是一个Java数组，那么对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/866fa60d6c9646839a115c54e6e4724f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_19,color_FFFFFF,t_70,g_se,x_16)\n\n\n## 2.数据实例\n数据实例：是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类定义的，都需要记录，这部分的存储顺序会受到虚拟机分配策略参数和字段在Java源码中的定义顺序的影响，HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers），从策略分配中可以看出，相同宽度的字段总是被分配到一起，在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前，如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量可能会插入到父类的空隙之中。\n\n## 3.对齐填充\n对齐填充：对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用，由于HotSpot VM的自动内存管理系统要求对象起始地址是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍，而对象头部分正好是8字节的倍数，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。\n\n# 四、对象访问定位\nJVM是如何通过栈桢中的对象引用访问到其内部的对象实例的呢？\n![在这里插入图片描述](https://img-blog.csdnimg.cn/a0581c8a362545d789d29b774a3d2121.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n\n建立对象是为了使用对象，我们的Java程序需要通过栈的reference数据来操作堆上的具体对象，由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的，目前主流的访问方式有使用句柄和直接指针两种\n\n对象访问的两种方式：\n（1）句柄访问\n如果使用句柄访问的话，那么Java堆中将划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/de22b17572d1476c9320a049058c148e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n\n补充：使用句柄方式需要保存到对象实例数据的指针和到对象类型数据的指针。\n\n（2）直接指针\n\n如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/e40c933a241e42919fa69a753578a173.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n> 使用直接指针方式，需要保存到对象类型数据的指针就行。\n\n这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本，HotSpot使用的就是直接指针访问。\n\n# 五、如何判定对象为垃圾对象？\n## 1.引用计数算法\n给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1，当引用失效时，计数器值减1，任何时刻计数器为0的对象就是不可能再被使用的。\n引用失效：把对象引用赋值null\n\n优点: 引用计数算法的实现简单，判断效率也很高，在大部分情况下它都是一个不错的算法\n\n缺点:\n- 它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。\n- 每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。\n- 它很难解决对象之间相互循环引用的问题，因此主流的Java虚拟机里没有选用引用计数算法来管理内存。\n\n举例：假设p.next = A, A.next = B, B.next=C，C.next = A，此时计数A是2，B是1，C是1，然后p.next=null，此时计数A是1，B是1，C是，此时会导致A、B、C不会被回收\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/f0155de2c8984bfa97b4888645e37b61.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n垃圾回收详细日志信息：-XX:+PrintGCDetails\n```java\npublic class ReferenceCoatingGC {\n    public Object instance = null;\n    private static final int _1MB = 1024 * 1024;\n 	\n    /**\n      * 这个成员属性的唯一意义就是占内存，以便能在GC日志中看清楚是否被回收过\n      */\n    private byte[] bigSize = new byte[2 * _1MB];\n    public static void testGC() {\n        ReferenceCoatingGC objA = new ReferenceCoatingGC();\n        ReferenceCoatingGC objB = new ReferenceCoatingGC();\n        objA.instance = objB;\n        objB.instance = objA;\n        objA = null;\n        objB = null;\n        // 假设在这行发生GC，objA和objB\n        System.gc();\n    }\n 	\n    public static void main(String[] args) {\n        testGC();\n    }\n}\n```\n从上面运行结果可以看出，虚拟机并没有因为两个对象互相引用就不回收它们，这也从侧面说明虚拟机并不是通过引用计数算法来判断对象是否存活的。\n\n## 2.可达性分析算法\n\n根节点枚举：所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，即便号称停顿时间可控或几乎不会发生停顿的CMS、G1等收集器，在这一步骤也会暂停用户线程\n\n执行效率比引用计算法低一点，但是可以解决循环引用问题\n\n这个算法的基本思路就是通过一系列的称为‘GC Roots’的对象作为起始点，从这些节点开始向下搜索，搜索所走的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。如图，对象object5、object6、object7虽然互相有关联，但是它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。 \n![在这里插入图片描述](https://img-blog.csdnimg.cn/146711ad506e43b7a8ad8e70fcd94183.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n> 假如给object1赋值null，那么object1、object12、object3、object4全部变为可回收对象\n\n总结：基本思路就是通过一系列名为”GC Roots\"的对象作为起始点，从这个被称为GC Roots的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。也即给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被\n遍历到的(可到达的)对象就被判定为存活；没有被遍历到的就自然被判定为死亡。\n\nJava中，可作为GC Roots的对象包括下面几种：\n1）虚拟机栈（栈帧中的本地变量表）中引用的对象（t1）\n2）方法区中类静态属性引用的对象（t2）\n3）方法区中常量引用的对象（t3）\n4）本地方法栈中JNI（即一般说的Native方法）引用的对象\n```java\npublic class GCRootDemo {\n    \n    private static GCRootDemo t2 = new GCRootDemo();\n    \n    private static final GCRootDemo t3 = new GCRootDemo();\n    \n    public static void main(String[] args) {\n        m1();\n    }\n\n    private static void m1() {\n        GCRootDemo t1 = new GCRootDemo();\n        System.gc();\n        System.out.println(\"第一次GC完成\");\n    }\n}\n```\n\n# 六、引用\n无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判断对象是否存活都与‘引用’有关，在JDK1.2以前，Java 中的引用的定义很传统，如果reference类型的数据中存储数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用，这种定义很纯粹，但是太过狭隘，一个对象在这种定义下就只有被引用或者没有被引用两种状态了，对于如何描述一些‘食之无味，弃之可惜’的对象就显得无能为力。我们希望能描述这样一类对象：当存储空间还足够时，则能保留在内存之中；如果存储空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象，很多系统的缓存功能都符合这样的应用场景。\n\n在JDK1.2后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，这4种引用强度依次逐渐减弱。\n\n- 强引用：强引用就是指在程序代码之中普遍存在的，类似Object obj = new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。\n- 软引用：软引用是用来描述一些还有用但并非必要的对象，对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常，在JDK1.2之后，提供了SoftReference类来实现软引用。\n- 弱引用：弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前，当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象，在JDK1.2后，提供了WeakReference类来实现弱引用\n- 虚引用：虚引用也称为幽灵或者幻影引用，它是最弱的一种引用关系，一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例，为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知，在JDK1.2之后，提供PhantomReference类来实现虚引用\n\n生存还是死亡：即使在可达性分析算法中不可达的对象，也并非是’非死不可’的，这时候它们暂时处于‘缓刑’阶段，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行可达性分析后发现没有GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法，当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为‘没有必要执行’。\n\n如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列中，并在稍后由一个由虚拟机自动建立、低优先级的Finalizer线程去执行它，这里所谓的’执行’是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模的标记，如果对象在finalize()中成功拯救自己-------只要重新与引用链上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那么在第二次标记时它将被移除‘即将回收’的集合，如果对象这时候还没有逃脱，那基本上它就真的被回收了。\n\n总结：对象可以在被GC时自我拯救，但是这种自救的机会只有一次，因为一个对象的finalize()方法最多只会被系统自动调用一次，不建议使用这种方法拯救对象，它的运行代价高昂，不确定性大，无法保证各个对象调用顺序。\n```java\npublic class FinalizeEscapeGC {\n    public static FinalizeEscapeGC SAVE_HOOK = null;\n 	\n    public void isAlive() {\n 	System.out.println(\"yes,i am still alive\");\n    }\n 	\n    @Override\n    protected void finalize() throws Throwable {\n 	super.finalize();\n 	System.out.println(\"finalize method executed!\");\n 	FinalizeEscapeGC.SAVE_HOOK = this;\n    }\n 	\n    public static void main(String[] args) {\n 	SAVE_HOOK = new FinalizeEscapeGC();\n 		\n 	// 对象第一次成功拯救自己\n 	SAVE_HOOK = null;\n 	System.gc();\n 	try {\n 	    // 因为finalize方法优先级低，所以暂停0.5秒等待它\n 	    Thread.sleep(500);\n 	    if(null != SAVE_HOOK) {\n 		SAVE_HOOK.isAlive();\n 	    }else {\n 		System.out.println(\"no i am dead\");\n 	    }\n 	} catch (InterruptedException e) {\n 	    e.printStackTrace();\n 	}\n 		\n    // 对象第二次自救，自救失败\n 	SAVE_HOOK = null;\n 	System.gc();\n 	try {\n 	    // 因为finalize方法优先级低，所以暂停0.5秒等待它\n 	    Thread.sleep(500);\n 	    if(null != SAVE_HOOK) {\n 		SAVE_HOOK.isAlive();\n 	    }else {\n 		System.out.println(\"no i am dead\");\n 	    }\n        } catch (InterruptedException e) {\n 	    e.printStackTrace();\n 	}\n    }\n}\n```\n执行结果：\nfinalize method executed!\nyes,i am still alive\nno i am dead\n\n# 七、如何回收垃圾对象？\n## 1.垃圾收集算法\n内存回收的方法论，垃圾收集器是方法论的落地实现\n\nJVM中比较常见的三种垃圾收集算法：\n### 标记-清除算法\n\n标记无用对象，然后进行清除回收。\n\n标记-清除算法（Mark-Sweep）是一种常见的基础垃圾收集算法，它将垃圾收集分为两个阶段：\n- 标记阶段：标记出可以回收的对象。\n- 清除阶段：回收被标记的对象所占用的空间。\n\n标记-清除算法之所以是基础的，是因为后面讲到的垃圾收集算法都是在此算法的基础上进行改进的。\n\n优点：实现简单，不需要对象进行移动。\n\n缺点：标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。\n- 效率问题，标记和清除两个过程的执行效率都随对象数量增长而降低（标记时通过GC Root递归遍历可达对象，清除时需要遍历所有堆空间的对象）。\n- 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。\n- 这种方式清理出来的空闲内存是不连续的，产生内存碎片。需要维护一个空闲列表。\n\n\n标记-清除算法的执行过程如图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/93b278c117574a06aab2377eaf4b3bc4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，在找合适内存空间的时候也比较耗时。\n\n>需要暂停用户线程，执行标记和清除操作\n\n### 复制算法\n为了解决标记-清除算法的效率不高的问题，产生了复制算法。它把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾收集时，遍历当前使用的区域，把存活对象复制到另外一个区域中，最后将当前使用的区域的可回收的对象进行回收。\n\n复制算法的执行过程如图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/b989f3c6251d42858307a615517b1c53.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n现在的商业虚拟机都采用这种收集算法来回收新生代，IBM公司的专门研究表明，新生代中的对象98%是’朝生暮死’的，所以不需要按照1:1比例来划分内存空间，回收的具体做法是把新生代分为一块较大的Eden空间和两块较小的Survivor空间， 每次分配内存只使用Eden和其中一块Survivor。发生垃圾收集时，将Eden和Survivor中仍然存活的对象一次性 复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot 虚拟机默认Eden和Survivor的大小比例是 8:1，也即每次新生代中可用内存空间为 整个新生代容量的90% (Eden的80%加上 一个Survivor的10%)，只有一个 Survivor空间，即10%的新生代是会被 “浪费”的。当然，98%的对象可被回收仅仅是“普通场景”下测得的数据，任何人都没有办法百分百保证每次回收都只有不多于10%的对象存活，因此这种回收方式还有一个充当罕见情况的“逃生门” 的安全设计，当Survivor空间不足以容纳一次 Minor GC之后存活的对象时，就需要依赖其他内存区域(实际上大多就是老年代) 进行分配担保(Handle Promotion)。 （Serial、ParNew等新生代收集器均采用这种策略来设计新生代的内存布局）\n\n内存的分配担保就好比我们去银行借款，如果我们信誉很好，在98%的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了，内存的分配担保也一样，如果另外一块Survivor空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。这对虚拟机来说就是安全的。\n\n总结：它将堆分为新生代和老年代，新生代又分为Eden空间和两块Survivor空间，它们的比例大概是8: 1: 1。 新生代中的对象大多存活率不高，所以我们一般采用复制算法。每次使用Eden 空间和其中的一块Survivor空间，当进行回收时， 将该两块空间中还存活的对象复制到另一块 Survivor空间中，每进行一次Minor GC对象的年龄就会加1, 默认达到15就可以进入老年代 (数值可以自己用调优参数设定)。Survivor区存放不下的对象，因为每次Minor GC的时候会将Eden区和一个from区的存存活对象放入to区，所以当to区装不下的对象时就会进入老年代\n\n优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。\n\n缺点：\n- 在对象存活率较高时，复制的对象很多时，效率大大降低\n- 内存缩小了一半，需要额外空间做分配担保（老年代）\n\n### 标记-整理算法\n在新生代中可以使用复制算法，但是在老年代就不能选择复制算法了，因为老年代的对象存活率会较高，这样会有较多的复制操作，导致效率变低。标记-清除算法可以应用在老年代中，但是它效率不高，在内存回收后容易产生大量内存碎片。因此就出现了一种标记-整理算法（Mark-Compact）算法，与标记-整理算法不同的是，在标记可回收的对象后将所有存活的对象压缩到内存的一端，使他们紧凑的排列在一起，然后对端边界以外的内存进行回收。回收后，已用和未用的内存都各自一边。\n\n优点：解决了标记-清理算法存在的内存碎片问题。\n\n缺点：仍需要进行局部对象移动，一定程度上降低了效率。\n\n“标记- 整理”算法的执行过程如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/e363fe814c7c491fb2554ce4d23f1f1f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n## 2.垃圾收集算法\n\n### Serial收集器\n在JDK1.3之前，它是虚拟机新生代收集的唯一选择，Serial 是一个单线程的收集器， 它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。\n\nSerial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/33130f747c944cde9ac4f2d1632a8921.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n-XX:UseSerialGC，开启后会使用Serial（Young区用）+ Serial Old（Old区用）的收集器组合\n\n### ParNew收集器\nParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样， ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。\n\nParNew 收集器默认开启和 CPU 数目相同的线程数，可以通过-XX:ParallelGCThreads 参数来限制垃圾收集器的线程数。\n\nParNew 虽然是除了多线程外和Serial 收集器几乎完全一样，但是ParNew垃圾收集器是很多 Java虚拟机运行在 Server 模式下新生代的默认垃圾收集器。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/1457365c8c1e4c8985ff1e88b98b6876.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n并行和并发都是并发编程中的专业名词，在谈论垃圾收集器的上下文语境中，它们可\n以理解为:\n①并行(Parallel) :并行描述的是多条垃圾收集器线程之间的关系，说明同一时间有多条这样的线程在协同工作，通常默认此时用户线程是处于等待状态。（指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态）\n②并发(Concurrent) :并发描述的是垃圾收集器线程与用户线程之间的关系，说明同一时间垃圾收集器线程与用户线程都在运行。由于用户线程并未被冻结，所以程序仍然能响应服务请求，但由于垃圾收集器线程占用了一部分系统资源，此时应用程序的处理的吞吐量将受到一定影响。（指用户线程与垃圾收集线程同时执行，但不一定是并行的，可能会交替执行，用户程序在继续运行，而垃圾收集程序运行于另一个CPU上）\n\n### Parallel Scavenge收集器\nParallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器， 它重点关注的是程序达到一个可控制的吞吐量（Thoughput， CPU 用于运行用户代码的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。 自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/15112a24a2974cc89e2bc8c718373d2a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n-XX:ParallelGCThreads：设置年轻代并行收集器的线程数。\n\n-XX:UseParallelGC、-XX:UseParallelOldGC可互相激活，不管配置哪个，两个都会开启，ParallelGC采用复制算法，ParallelOldGC采用标记-整理算法\n\nJDK1.8 默认收集器： Parallel Scavenge (新生代) 和 Parallel Old (老年代)\n\n### Serial Old收集器\n\nSerial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用’标记-整理’算法，这个收集器的主要意义也是在给Client模式下的虚拟机使用，如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种就是作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/93a638aed4c6431ba605b035bc04960c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n### Parallel Old收集器\nParallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于’标记-整理’算法实现，这个收集器是在JDK1.6中才开始提供，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态，原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器外别无选择，由于老年代Serial Old收集器在服务端应用性能上的‘拖累’，使用了Parallel Scavenge收集器也未必在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件条件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS组合’给力’。\n\n直到Parallel Old收集器出现后，’吞吐量优先’收集器终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器，Parallel Old收集器的工作过程如图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/8fa8cfaaeb764c3bb46d9c2fe6ed82a5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n### CMS收集器\nCMS (Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网网站或者基于浏览器的B/S系统的服务端上，这类应用通常都会较为关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验。CMS收集器就非常符合这类应用的需求。\n\n从名字(包含“Mark Sweep”)上就可以看出CMS收集器是基于标记-清除算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为四个步骤，包括:\n![在这里插入图片描述](https://img-blog.csdnimg.cn/04775431d3944ce185e1127af8cc1374.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)①初始标记（CMS initial mark）\n②并发标记（CMS concurrent mark）\n③重新标记（CMS remark）\n④并发清除（CMS concurrent sweep）\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快；并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行；而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短；最后是并发清除阶段，清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。\n\n由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过图3-11可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的阶段。\n\n> safepoint是还原点\n\n优点：并发收集低停顿\n\nCMS是一款优秀的收集器，它最主要优点在名字上已经体现出来:并发收集、低停顿，一些官方公开文档里面也称之为“并发低停顿收集器”(Concurrent Low Pause Collector) 。CMS收集器是HotSpot虚拟机追求低停顿的第一次成功尝试，但是它还远达不到完美的程度，至少有以下三个明显的缺点:\n①首先，CMS收集器对处理器资源非常敏感。事实上，面向并发设计的程序都对处理器资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程(或者说处理器的计算能力)而导致应用程序变慢，降低总吞吐量。CMS默认启动的回收线程数是(处理器核心数量+3) /4，也就是说，如果处理器核心数在四个或以上，并发回收时垃圾收集线程只占用不超过25%的处理器运算资源，并且会随着处理器核心数量的增加而下降。但是当处理器核心数量不足四个时，CMS对用户程序的影响就可能变得很大。如果应用本来的处理器负载就很高，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然大幅降低。为了缓解这种情况，虚拟机提供了一种称为“增量式并发收集器’(Incremental Concurrent Mark Sweep / iCMS)的CMS收集器变种，所做的事情和以前单核处理器年代PC机操作系统靠抢占式多任务来模拟多核并行多任务的思想一样，是在并发标记、清理的时候让收集器线程、用户线程交替运行，尽量减少垃圾收集线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得较少一些，直观感受是速度变慢的时间更多了，但速度下降幅度就没有那么明显。实践证明增量式的CMS收集器效果很一般，从JDK 7开始，iCMS模式已经被声明为“deprecated”,即已过时不再提倡用户使用，到JDK 9发布后iCMS模式被完全废弃。\n\n②然后，由于CMS收集器无法处理“浮动垃圾”(Floating Garbage)，有可能出现“Concurrent Mode Failure”失败进而导致另一次完全 “Stop The World”的Full GC的产生。在CMS的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。同样也是由于在垃圾收集阶段用户线程还需要持续运行，那就还需要预留足够内存空间提供给用户线程使用，因此CMS收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集，必须预留一部分空间供并发收集时的程序运作使用。在JDK 5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在实际应用中老年代增长并不是太快，可以适当调高参数-XX: CMSInitiatingOccupancyFraction的值来提高CMS的触发百分比，降低内存回收频率，获取更好的性能。到了JDK 6时，CMS收集器的启动阈值就已经默认提升至92%。但这又会更容易面临另一种风险:要是CMS运行期间预留的内存无法满足程序分配新对象的需\n要，就会出现一次“并发失败”(Concurrent Mode Failure) ，这时候虚拟机将不得不启动后备预案:冻结用户线程的执行，临时启用Serial Old收集器来重新进行老年代的垃圾收集，但这样停顿时间就很长了。所以参数-XX: CMSInitiatingOccupancyFraction设置得太高将会很容易导致大量的并发失败产生，性能反而降低，用户应在生产环境中根据实际应用情况来权衡设置。\n\n③还有最后一个缺点，在本节的开头曾提到，CMS是一款基于 “标记-清除”算法实现的收集器，如果读者对前面这部分介绍还有印象的话，就可能想到这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。为了解决这个问题，CMS收集器提供了一个XX: +UseCMSCompactAtFullCollection开关参数(默认是开启的，此参数从JDK 9开始废弃)，用于在CMS收集器不得不进行Full GC时开启内存碎片的合并整理过程，由于这个内存整理必须移动存活对象，(在 Shenandoah和ZGC出现前)是无法并发的。这样空间碎片问题是解决了，但停顿时间又会变长，因此虚拟机设计者们还提供了另外一个参数- XX: CMSFullGCsBeforeCompaction (此参数从JDK 9开始废弃)，这个参数的作用是要求CMS收集器在执行过若干次(数量由参数值决定)不整理空间的Full GC之后，下一次进入Full GC前会先进行碎片整理(默认值为0，表示每次进入Full GC时都进行碎片整理)。\n\n适用场景：CMS非常适合堆内存大、CPU核数多的服务器端应用，也是G1出现之前大型应用的首选收集器\n\n开启该收集器的JVM参数：-XX:+UseConcMarkSweepGC开启该参数后会自动将 -XX:+UseParNewGC打开\n\n开启该参数后，使用ParNew(Young区用) + CMS(Old区用) + Serial Old的收集器组合，Serial Old将作为CMS出错的后备收集器\n\n### G1收集器\nG1是一款主要面向服务端应用的垃圾收集器。HotSpot开发团队最初赋予它的期望是(在比较长期的)未来可以替换掉JDK 5中发布的CMS收集器。现在这个期望目标已经实现过半了，JDK 9发布之日,G1宣告取代Parallel Scavenge加Parallel Old组合，成为服务端模式下的默认垃圾收集器，而CMS则沦落至被声明为不推荐使用(Deprecate) 的收集器。如果对JDK 9及以上版本的HotSpot虚拟机使用参数-XX: +UseConcMarkSweepGC来开启CMS收集器的话，用户会收到一个警告信息，提示CMS未来将会被废弃。\n\n但作为一款曾被广泛运用过的收集器，经过多个版本的开发迭代后，CMS (以及之前几款收集器)的代码与HotSpot的内存管理、执行、编译、监控等子系统都有千丝万缕的联系，这是历史原因导致的，并不符合职责分离的设计原则。为此，规划JDK 10功能目标时，HotSpot虛拟机提出了“统一垃圾收集器接口”，将内存回收的“行为”与“实现”进行分离，CMS以及其他收集器都重构成基于这套接口的一种实现。以此为基础，日后要移除或者加入某一款收集器，都会变得容易许多，风险也可以控制，这算是在为CMS退出历史舞台铺下最后的道路了。\n\n作为CMS收集器的替代者和继承人，设计者们希望做出一款能够建立起“停顿时间模型”(Pause Prediction Model)的收集器，停顿时间模型的意思是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标，这几乎已经是实时Java (RTSJ) 的中软实时垃圾收集器特征了。\n\n那具体要怎么做才能实现这个目标呢?首先要有一个思想上的改变，在G1收集器出现之前的所有其他收集器，包括CMS在内，垃圾收集的目标范围要么是整个新生代(Minor GC)，要么就是整个老年代(Major GC)，再要么就是整个Java堆(Full GC)。而G1跳出了这个樊笼，它可以面向堆内存任何部分来组成回收集(Collection Set，一般简称CSet) 进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。\n\nG1开创的基于Region的堆内存布局是它能够实现这个目标的关键。虽然G1也仍是遵循分代收集理论设计的，但其堆内存的布局与其他收集器有非常明显的差异:G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域(Region) ，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间， 或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。\n\n核心思想是将整个堆内存区域分成大小相同的子区域(Region)，在JVM启动时会自动设置这些子区域的大小，在堆的使用上，G1并不要求对象的存储一定是物理上连续的只要逻辑上连续即可，每个分区也不会固定地为某个代服务，可以按需在年轻代和老年代之间切换。启动时可以通过参数-XX:G1HeapRegionSize=n可指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区。\n\n大小范围在1MB~32MB，最多能设置2048个区域，也即能够支持的最大内存为: 32MB * 2048 = 65536MB = 64G内存\n\nRegion中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围为1MB ~ 32MB，且应为2的N次幂。而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来进行看待，如图3-12所示。\n\n虽然G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，它们都是一系列区域(不需要连续)的动态集合。G1收集器之所以能建立可预测的停顿时间模型，是因为它将Region作为单次回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍，这样可以有计划地避免在整个Java堆中进行全区域的垃圾收集。更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间(使用参数-XX:MaxGCPauseMillis指定，默认值是200毫秒)，优先处理回收价值收益最大的那些Region，这也就是“Garbage First”名字的由来。这种使用Region划分内存空间，以及具有优先级的区域回收方式，保证了G1收集器在有限的时间内获取尽可能高的收集效率。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2532fe55f77f45828ba70fbb3de0eb0f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n针对Eden区进行收集，Eden区耗尽后会被触发,主要是小区域收集+形成连续的内存块，避免内存碎片\n*Eden区的数据移动到Survivor区，假如出现Survivor区空间不够，Eden区数据会部会晋升到Old区\n*假如出现Survivor区空间不够，Survivor区的数据移动到新的Survivor区，部会数据晋升到Old区\n*最后Eden区收拾干净了，GC结束，用户的应用程序继续执行。\n\nG1将堆内存“化整为零”的“解题思路”，看起来似乎没有太多令人惊讶之处，也完全不难理解，但其中的实现细节可是远远没有想象中那么简单，否则就不会从2004年Sun实验室发表第一篇关于G1的论文后一直拖到2012年4月JDK 7 Update4发布，用将近10年时间才倒腾出能够商用的G1收集器来。G1收集器至少有(不限于)以下这些关键的细节问题需要\n妥善解决:\n①譬如，将Java堆分成多个独立Region后，Region 里面存在的跨Region引用对象如何解决?使用记忆集避免全堆作为GC Roots扫描，但在G1收集器上记忆集的应用其实要复杂很多，它的每个Region都维护有自己的记忆集，这些记忆集会记录下别的Region指向自己的指针，并标记这些指针分别在哪些卡页的范围之内。G1的记忆集在存储结构的本质上是一种哈希表，Key是别的Region的起始地址，Value是一个集合，里面存储的元素是卡表的索引号。这种“双向”的卡表结构(卡表是“我指向谁”，这种结构还记录了“谁指向我”)比原来的卡表实现起来更复杂，同时由于Region数量比传统收集器的分代数量明显要多得多，因此G1收集器要比其他的传统垃圾收集器有着更高的内存占用负担。根据经验，G1至少要耗费大约相当于Java堆容量10%至20%的额外内存来维持收集器工作。\n\n②譬如，在并发标记阶段如何保证收集线程与用户线程互不干扰地运行?这里首先要解决的是用户线程改变对象引用关系时，必须保证其不能打破原本的对象图结构，导致标记结果出现错误：CMS收集器采用增量更新算法实现，而G1收集器则是通过原始快照(SATB)算法来实现的。此外，垃圾收集对用户线程的影响还体现在回收过程中新创建对象的内存分配上，程序要继续运行就肯定会持续有新对象被创建，G1为每一个Region设计了两个名为TAMS (Top at Mark Start)的指针，把Region中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上。G1收集器默认在这个地址以上的对象是被隐式标记过的，即默认它们是存活的，不纳入回收范围。与CMS中“Concurrent Mode Failure” 失败会导致Full GC类似，如果内存回收的速度赶不上内存分配的速度，G1收集器也要被迫冻结用户线程执行，导致Full GC而产生长时间“StopThe World”。\n\n③譬如，怎样建立起可靠的停顿预测模型?用户通过-XX: MaxGCPauseMillis参数指定的停顿时间只意味着垃圾收集发生之前的期望值，但G1收集器要怎么做才能满足用户的期望呢? G1收集器的停顿预测模型是以衰减均值(Decaying Average)为理论基础来实现的，在垃圾收集过程中，G1收集器会记录每个Region的回收耗时、每个Region记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息。这里强调的“衰减平均值”是指它会比普通的平均值更容易受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。换句话说，Region的统计状态越新越能决定其回收的价值。然后通过这些信息预测现在开始回收的话，由哪些Region组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益。\n\n如果我们不去计算用户线程运行过程中的动作(如使用写屏障维护记忆集的操作)，G1收集器的运作过程大致可划分为以下四个步骤:\n1）初始标记(Initial Marking) :仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际并没有额外的停顿。\n\n2）并发标记(Concurrent Marking) :从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理SATB记录下的在并发时有引用变动的对象。\n\n3）最终标记(Final Marking) :对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。\n\n4）筛选回收(Live Data Counting and Evacuation) :负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。\n\n从上述阶段的描述可以看出，G1收集器除了并发标记外，其余阶段也是要完全暂停用户线程的，换言之，它并非纯粹地追求低延迟，官方给它设定的目标是在延迟可控的情况下获得尽可能高的吞吐量,所以才能担当起“全功能收集器”的重任与期望。\n\n从Oracle官方透露出来的信息可获知，回收阶段(Evacuation) 其实本也有想过设计成与用户程序一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回收一部分Region, 停顿时间是用户可控制的，所以并不迫切去实现，而选择把这个特性放到了G1之后出现的低延迟垃圾收集器(即ZGC) 中。另外，还考虑到G1不是仅仅面向低延迟，停顿用户线程能够最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择了完全暂停用户线程的实现方案。通过图3-13可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/014858a9a6a14aa4ae9902ea3ba8edce.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n毫无疑问，可以由用户指定期望的停顿时间是G1收集器很强大的一个功能，设置不同的期望停顿时间，可使得G1在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。不过，这里设置的“期望值”必须是符合实际的，不能异想天开，毕竟G1是要冻结用户线程来复制对象的，这个停顿时间再怎么低也得有个限度。它默认的停顿目标为两百毫秒，一般来说，回收阶段占到几十到一百甚至接近两百毫秒都很正常，但如果我们把停顿时间调得:\n非常低，譬如设置为二十毫秒，很可能出现的结果就是由于停顿目标时间太短，导致每次选出来的回收集只占堆内存很小的一部分，收集器收集的速度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间，但应用运行时间一长就不行了，最终占满堆引发Full GC反而降低性能，所以通常把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的。\n\n从G1开始，最先进的垃圾收集器的设计导向都不约而同地变为追求能够应付应用的内存分配速率(Allocation Rate)，而不追求一次把整个Java堆全部清理干净。这样，应用在分配，同时收集器在收集，只要收集的速度能跟得上对象分配的速度，那一切就能运作得很完美。这种新的收集器设计思路从工程实现上看是从G1开始兴起的，所以说G1是收集器技术发展的一个里程碑。\n\nG1收集器常会被拿来与CMS收集器互相比较，毕竟它们都非常关注停顿时间的控制，官方资料中将它们两个并称为“The Mostly Concurrent Collectors”在未来，G1收集器最终还\n是要取代CMS的，而当下它们两者并存的时间里，分个高低优劣就无可避免。\n\n相比CMS，G1的优点有很多，暂且不论可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集这些创新性设计带来的红利，单从最传统的算法理论上看，G1也更有发展潜力。与CMS的“标记-清除”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器，但从局部(两个Region之间)上看又是基于“标记-复制”算法实现，无论如何，这两\n种算法都意味着G1运作期间不会产生内存空间碎片，垃圾收集完成之后能提供规整的可用内存。这种特性有利于程序长时间运行，在程序为大对象分配内存时不容易因无法找到连续内存空间而提前触发下一次收集。\n\n不过，G1相对 于CMS仍然不是占全方位、压倒性优势的，从它出现几年仍不能在所有应用场景中代替CMS就可以得知这个结论。比起CMS，G1的弱项也可以列举出不少，如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用(Footprint)还是程序运行时的额外执行负载(Overload) 都要比CMS要高。就内存占用来说，虽然G1和CMS都使用卡表来处理跨代指针，但G1的卡表实现更为复杂，而且堆中每个Region，无论扮演的是新生代还是老年代角色，都必须有一份卡表，这导致G1的记忆集(和其他内存消耗)可能会占整个堆容量的20%乃至更多的内存空间;相比起来CMS的卡表就相当简单，只有唯一一份，而且只需要处理老年代到新生代的引用，反过来则不需要，由于新生代的对象具有朝生夕灭的不稳定性，引用变化频繁，能省下这个区域的维护开销是很划算的。\n\n在执行负载的角度上，同样由于两个收集器各自的细节实现特点导致了用户程序运行时的负载会有不同，譬如它们都使用到写屏障，CMS用写后屏障来更新维护卡表;而G1除了使用写后屏障来进行同样的(由于G1的卡表结构复杂，其实是更烦琐的)卡表维护操作外，为了实现原始快照搜索(SATB) 算法，还需要使用写前屏障来跟踪并发时的指针变化情况。相比起增量更新算法，原始快照搜索能够减少并发标记和重新标记阶段的消耗，避免CMS那样在最终标记阶段停顿时间过长的缺点，但是在用户程序运行过程中确实会产生由跟踪引用变化带来的额外负担。由于G1对写屏障的复杂操作要比CMS消耗更多的运算资源，所以CMS的写屏障实现是直接的同步操作，而G1就不得不将其实现为类似于消息队列的结构，把写前屏障和写后屏障中要做的事情都放到队列里，然后再异步处理。\n\n以上的优缺点对比仅仅是针对G1和CMS两款垃圾收集器单独某方面的实现细节的定性分析，通常我们说哪款收集器要更好、要好上多少，往往是针对具体场景才能做的定量比较。按照笔者的实践经验，目前在小内存应用上CMS的表现大概率仍然要会优于G1，而在大内存应用上G1则大多能发挥其优势，这个优劣势的Java堆容量平衡点通常在6GB至8GB之间，当然，以上这些也仅是经验之谈，不同应用需要量体裁衣地实际测试才能得出最合适的结论，随着HotSpot的开发者对G1的不断优化，也会让对比结果继续向G1倾斜。\n\n-XX:+UseG1GC\n\n-XX:G1HeapRegionSize=n，设置的G1区域的大小，值是2的幂，范围是1MB到32MB。目标是根据最小的Java堆大小划分出约2048个区域\n-XX:MaxGCPauseMillis=n，最大Gc停顿时间，这是个软目标，JVM将尽可能(但不保证)停顿小于这个时间\nXX:InitatingHeapOccupancyPercent=n，堆占用了多少的时候就触发GC，默认为45\n-XX:ConcGCThreads=n，并发Gc使用的线程数\n-XX:G1ReservePercent=n，设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险，默认值是10%\n\njdk1.7 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）\njdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）\njdk1.9 默认垃圾收集器G1\n\n参考文献：\n《Oracle HotSpot》\n《深入理解Java虚拟机》', 2, '面试题专栏', 'JVM', 1, 0, 0, 0, '2021-09-29 18:18:17', '2021-09-29 18:18:17');
INSERT INTO `tb_blog` VALUES (3, '我把面试问烂了的⭐Redis面试题⭐总结了一下（带答案，万字总结，精心打磨，建议收藏）', 'redis_interview', 'http://localhost:8888/upload/20210929_18201293.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容| 链接地址|\n|--|--|--|\n|  1| [Java基础知识面试题](https://blog.csdn.net/qq_35620342/article/details/119636436) |https://blog.csdn.net/qq_35620342/article/details/119636436|\n|2|[Java集合容器面试题](https://blog.csdn.net/qq_35620342/article/details/119947254)|https://blog.csdn.net/qq_35620342/article/details/119947254|\n|3|[Java并发编程面试题](https://blog.csdn.net/qq_35620342/article/details/119977224)|https://blog.csdn.net/qq_35620342/article/details/119977224|\n|4|[Java异常面试题](https://blog.csdn.net/qq_35620342/article/details/119977051)|https://blog.csdn.net/qq_35620342/article/details/119977051|\n|5|[JVM面试题](https://blog.csdn.net/qq_35620342/article/details/119948989)|https://blog.csdn.net/qq_35620342/article/details/119948989|\n|6|[Java Web面试题](https://blog.csdn.net/qq_35620342/article/details/119642114)|https://blog.csdn.net/qq_35620342/article/details/119642114|\n|7|[Spring面试题](https://blog.csdn.net/qq_35620342/article/details/119956512)|https://blog.csdn.net/qq_35620342/article/details/119956512|\n|8|[Spring MVC面试题](https://blog.csdn.net/qq_35620342/article/details/119965560)|https://blog.csdn.net/qq_35620342/article/details/119965560|\n|9|[Spring Boot面试题](https://blog.csdn.net/qq_35620342/article/details/120333717)|https://blog.csdn.net/qq_35620342/article/details/120333717|\n|10|[MyBatis面试题](https://blog.csdn.net/qq_35620342/article/details/119956541)|https://blog.csdn.net/qq_35620342/article/details/119956541|\n|11|Spring Cloud面试题|待分享|\n|12|[Redis面试题](https://blog.csdn.net/qq_35620342/article/details/119575020)|https://blog.csdn.net/qq_35620342/article/details/119575020|\n|13|[MySQL数据库面试题](https://blog.csdn.net/qq_35620342/article/details/119930887)|https://blog.csdn.net/qq_35620342/article/details/119930887|\n|14|RabbitMQ面试题|待分享|\n|15|Dubbo面试题|待分享|\n|16|Linux面试题|待分享|\n|17|Tomcat面试题|待分享|\n|18|ZooKeeper面试题|待分享|\n|19|Netty面试题|待分享|\n|20|数据结构与算法面试题|待分享|\n\n第一期我给大家准备了12道高频面试题，大家可以自查，哪块知识点不明白的可以细看。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/21d0efe76cc84b69bdf3ca8668a89350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n# 1.Redis和Memcached相比，有哪些优势？\n①Redis数据结构更丰富，支持string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)等数据结构存储，Memcached仅支持String数据类型。\n\n②Redis支持数据的持久化，可以把内存中的数据持久化到硬盘中，而Memcached不支持持久化，数据只能存在内存中，重启后数据就没了。\n\n③Memcached没有原生的集群模式，需要依靠客户端自己实现集群分片，而Redis原生支持集群模式。\n\n④Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。\n\n# 2.Redis为什么要把数据放到内存中？\nRedis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据刷回磁盘。所以 Redis 具有性能好和数据持久化的特征。 如果不将数据放在内存中，磁盘 I/O 速度会严重\n影响 Redis 的性能。在内存越来越便宜的今天， Redis 越来越受欢迎。\n\n\n# 3.Redis为什么这么快？\n大家都知道，Redis是单线程的，为什么采用单线程的Redis也会如此之快呢？接下来我们分析其中缘由。\n\n\n严格来说，**Redis Server是多线程的，** 只是它的请求处理整个流程是单线程处理的。 这一点我们一定要清楚了解到，不要单纯地认为Redis Server是单线程的。\n\n\nRedis的性能非常之高，每秒可以承受10W+的QPS，它如此优秀的性能主要取决于以下几个方面：\n\n- Redis大部分操作在内存完成\n- 采用IO多路复用机制\n- 非CPU密集型任务\n- 单线程的优势\n\n\n（1）纯内存操作\n\nRedis是一个内存数据库，它的数据都存储在内存中，这意味着我们读写数据都是在内存中完成，这个速度是非常快的。\n\nRedis底层采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。\n\n\n（2）采用IO多路复用机制\n\nRedis 基于 Reactor 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n\n当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n\n虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n\n（3）非CPU密集型任务\n\n采用单线程的缺点很明显，无法使用多核CPU。Redis作者提到，由于Redis的大部分操作并不是CPU密集型任务，而Redis的瓶颈在于内存和网络带宽。\n\n在高并发请求下，Redis需要更多的内存和更高的网络带宽，否则瓶颈很容易出现在内存不够用和网络延迟等待的情况。\n\n当然，如果你觉得单个Redis实例的性能不足以支撑业务，Redis作者推荐部署多个Redis节点，组成集群的方式来利用多核CPU的能力，而不是在单个实例上使用多线程来处理。\n\n（4）单线程的优点\n\n基于以上特性，Redis采用单线程已足够达到非常高的性能，所以Redis没有采用多线程模型。\n\n另外，单线程模型还带了以下好处：\n\n- 避免多线程上下文切换导致的性能损耗\n- 避免多线程访问共享资源加锁导致的性能损耗\n\n所以Redis正是基于有以上这些优点，所以采用了单线程模型来完成请求处理的工作。\n\n（5）单线程的缺点\n\n单线程处理最大的缺点就是，**如果前一个请求发生耗时比较久的操作**，那么整个Redis都会被阻塞，其他请求也无法进来，直到这个耗时久的操作处理完成并返回，其他请求才能被处理到。\n\n我们平时遇到Redis响应变慢或长时间阻塞的问题，大部分都是因为Redis处理请求是单线程这个原因导致的。\n\n所以，我们在使用Redis时，**一定要避免非常耗时的操作**，例如使用时间复杂度过高的方式获取数据、一次性获取过多的数据、大量key集中过期导致Redis淘汰key压力变大等等，这些场景都会阻塞住整个处理线程，直到它们处理完成，势必会影响业务的访问。\n\n（6）多线程优化\n\nRedis Server是多线程的，除了请求处理流程是单线程处理之外，Redis内部还有其他工作线程在后台执行，它负责异步执行某些比较耗时的任务，例如AOF每秒刷盘、AOF文件重写都是在另一个线程中完成的。 \n\n\n\n而在Redis 4.0之后，Redis引入了lazyfree的机制，提供了unlink、flushall aysc、flushdb async等命令和lazyfree-lazy-eviction、lazyfree-lazy-expire等机制来异步释放内存，它主要是为了解决在释放大内存数据导致整个redis阻塞的性能问题。 \n\n\n\n在删除大key时，释放内存往往都比较耗时，所以Redis提供异步释放内存的方式，让这些耗时的操作放到另一个线程中异步去处理，从而不影响主线程的执行，提高性能。 \n\n\n\n到了Redis 6.0，Redis又引入了多线程来完成请求数据的协议解析，进一步提升性能。它主要是解决高并发场景下，单线程解析请求数据协议带来的压力。请求数据的协议解析由多线程完成之后，后面的请求处理阶段依旧还是单线程排队处理。 \n\n\n\n可见，Redis并不是保守地认为单线程有多好，也不是为了使用多线程而引入多线程。Redis作者很清楚单线程和多线程的使用场景，针对性地优化。\n\n# 4.Redis数据类型有哪些？分别应用于哪些场景？\n\nRedis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。\n\nRedis 所有的数据结构都是一个key对应一个value，不同类型的数据结构之间的差异就在于value的结构不同，例如string数据类型，他的value就是一个字符串，list数据类型，他的value是一个链表。\n\n## string\n\n字符串 string 是 Redis 最简单的数据结构，可以存储字符串、整数或者浮点数。最常见的应用场景就是对象缓存，例如缓存用户信息，key是\"userInfo\"+#{用户ID}，value是用户信息对象的json字符串。\n\n案例：\n\nkey：userInfo123\n\nvalue：{\"gender\":1,\"nickname\":\"java程序鱼\",\"userId\":123}\n\n（1）基本操作\n\n```bash\n127.0.0.1:6379> set name hzy # 设置\nOK\n127.0.0.1:6379> get name # 获取\n\"hzy\"\n127.0.0.1:6379> exists name  # 判断是否存在\n(integer) 1\n127.0.0.1:6379> del name # 删除\n(integer) 1\n127.0.0.1:6379> get key\n(nil)\n```\n\n（2）批量操作\n\n可以批量对多个字符串进行读写，节省网络耗时开销。\n\n```bash\n127.0.0.1:6379> mset name1 xiaoming name2 xiaohong # 批量设置\nOK\n127.0.0.1:6379> mget name1 name2 # 批量获取\n1) \"xiaoming\"\n2) \"xiaohong\"\n```\n\n（3）计数\n\n如果 value 值是一个整数，我们可以对它进行自增长操作。自增长是有范围的，它的范围是 signed long 的最大最小值，超过了这个值，Redis 会报错。\n\n```bash\n127.0.0.1:6379> incr likenum # 自增1\n(integer) 1\n127.0.0.1:6379> get likenum\n\"1\"\n127.0.0.1:6379> decr likenum # 减1\n(integer) 0\n127.0.0.1:6379> get number\n\"0\"\n```\n\n（4）过期\n\n```bash\n127.0.0.1:6379> expire name 60 # 设置超时时间\n(integer) 1\n127.0.0.1:6379> setex name 60 value # 等价于 setex + expire\nOK\n127.0.0.1:6379> ttl key # 查看数据还有多久过期\n(integer) 11\n```\n\n字符串是由多个字节组成，每个字节又是由 8 个 bit 组成\n\n（5）应用场景\n\n- 缓存：像我们平时开发，经常会把一个对象转成json字符串，然后放到redis里缓存\n- 计数器：像博客文章的阅读量、评论数、点赞数等等\n- 分布式系统生成自增长ID\n\n## list\n\nRedis 的列表相当于 Java 语言里面的 LinkedList。\n\nLinkedList优点：插入性能高，不管是从末尾插入还是中间插入\n\nLinkedList缺点：随机读性能差，例如LinkedList.get(10)，这种操作，性能就很低，因为他需要遍历这个链表，从头开始遍历这个链表，直到找到index = 10的这个元素为止。\n\n（1）通过list实现队列\n\n右边进左边出\n\n```bash\n127.0.0.1:6379> rpush apps qq # 将元素插入到列表的尾部(最右边)\n(integer) 1\n127.0.0.1:6379> rpush apps wechat taobao # 将多个元素插入到列表的尾部(最右边)\n(integer) 3\n127.0.0.1:6379> lpop apps # 移除并返回列表的第一个元素(最左边)\n\"qq\"\n127.0.0.1:6379> lrange apps 0 1 # 返回列表中指定区间内的元素，0表示第一个，1表示第二个，-1表示最后一个\n1) \"wechat\"\n2) \"taobao\"\n127.0.0.1:6379> lrange apps 0 -1 # -1表示倒数第一\n1) \"wechat\"\n2) \"taobao\"\n```\n\n注意：**当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收**\n\n（2）通过list实现栈\n\n先进先出，右边进右边出\n\n```bash\n127.0.0.1:6379> rpush apps qq wechat taobao\n(integer) 3\n127.0.0.1:6379> rpop apps # 移除列表的最后一个元素，返回值为移除的元素\n\"taobao\"\n```\n\n（3）应用场景\n\n- 异步队列\n- 任务轮询（RPOPLPUSH）\n- 文章列表（lrange key 0 9）\n\n\n\n## hash\n\nRedis的hash结构相当于Java语言的HashMap，内部实现结构上与JDK1.7的HashMap一致，底层通过数据+链表实现。\n\n（1）常用命令\n\n```bash\n127.0.0.1:6379> hmset userInfo name \"hzy\" age \"24\" sex \"1\" \nOK\n127.0.0.1:6379> hexists userInfo name # 相当于HashMap的containsKey()\n(integer) 1\n127.0.0.1:6379> hget userInfo name # 相当于HashMap的get()\n\"hzy\"\n127.0.0.1:6379> hget userInfo age\n\"24\"\n127.0.0.1:6379> hgetall userInfo # 数据量大时，谨慎使用！获取在哈希表中指定 key 的所有字段和值\n1) \"name\"\n2) \"hzy\"\n3) \"age\"\n4) \"24\"\n5) \"sex\"\n6) \"1\"\n127.0.0.1:6379> hkeys userInfo # 数据量大时，谨慎使用！获取 key 列表\n1) \"name\"\n2) \"age\"\n3) \"sex\"\n127.0.0.1:6379> hvals userInfo # 获取 value 列表\n1) \"hzy\"\n2) \"24\"\n3) \"1\"\n127.0.0.1:6379> hset userInfo name \"test\" # 修改某个字段对应的值\n127.0.0.1:6379> hget userInfo name\n\"test\"\n```\n\n（2）应用场景\n\n记录整个博客的访问人数（数据量大会考虑HyperLogLog，但是这个数据结构存在很小的误差，如果不能接受误差，可以考虑别的方案）\n\n记录博客中某个博主的主页访问量、博主的姓名、联系方式、住址\n\n## set\n\nRedis的set集合相当于Java的HashSet。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。\n\n补充：HashSet就是基于HashMap来实现的，HashSet，他其实就是说一个集合，里面的**元素是无序的**，他里面的**元素不能重复**的，HashMap的key是无顺序的，你插入进去的顺序，跟你迭代遍历的顺序是不一样的，而且HashMap的key是没有重复的，HashSet直接基于HashMap实现的。\n\n（1）常用命令\n\n```bash\n127.0.0.1:6379> sadd apps wechat qq # 添加元素\n(integer) 2\n127.0.0.1:6379> sadd apps qq # 重复\n(integer) 0\n127.0.0.1:6379> smembers apps # 注意：查询顺序和插入的并不一致，因为 set 是无序的\n1) \"qq\"\n2) \"wechat\"\n127.0.0.1:6379> scard apps # 获取长度\n(integer) 2\n127.0.0.1:6379> sismember apps qq # 谨慎使用！检查某个元素是否存在set中，只能接收单个元素\n(integer) 1\n127.0.0.1:6379> sadd apps2 wechat qq\n(integer) 2\n127.0.0.1:6379> sinterstore apps apps apps2 # 获取 apps 和 apps 的交集并存放在 apps3 中\n(integer) 1\n127.0.0.1:6379> smembers app3\n1) \"qq\"\n2) \"wechat\"\n```\n\n注意：<font style=\"color: rgb(255, 76, 0);\"> **当集合中最后一个元素移除之后，数据结构自动删除，内存被回收** </font>\n\n（2）应用场景\n\n- \n  微博抽奖：如果数据量不是特别大的时候，可以使用spop（移除并返回集合中的一个随机元素）或srandmember（返回集合中一个或多个随机数）\n\n- QQ标签：一个用户多个便签\n\n- 共同关注（交集）\n\n- 共同好友（交集）\n\n\n## sorted set\n\nsorted set 有序集合，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。使得它类似于Java的TreeSet和HashMap的结合体。\n\n（1）常用命令\n\n```bash\n127.0.0.1:6379> zadd apps 3.0 qq # 添加元素到 sorted set 中,3.0是score的值\n(integer) 1\n127.0.0.1:6379> zadd apps 2.0 wechat 1.0 aliyun # 一次添加多个元素\n(integer) 2\n127.0.0.1:6379> zcard apps # 查看 sorted set 中的元素数量\n(integer) 3\n127.0.0.1:6379> zscore apps wechat # 查看某个 value 的权重\n\"2.0\"\n127.0.0.1:6379> zrange apps 0 -1 # 通过索引区间返回有序集合指定区间内的成员，0 -1 表示输出所有元素\n1) \"aliyun\"\n2) \"wechat\"\n3) \"qq\"\n127.0.0.1:6379> zrange apps 0 1 # 通过索引区间返回有序集合指定区间内的成员\n1) \"aliyun\"\n2) \"wechat\"\n127.0.0.1:6379> zrevrange apps 0 1 # 相当于zrange的反转\n1) \"qq\"\n2) \"wechat\"\n```\n\n注意：<font style=\"color: rgb(255, 76, 0);\"> **sorted set 中最后一个 value 被移除后，数据结构自动删除，内存被回收** </font>\n\n（2）应用场景\n\n- 排行榜\n\n- 订单支付超时（下单时插入，member为订单号，score为订单超时时间戳，然后写个定时任务每隔一段时间执行zrange）\n\n\n# 5.Redis的过期策略有哪些？大量key集中过期导致卡顿如何解决？\n\n如果我们对key设置了失效时间1分钟，1分钟后，Redis 是如何对这个 key 进行删除的呢？\n\nRedis过期策略采用的是惰性删除+定期删除策略。\n\n\n\n## 惰性删除\n\n当某个key被设置了过期时间之后，客户端每次对该key的访问（读写）都会事先检测该key是否过期，如果过期就直接删除。\n\n\n\n## 定期删除\n\n当某个key被设置了过期时间之后，客户端每次对该key的访问（读写）都会事先检测该key是否过期，如果过期就直接删除（这种是被动删除）；**但有一些键只访问一次或者是冷数据**，因此需要主动删除，默认情况下Redis每秒检测10次，**检测的对象是所有设置了过期时间的键集合**，每次从这个集合中随机检测20个键查看他们是否过期，如果过期就直接删除，如果过期的key比例超过1/4，那就把上述操作重复一次（贪心算法）。同时为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过25ms。\n\n如果一个大型的 Redis 实例中所有的 key 在同一时间过期了，会引发什么问题? \n\n这个主动过期 key 的定时任务，是在 Redis 主线程中执行的，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期 key 的情况，那么此时应用程序在访问 Redis 时，必须要等待这个过期任务执行结束，Redis 才可以服务这个客户端请求。此时就会出现，应用访问 Redis 延时变大。\n\n有小伙伴问，扫描不是有 25ms 的时间上限了么，怎么会导致卡顿呢?\n\n假如有 1001 个客户端同时将请求发过来了，然后前 1000 个请求的执行时间都是 25ms，那么第 1001 个指令需要等待多久才能执行？25000ms，25秒，这个就是客户端的卡顿时间，是由服务器不间断的小卡顿积少成多导致的。 \n\n\n大量key集中过期导致卡顿如何解决？\n\n方案一：在设置 key 的过期时间时，增加一个随机时间\n\n```bash\nredis.expireat(key, expire_time + random(300))\n```\n\n这样一来，Redis 在处理过期时，不会因为集中删除过多的 key 导致压力过大，从而避免阻塞主线程。\n\n\n方案二：Redis 4.0 以上版本，开启 lazy-free 机制\n\n```bash\nlazyfree-lazy-expire yes\n```\n\n另外，除了业务层面的优化和修改配置之外，你还可以通过运维手段及时发现这种情况。\n\n运维层面，你需要把 Redis 的各项运行状态数据监控起来，在 Redis 上执行 INFO 命令就可以拿到这个实例所有的运行状态数据。\n\n在这里我们需要重点关注 expired_keys 这一项，它代表整个实例到目前为止，累计删除过期 key 的数量。\n\n你需要把这个指标监控起来，**当这个指标在很短时间内出现了突增**，需要及时报警出来，然后与业务应用报慢的时间点进行对比分析，确认时间是否一致，如果一致，则可以确认确实是因为集中过期 key 导致的延迟变大。\n\n\n\n从库的过期策略：**从库不会进行过期扫描**，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。\n\n# 6.Redis内存淘汰策略有哪些？他们有什么区别？\n当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。 交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样低速的存取效率基本上等于不可用。\n\n在生产环境中我们是不允许 Redis 出现交换行为的，为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。\n\n\n## 淘汰策略\n\n当实际内存超出 maxmemory 时，Redis 提供了6种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务。\n\n- noeviction：不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。\n- volatile-lru：尝试淘汰**设置了过期时间**的 key，通过LRU算法驱逐最近最少使用的key。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。\n- volatile-random：尝试淘汰**设置了过期时间**的 key，在设置了过期时间的key集合中随机选择数据淘汰。\n- volatile-ttl：尝试淘汰**设置了过期时间**的 key，在设置了过期时间的key集合中优先淘汰ttl小的。\n- allkeys-lru：和volatile-lru的区别在于要淘汰的key对象是全体key集合而不只是设置了过期时间的key，其他都一样。\n- allkeys-random：和volatile-random的区别在于要淘汰的key对象是全体key集合而不只是设置了过期时间的key，其他都一样。\n\n\n\nRedis4.0后新增了两个策略：\n\nvolatile-lfu：尝试淘汰**设置了过期时间**的 key，通过LFU算法驱逐使用频率最少的key。没有设置过期时间的 key 不会被淘汰。\n\nallkeys-lfu：和volatile-lfu的区别在于要淘汰的key对象是全体key集合而不只是设置了过期时间的key，其他都一样。\n\n## LRU算法\n\nRedis LRU使用的是近似LRU算法，它跟 LRU 算法还不太一样。之所以不使用 LRU 算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。\n\nRedis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段长度24位，存的是最后一次被访问的时间戳，当Redis执行写操作时，发现内存超出我们配置的${maxmemory}，就会执行一次LRU淘汰算法，随机采样出${maxmemory_samples}个样本，默认值为5，然后淘汰掉最旧的key，如果淘汰后内存还超出${maxmemory}，那就继续随机采样淘汰，直到内存低于${maxmemory}为止。\n\n采样数越大，近似LRU算法的效果越接近严格LRU算法，通过样本数量调整算法的精度\n\n淘汰池是一个数组，它的大小是${maxmemory_samples}，在每次淘汰循环中，新随机出的key列表会淘汰池中的key列表进行融合，淘汰掉最旧的一个key之后，保留剩余较旧的key列表放入淘汰池等待下一个循环。\n\n# 7.持久化方式有哪些？有什么区别？\nRedis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。\n\n\n什么是持久化？\n就是把内存里的数据保存到硬盘上。\n\n\n必须使用数据持久化吗?\nRedis的数据持久化机制是可以关闭的。如果你只把Redis作为缓存服务使用，Redis中存储的所有数据都不是该数据的主体而仅仅是同步过来的备份，那么可以关闭Redis的数据持久化机制。\n\n\n但通常来说，仍然建议至少开启RDB方式的数据持久化，因为：\n\n①数据量不是非常大时，RDB方式的持久化几乎不损耗Redis本身的性能，因为Redis父进程持久化时只需要fork一个子进程，这个子进程可以共享主进程的所有内存数据，子进程会去读取主进程的内存数据，并把它们写入RDB文件。\n\n②Redis无论因为什么原因发送故障，重启时能够自动恢复到上一次RDB快照中记录的数据（自动加载RDB文件）。这省去了手工从其他数据源（如数据库）同步数据的过程，而且要比其他任何的数据恢复方式都要快\n\n③服务器的硬盘都是T级别的，几个G的数据影响忽略不计\n\n\nRedis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持三种不同的持久化策略。\n\n\n\n## RDB\n\nRedis提供了两个命令来生成 RDB 文件：\n\n- save：在主进程中执行，会导致写请求阻塞。\n- bgsave：fork一个子进程，专门用于写入 RDB 文件，避免了主进程的阻塞。\n\n为了快照而阻塞写请求，这是系统无法接受的，因此Redis借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。\n\nRedis在执行持久化时，会fork出一个bgsave子进程，这个子进程可以共享主进程的所有内存数据，bgsave子进程运行后，会去读取主进程的内存数据，并把它们写入RDB文件。\n\n有小伙伴问，为什么要fork一个子线程？\n\nredis是单线程程序，**若单线程同时在服务线上的请求还需要进行文件IO操作，这不仅影响性能而且还会阻塞线上业务**，因此这里主进程fork出一个进程，fork出的这个进程去完成快照操作。\n\n\n\n快照持久化是 Redis 默认采用的持久化方式，我们可以根据业务需求配置下面参数：\n\n```bash\nsave 900 1    #每900秒(15分钟)至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 300 10   #每300秒(5分钟)至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n\nsave 60 10000 #每60秒(1分钟)至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\n```\n\nkey发生变化（key数据添加、修改、删除）\n\n\n触发快照的几种方式：\n\n①服务器正常关闭时，会照一次快照  ./bin/redis-cli shutdown\n\n②key满足一定条件，会照一次快照（通过上述Redis.conf配置）\n\n③通过BGSAVE命令（在redis中执行）手动触发RDB快照保存\n\n\n优点：\n\n①RDB文件紧凑，体积小，网络传输快，适合全量复制\n\n②与AOF方式相比，通过RDB文件恢复数据比较快更快\n\n③RDB最大化了Redis的性能，因为Redis父进程持久化时只需要fork一个子进程，这个子进程可以共享主进程的所有内存数据，子进程会去读取主进程的内存数据，并把它们写入RDB文件。\n\n缺点：\n\n①快照是定期生成的，所有在 Redis 故障时或多或少会丢失一部分数据\n\n②当数据量比较大时，fork 的过程是非常耗时的，fork 子进程时是会阻塞的，在这期间 Redis 是不能响应客户端的请求的。\n\n\n## AOF\n\nRedis会把每一个写请求都记录在一个日志文件里，在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。\n\nRedis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是**先存到磁盘，然后再执行指令**。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。\n\n日志文件太大怎么办？\n\nAOF 日志在长期的运行过程中会变的很大，Redis重启时需要加载 AOF 日志进行指令重放，此时这个过程就会非常耗时。 所以需要定期进行**AOF 重写**，给 AOF 日志进行瘦身。\n\n\nAOF如何重写？\n\nRedis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。每次执行重写时，主进程 fork 出一个bgrewriteaof 子进程，会把主进程的内存拷贝一份给 bgrewriteaof 子进程，对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。\n\n\nRedis提供了AOF rewrite功能，可以重写AOF文件，只保留能够把数据恢复到最新状态的最小写操作集。\n\nAOF 重写可以通过bgrewriteaof命令（在redis里执行）触发，也可以配置Redis定期自动进行：\n\n```bash\n## Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n\nAOF默认是关闭的，如果需要开启，需要在redis.conf配置文件中配置\n\n```bash\nappendonly  yes\n```\n\n\n\nAOF提供三种fsync配置，always/everysec/no，通过配置项appendfsync指定，默认是everysec。\n\n```bash\nappendfsync always    # 每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢（每次有数据修改发生时都会写入AOF文）\nappendfsync everysec  # 折中的做法，交由后台线程每秒fsync一次（每秒钟同步一次，该策略为AOF的缺省策略）\nappendfsync no        # 不进行fsync，将flush文件的时机交给OS决定，速度最快（从不同步。高效但是数据不会被持久化）\n```\n\n优点：\n\n①数据安全性高，可以根据业务需求配置fsync策略\n\n②AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误命令删除，然后恢复数据\n\n缺点：\n\n①AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大\n\n②数据恢复速度比RDB慢\n\n\n## 混合持久化\n\n如果我们采用 RDB 持久化会丢失一段时间数据。如果我们采用 AOF 持久化，AOF日志较大，重放比较慢。\n\nRedis 4.0 为了解决这个问题，支持混合持久化。将 RDB 文件的内容和增量的 AOF 日志文件存在一起。\n\n混合持久化同样也是通过 bgrewriteaof 完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以 RDB 方式写入 AOF 文件，然后在将重写缓冲区的增量命令以 AOF 方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。\n\n于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。\n\n\n## 实战经验\n\n快照需要fork子进程的方式进行的，它是一个比较耗资源的操作。（当数据量非常大时，fork会很耗时，需要大概几百毫秒甚至1秒，fork时父进程是阻塞的，不能正常服务redis读写请求）\n\nAOF 的 fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系统 IO 负担\n\n所以通常 Redis 的**主节点是不会进行持久化操作**，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。\n\n但是如果出现网络分区，从节点长期连不上主节点，就会出现数据不一致的问题，特别是在网络分区出现的情况下又不小心主节点宕机了，那么数据就会丢失，所以在生产环境要做好实时监控工作，保证网络畅通或者能快速修复。另外还应该再增加一个从节点以降低网络分区的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失。\n\n# 8.怎么实现 Redis 的高可用？主从架构主节点和从节点数据怎么同步？\n\n如果 Redis 的读写请求量很大，那么单个 Redis 实例很有可能承担不了这么大的请求量，如何提高Redis的性能呢？我们可以部署多个副本节点，业务采用读写分离的方式，把读请求分担到多个副本节点上，提高访问性能。要实现读写分离，就必须部署多个副本，每个副本需要实时同步主节点的数据。\n\n单可用区（节点全部在一个可用区）：无法应对机房级别的故障\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b346672b63d4d1495522a29e3264b13~tplv-k3u1fbpfcp-zoom-1.image\"/>\n如果上海可用区机房出现故障，整个Redis服务全部瘫痪，所以我们在平时部署时，需要把节点分散在不同的可用区，如果有小伙伴公司对可用性要求极高，可以研究下异地多活方案，在这里我就不展开了。\n\n\n主从复制的三种方式：\n\n①全量复制\n\n②增量复制\n\n③无盘复制\n\n\n\n## 全量复制\n\n假设我们有两个节点，A节点是 Master 节点，B节点是 Slave 节点。\n\n当我们在节点B上执行`slaveof`命令后，节点B会与节点A建立一个TCP连接，然后发送`psync ${runid} ${offset}`命令，告知节点A需要开始同步数据。\n\n参数介绍：\n\n- `runid`：每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例\n- `offset`：偏移量，slave需要从哪个位置开始同步数据\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/795cb70d06ee4b3ba5cb3819125278dd~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n\n由于是第一次同步，Slave 节点不知道 Master节点的`runid`，所以 Slave 节点会发送`psync ? -1`，表示需要全量同步数据。\n\nMaster 节点在收到 Slave 节点发来的`psync`后，会给slave回复`+fullresync ${runid} ${offset}`，这个`runid`就是master的唯一标识，slave会记录这个`runid`，用于后续断线重连同步请求。\n\nMaster 执行 bgsave 命令，生成 RDB 文件，接着将文件发给 Slave。Slave 接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为Slave在通过 replicaof 命令开始和 Master 同步前，可能保存了其他数据。为了避免之前数据的影响，Slave 需要先把当前数据库清空。\n\n在 Master 将数据同步给 Slave 的过程中，Master 不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主 Slave 的数据一致性，Master 会在内存中用 repl_backlog_buffer 记录 RDB 文件生成后收到的所有写操作。\n\n最后，Master 会把 repl_backlog_buffer数据再发送给从库。这样一来，主从库就实现同步了。\n\n\n全量复制的开销：\n\n主节点：生成RDB文件会占用内存、硬盘资源，网络传输RDB的时候会占用一定的网络带宽资源\n\n从节点：清空数据，若数据量大，需要消耗一定的时间，加载RDB也需要一定的时间\n\n\n## 增量同步\n\n在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，从库就会和主库重新进行一次全量复制，开销非常大。\n\n在Redis在这方面进行了改进，在2.8版本之后，Redis支持**增量同步**。\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5e0fbf1a52144137b43759fce8582e47~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n主从因为故障断开，故障恢复后，他们重新建立连接，Slave 节点向 Master 节点发送数据 同步请求：`psync ${runid} ${offset}`，Master 收到`psync`命令之后，检查slave发来的`runid`与自身的`runid`一致，如果一致，说明之前已经同步过数据，这次只需要同步部分数据即可。\n\n这里分为两种情况：\n①如果offset在repl_backlog_buffer范围内，那么 Master 节点给 Slave 节点回复`+continue`，表示这次只同步部分数据。之后 Master 节点把复制缓冲区`offset`之后的数据给 Slave 节点，接下来 Slave 节点执行这些命令后就与 Master 数据一致了。\n\n②如果offset不在repl_backlog_buffer范围内，说明断开连接很久了，如果offset在repl_backlog_buffer的内容已经被新的内容覆盖了，此时只能触发全量数据同步。\n\n## 无盘复制\n\n通常，全量复制需要在磁盘上创建RDB文件，然后加载到内存中，Redis支持无盘复制，生成的RDB文件不保存到磁盘而是直接通过网络发送给从节点。无盘复制适用于主节点所在机器磁盘性能较差但网络宽带较充裕的场景。需要注意的是，无盘复制目前依然处于**实验阶段**。\n\n# 9.怎么做自动故障转移？哨兵如何监控节点？哨兵集群如何选主？故障迁移后如何通知客户端？\nRedis 除了具有非常高的性能之外，还需要保证高可用，在故障发生时，尽可能地降低故障带来的影响，Redis提供了哨兵模式，来进行故障恢复。\n\n哨兵主要负责做三件事：\n\n①监控，监控主、从节点是否正常运行\n\n②选主，Sentinel集群需要选择一个Leader来进行主从切换。\n\n③通知，选主完成后，需要把新主库的连接信息通知给从库和客户端。\n\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4557834a38f47e3890ad619d477cc99~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n## 状态感知\n\n哨兵启动后只指定了master的地址，要想知道整个集群中完整的拓扑关系怎么做呢？\n\n哨兵每隔10秒会向每个master节点发送`info`命令，`info`命令返回的信息中，包含了主从拓扑关系，其中包括每个slave的地址和端口号。有了这些信息后，哨兵就会记住这些节点的拓扑信息，在后续发生故障时，选择合适的slave节点进行故障恢复。\n\n那么有小伙伴会问，哨兵之间是如何通信的呢？\n\n基于Redis提供的发布（pub）/订阅（sub）机制完成的。哨兵节点不会直接与其他哨兵节点建立连接，**而是首先会和主库建立起连接**，然后向一个名为\"_sentinel_:hello\"频道发送自己的信息（IP 和端口），其他订阅了该频道的哨兵节点就会获取到该哨兵节点信息，从而哨兵节点之间互知。\n\n\n## 心跳检测\n\n每一秒，每个 Sentinel 对 Master、Slave、其他哨兵节点执行PING命令，检测它们是否仍然在线运行，如果有节点在规定时间内没有响应PING命令，那么该哨兵节点认为此节点\"主观下线\"。\n\n\n\n## 主观下线和客观下线\n\n为什么需要客观下线机制？\n\n因为当前哨兵节点探测对方没有得到响应，很有可能这两个机器之间的网络发生了故障，而 Master 节点本身没有任何问题，此时就认为 Master 故障是不正确的。\n\n为了解决上述问题，客观下线应运而生，Sentinel一般会集群部署，引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。\n\n假设我们有N个哨兵实例，如果有N/2+1个实例判断主库“主观下线”，此时把节点标记为“客观下线”，此时就可以做主从切换了。\n\n\n## 选举哨兵领导者？\n\n假设Sentinel 判断主库“主观下线”后，就会给其他 Sentinel 实例发送 is-master-down-by-addr 命令，接着，其他 Sentinel 实例会根据自己和主库的连接情况，做出赞成和反对决定。\n\n假设我们有N个哨兵实例，如果有#{quorum}个实例赞成，此时这个 Sentinel 就会给其他 Sentinel 发送主从切换请求，其他 Sentinel 会进行投票，如果投票通过，这个 Sentinel 就可以进行主从切换了，**这个投票过程被称为Leader 选举**。其实整体思想和Zookeeper一样的。\n\n在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。\n\nquorum一般我们都会配置成``实例数量/2+1``\n\n\n此时会有小伙伴问，如果所有Sentinel都想成为Leader执行主从切换怎么办？\n\n哨兵选举领导者的过程类似于Raft算法，每个哨兵都设置一个**随机超时时间**，超时后向其他哨兵发送申请成为领导者的请求，把超时时间都分散开来，**在大多数情况下只有一个服务器节点先发起选举，而不是同时发起选举，这样就能减少因选票瓜分导致选举失败的情况**。\n\n后期我会专门写一个专栏为大家介绍所有一致性算法，例如：Paxos、Raft、Gossip、ZAB等，到时候具体给大家讲解Sentinel是如何解决上述问题的。\n\n\n\n## 谁来做新的Master？\n\n选择新master过程也是有优先级的，在多个slave的场景下，优先级按照：slave-priority配置 > 数据完整性 > runid较小者进行选择。\n\n\n用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。如果所有从节点的 slave-priority 值一致，那就看谁的数据更完整。\n\n如何判断谁的数据更完整呢？\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9ce939f9b8e7468484942d420629ee4b~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n主库会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。此时，哪个从库的 slave_repl_offset 最接近 master_repl_offset。那么谁就可以作为新主库。\n\n\n如果 slave_repl_offset都一致，那就比 runid，选择runid最小的 Slave 节点作为新主库。\n\n\n选择出新主库，哨兵 Leader 会给该节点发送`slaveof no one`命令，让该节点成为 Master。之后，哨兵 Leader会给故障节点的所有 Slave 发送`slaveof $newmaster`命令，让这些 Slave 成为新 Master 的从节点，开始从新的Master 上同步数据（这里会进行全量复制）。最后哨兵 Leader 把故障节点降级为 Slave，并写入到自己的配置文件中，待这个故障节点恢复后，则自动成为新 Master 节点的 Slave。至此，整个故障切换完成。\n\n## 如何通知客户端？\n\n上面已经介绍了完整的故障切换全流程，故障切换后，主节点变化了，客户端如何感知呢？\n\n基于Redis提供的发布（pub）/订阅（sub）机制完成的，客户端可以从哨兵订阅消息，故障转移后，客户端会收到订阅消息。\n\n# 10.能说说集群原理吗？客户端如何能感知到槽位的变化？MOVED、Asking知道是干嘛的吗？\n\n在大数据高并发场景下，Sentinel存在一些问题，写请求全部落在 Master 节点，Master 节点就一个实例，存储容量、CPU、内存、IO都存在瓶颈，如果我们扩容内存，会导致RDB文件过大，从而fork子进程时会阻塞较长时间。此时Redis 集群方案应运而生。\n\n\n## 数据如何分片？\n\n**Redis Cluster 采用的是虚拟槽分区**，一个集群共有 16384 个哈希槽，Redis Cluster会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N个。\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9998504585e3438b9143371cb3d7b181~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\nRedis Cluster 会对 key 进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 \n\n## 扩容机制\n\n如图所示，6379、6380、6381三个主节点，6382是6379的从节点，6383是6380的从节点，6384是6381的从节点，现在因为业务发展过快，需要进行扩容，我们新增一个主节点6385和一个从节点6386。\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c5adcdc47fcb4e0983ad4f461cccd8ca~tplv-k3u1fbpfcp-zoom-1.image\" />\n\n步骤一：首先需要为新节点指定槽的迁移计划，也就是将哪些节点的哪些槽迁移到新节点中。并且迁移计划要确保每个节点负责相似数量的槽，从而保证各节点的数据均匀。槽迁移计划确定后开始逐个把槽内数据从源节点迁移到目标节点中。\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dd16441c28ab4fa5877988df6694242b~tplv-k3u1fbpfcp-zoom-1.image\" />\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9a9a646a3a324bc7ab142cc1b8acbac5~tplv-k3u1fbpfcp-zoom-1.image\" />\n\n如上图所示，6379准备把自己的4097-5460槽迁移给新节点6385，6380准备把自己的9558-10921槽迁移给新节点6385，6381准备把自己的15019-16383槽迁移给新节点6385。\n\n步骤二：迁移数据数据迁移过程是逐个槽进行的，每个槽迁移的流程如下流程说明:\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/19824ba99c094e1a91eed2a879a197c9~tplv-k3u1fbpfcp-zoom-1.image\" style=\"zoom:50%;\" />\n\n①对目标节点发送cluster setslot {slot} importing {sourceNodeId}命令，让目标节点准备导入槽数据。\n\n②对源节点发送cluster setslot {slot} migrating {targetNodeId}命令，让源节点准备迁出槽数据。 \n\n③源节点循环执行cluster getkeysinslot {slot} {count}命令，获取count个数据槽{slot}的键。 \n\n④在源节点上执行migrate {targetIp} {targetPort} key 0 {timeout} 命令把指定key迁移\n\n注意：Redis3.2.8后，使用pipeline传输\n\n⑤重复步骤3、4直到槽下所有的键值数据迁移到目标节点。\n\n⑥向集群内所有主节点发送cluster setslot {slot} node {targetNodeId}命令，通知槽分配给目标节点。\n\n## 缩容机制\n\n缩容的三种情况：\n\n①下线迁移槽\n\n②忘记节点\n\n③关闭节点\n\n**槽迁移和扩容一样**\n\n## MOVED\n\n当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个 MOVED 指令并携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。\n\n客户端收到 MOVED 指令后，要立即纠正本地的槽位映射表。后续所有 key 将使用新的槽位映射表。\n\n\n案例：\n\n首先计算出哈希值，然后取模16384，得到槽\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/11442b32e3c94baf9be46ec572e8a052~tplv-k3u1fbpfcp-zoom-1.image\" style=\"zoom:50%;\" />\n\n计算哈希值命令：\n\n```bash\n127.0.0.1:6379>cluster keyslot \"hello world\"\n```\n\n命中\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3310523f2db14fc8a4188fd8370b2312~tplv-k3u1fbpfcp-zoom-1.image\" style=\"zoom:50%;\" />\n\n未命中\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/379c2d6dbd6d4ef09c5aaabb824c97dc~tplv-k3u1fbpfcp-zoom-1.image\" style=\"zoom:50%;\" />\n\nMOVED命令里包含两个信息，一个是槽的位置，一个是目标节点地址。\n\n## Asking\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4de6ecdaebb24e58ac47c8122a37876e~tplv-k3u1fbpfcp-zoom-1.image\" style=\"zoom:50%;\" />\n\n集群的伸缩（扩容/缩容）的时候，当我们去源节点访问时，发现key已经迁移到目标节点，会回复ask转向异常，收到异常后，先是执行asking命令，然后给目标节点再次发送命令，然后就会返回结果。\n\n假如我们执行一个get key命令，这个key原来是在A节点，现在迁移到B节点，然后会给我们返回ASK转向异常，当我们收到ASK转向异常后，需要执行一条Asking命令给目标节点，然后在发送get命令。\n\nASK与MOVED共同点：两者都是重定向\nASK与MOVED不同点：\n- MOVED：槽已经确定\n- Asking：槽在迁移过程，key有可能在source节点有可能在target节点\n\n## 槽位迁移感知\n\n如果集群中某个槽位正在迁移或者已经迁移完了，客户端如何能感知到槽位的变化？\n\n客户端保存了槽位和节点的映射关系表，当客户端收到moved指令的时候，他会去刷新槽位映射关系表，获取到最新的映射关系。当收到ask转向异常时，不会刷新槽位映射关系表，因为它是临时纠正。\n\n\n## 容错\n\nRedis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会自动将其中某个从节点提升为主节点。如果某个主节点没有从节点，那么当它发生故障时，集群将完全处于不可用状态。不过 Redis 也提供了一个参数cluster-require-full-coverage可以允许部分节点故障，其它节点还可以继续提供对外访问。\n\n# 11.缓存雪崩、击穿、穿透如何解决？\n## 缓存雪崩\n\n什么是缓存雪崩？\n\n缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到数据库，导致数据库压力激增，从而崩溃。\n\n\n\n导致缓存雪崩的两个原因：\n\n①缓存中有大量数据采用了相同的过期时间，从而同时过期，导致大量请求无法在Redis命中\n\n解决方案：给这些数据的过期时间增加一个较小的随机数\n\n\n\n②Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。\n\n方案一：开启限流\n\n方案二：针对热点数据，可以做多级缓存，可以用Guava在本地构建一个缓存，但需要考虑内存因素\n\n\n\n第二个问题在生产环境中很少遇到，我们线上环境采用的是Redis集群架构，并且每个主节点都配备了两个从节点，而且服务器都分散在全国各地，几乎不会出现大面积Redis故障。\n\n\n\n## 缓存击穿\n\n对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。\n\n缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从数据库读取数据并设置到缓存，这个时候大并发的请求可能会瞬间把数据库压垮。\n\n解决方案：采用互斥锁/分布式锁，让一个线程去查询就行，其他线程等待。\n\n## 缓存穿透\n\n什么是缓存穿透？\n\n恶意请求缓存中不存在的数据，这导致缓存无法命中，每次请求都会查数据库（穿透到后端数据库进行查询），这个时候就出现穿透问题。\n\n解决方案：\n\n①如果数据库查不到，那缓存就设置null，并设置过期时间\n\n②使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。\n\n③假设我们用户ID是有规律的（例如长度是20），当请求过来，我们先判断这个ID是否符合我们的规律，如果不符合可以直接拦截（例如传过来的ID只有18位）\n\n# 12.分布式锁如何实现？\n## 为什么需要分布式锁？\n\n```java\npublic synchronized void test() {\n    System.out.println(\"获取到锁\");\n}\npublic void test2() {\n     synchronized (Test.class) {\n          System.out.println(\"获取到锁\");\n     }\n}\n```\n\n假设我们把上述代码部署到多台服务器上，这个互斥锁还能生效吗？答案是否定的，这时分布式锁应运而生。\n\n## Redis分布式锁？\n\n接下来我给大家讲解完整的演变过程，让大家更深刻的理解分布式锁。\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/529eb434dc524f90ad88c7851aeb50e5~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n\n### Redis setnx\n\n线程1申请加锁，这时没有人持有锁，加锁成功：\n\n```bash\n127.0.0.1:6379> setnx lock 1\n(integer) 1\n```\n\n线程2申请加锁，此时发现有人持有锁未释放，加锁失败：\n\n```bash\n127.0.0.1:6379> setnx lock 1\n(integer) 0\n```\n\n线程1执行完成业务逻辑后，执行DEL命令释放锁：\n\n```bash\n127.0.0.1:6379> del lock\n(integer) 1\n```\n\n\n\n存在问题：\n\n①假设线程1执行到一半，系统挂了，这时锁还没释放，就会造成死锁。\n\n②如果Redis加锁后，Master还没同步给Slave就挂了，会导致有两个客户端获取到锁\n\n解决方案：setnx expire\n\n\n### Redis setnx expire\n\n为了解决上述死锁问题，我们在setnx后，给这个key加上失效时间。\n\n此时线程1加锁的代码改成：\n\n```bash\n127.0.0.1:6379> setnx lock 1 ## 加锁\n(integer) 1\n127.0.0.1:6379> expire lock 3 ## 设置 key 3秒失效\n(integer) 1\n```\n\n存在问题：\n\n①假设`setnx lock 1`执行成功了，但是`expire lock 3`执行失败了，还是会存在死锁问题，这两个命令需要保证<font style=\"color: rgb(255, 76, 0);\">**原子性**</font>。\n\n②失效时间是我们写死的，不能自动续约，如果业务执行时间超过失效时间，会出现线程1还在执行，线程2就加锁成功了，并有没达到互斥效果。\n\n③如果Redis加锁后，Master还没同步给Slave就挂了，会导致有两个客户端获取到锁\n\n解决方案：RedissonLock\n\n### RedissonLock\n\n上述两个问题，RedissonLock都解决了，我通过源码给大家剖析，看RedissonLock是如何解决的，基础好的小伙伴可以好好读读源码，其实RedissonLock源码也不难。\n\n我先写结论，基础较弱的小伙伴，只要记得结论就行：\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c8a119da13dc407fb87144080a689273~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n①RedisssonLock底层使用的是lua脚本执行的redis指令，lua脚本可以保证加锁和失效指令的原子性。\n\n②RedisssonLock底层有个看门狗机制，加锁成功后，会开启一个定时调度任务，每隔10秒去检查锁是否释放，如果没有释放，把失效时间刷新成30秒。这样锁就可以一直续期，不会释放。\n\n\n\n我看的是3.12.5版本源码，不同版本实现上可能存在一些差异。\n\n应用程序加锁代码：\n\n```java\nRLock lock = redissonLock.getLock(\"anyLock\");\nlock.lock();\n```\n\nRedissonLock加锁核心代码：\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eb1949e2d33744a0b7b9d8efa1a47775~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\nRedissonLock获取锁核心代码：\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/490d8c053f454be1a3437fedf2383a95~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n底层加锁逻辑：\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e28adc009ccc4b099cee0d2cc7baec61~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\nKEYS[1] = anyLock，锁的名称。\n\nARGV[1] = 30000，失效时间，通过lockWatchdogTimeout配置。\n\nARGV[2] = c1b51ddb-1505-436c-a308-b3b75b4bd407:1，他是ConnectionManager的ID，我们可以简单的把它理解为一个客户端的一个线程对应的唯一标志性。\n\n\nRedissonLock解锁核心代码：\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e64c685270fc47cea7a0d45d445f51ad~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n\n\n存在问题：如果redis是单节点，存在单节点故障问题；如果做主从架构，Redis加锁后，Master还没同步给Slave就挂了，会导致有两个客户端获取到锁\n\n有小伙伴问我，如果这里我用集群会存在这个问题吗？集群的本质是分片，这个key最终还是会落到某个具体的节点，这个节点要么是单独存在，要么是主从架构，所以还是会存在上述问题。\n\n解决方案：RedLock\n补充：虽然RedLock可以解决上述问题，但是在生产环境中我们很少使用，因为它部署成本很高，相比RedissonLock性能也略微有所下降​。\n如果业务能接受极端情况下存在互斥失败问题，并且对性能要求比较高，我们会选择RedissonLock，并做好响应​的兜底方案。\n如果业务对数据要求绝对正确，​我们会采用Zookeeper来做分布式锁。​\n\n\n### Redlock\n\n我们假设有5个完全相互独立的Redis Master单机节点，所以我们需要在5台机器上面运行这些实例，如下图所示（请注意这张图中5个Master节点完全相互独立）\n\n\n为了取到锁，客户端应该执行以下操作:\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f49b88c14ea44a8a9084819c072cb7e1~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n①获取当前Unix时间，以毫秒为单位。\n\n②依次尝试从**N个Master实例使用相同的key和随机值获取锁**（假设这个key是LOCK_KEY）。当向Redis设置锁时，**客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间**。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。\n\n③客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当**从大多数的Redis节点都取到锁**，并且使用的时间小于锁失效时间时，锁才算获取成功。\n\n④如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。\n\n⑤如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。\n\n\n缺点：像我们系统，并发量比较大，生产环境必须要做分片才能扛住并发，像上述方案，**我们需要准备5个Redis集群**，这种机器成本是非常高的。\n\n\n\n## Zookeeper分布式锁\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f0d30a30ef574e95a3f519ec89b7eb6c~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n如果有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁，后面的每个人都会去监听排在自己前面的那个人创建的node上，一旦某个人释放了锁，排在自己后面的人就会被zookeeper给通知，一旦被通知了之后，就ok了，自己就获取到了锁，就可以执行代码了。\n\n\n为了帮助大家理解，我暂时不用框架，通过手写代码带大家理解Zookeeper锁：\n\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/49c23533980449b18a905296c78a4bae~tplv-k3u1fbpfcp-zoom-1.image\"/>\n<img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2f9dc1012d994d1d9c80259697b39a9b~tplv-k3u1fbpfcp-zoom-1.image\"/>\n\n\n此时有小伙伴问，如果业务执行一半，系统宕机了怎么办？\n\nzk创建的是临时节点，客户端获取到锁执行业务，执行到一半突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉，其他客户端自动获取锁，不会存在死锁问题。\n\n\n一般生产环境我们都会使用Curator来完成分布式锁编码，他提供了可重入锁、非可重入锁、Semaphore、可重入读写锁、MultiLock等各种分布式锁。\n\n# 13.如何保证Redis命令的原子性？\n原子性：多个命令要么全部成功，要么全部失败。\n通过Lua脚本实现。', 2, '面试题专栏', 'Redis', 1, 0, 0, 0, '2021-09-29 18:20:14', '2021-09-29 18:20:14');
INSERT INTO `tb_blog` VALUES (4, '大学四年，这个Java学习路线，让我进了大厂', 'java', 'http://localhost:8888/upload/20210929_18211864.png', '**大家有什么想要深入了解的知识点，可以评论区留言，点赞最多的技术，我会写一个专栏给大家深入剖析**\n\n我先给大家看一张大型项目架构图，接下来我会给大家一步一步剖析。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/95fe4c749d1f47da8eb09f97006c852b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/c4d21cd78d8d47d384ef16de4a8c262a.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n## 1.Java基础\n### Java基础核心\n![请添加图片描述](https://img-blog.csdnimg.cn/6312744cf8654c1c9d4ff74d97c705ca.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n\n### 集合\n![在这里插入图片描述](https://img-blog.csdnimg.cn/4b702780e7494c35aed58f0f1c3cd7c8.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n\n### 并发编程\n![在这里插入图片描述](https://img-blog.csdnimg.cn/26ab947c86f843628151474598d7858e.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n## 2.JavaWeb\n学完上述内容，JavaSE就掌握的差不多了，此时我们可以开始学习JavaWeb了。\n\n### HTML\n![请添加图片描述](https://img-blog.csdnimg.cn/facddf31395a46d1a4cfc4341de17374.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n\n### CSS\n![请添加图片描述](https://img-blog.csdnimg.cn/2aa44bd1896a4abe9fe1e93442e69d12.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n### Tomcat\n![请添加图片描述](https://img-blog.csdnimg.cn/a3c7bf62935040f0871b2dc81f0ab25b.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n### HTTP协议\n![在这里插入图片描述](https://img-blog.csdnimg.cn/7bdf6ea5d5244185aee8a61c9133576c.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n### Servlet\n![在这里插入图片描述](https://img-blog.csdnimg.cn/b89f79880db4454c84897cfcdaad12f4.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n### Cookie、Session\n![在这里插入图片描述](https://img-blog.csdnimg.cn/7ee21f323556409dbac8e0574c704e25.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n### Filter 过滤器\n![请添加图片描述](https://img-blog.csdnimg.cn/48de008fa641496b8252e4991dca9dac.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70)\n### Listener 监听器\n![在这里插入图片描述](https://img-blog.csdnimg.cn/c5c5e1996a4f49b8b05ccea217e84795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n### JSP\n![在这里插入图片描述](https://img-blog.csdnimg.cn/ca37fd7cb689413ba337c6801a642440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n### el表达式\n![在这里插入图片描述](https://img-blog.csdnimg.cn/fff080f8765b4942b36402ad6dde90bd.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n### Java Web 设计模式\n![在这里插入图片描述](https://img-blog.csdnimg.cn/18b40bdacb7b4d67a3676f94f9645e97.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n### 文件上传\n![在这里插入图片描述](https://img-blog.csdnimg.cn/1da2b13959d9487a9f9693dfaa0a54ba.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n### jQuery\n![在这里插入图片描述](https://img-blog.csdnimg.cn/1f612a4b4185445c910b1b81134d5f46.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n像HTML、CSS、jQuery这些偏前端的支持大家了解下就行，中大型互联网公司，Java工程师面试很少问前端，但有些公司Java工程师需要负责后台管理系统的前后端开发，所以前端知识我们也了解下。\n\n像Tomcat、Servlet、Filter、Listener、Cookie、Session、JSP、HTTP协议这些内容，希望大家认真学习，很多同学有个误区，就是上来就研究框架，忽略了一点，框架底层其实就是Servlet、Filter、Listener等知识，基础没学好，要想深入研究框架几乎不可能。学好了这些核心基础，框架上手非常容易。\n\n## 3.MySQL\nMySQL我会写两个专栏，一个面向初学者（[MySQL入门](https://blog.csdn.net/qq_35620342/category_11292886.html)），一个面向有工作经验的（[MySQL进阶](https://blog.csdn.net/qq_35620342/category_7125081.html)）。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/02e442eb0c41415cbcb7f10ecb0eba18.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n## 4.Spring\n![在这里插入图片描述](https://img-blog.csdnimg.cn/f5d6e6ef6f5c4cd98f806c988318bd04.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n## 5.SpringMVC\n![在这里插入图片描述](https://img-blog.csdnimg.cn/350200fa7ddc49b6b82da8a9b2ba3a35.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n## 6.MyBatis\n![在这里插入图片描述](https://img-blog.csdnimg.cn/e0f11c69f0e648afa914183f6b4931a9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n## 7.SpringBoot\nSpringBoot工作机制：@SpringBootApplication、@EnableAutoConfiguration\n\nSpringApplication程序启动原理：SpringApplication执行流程、SpringApplicationRunListener、ApplicationListener、ApplicationContextInitializer、CommandLineRunner\n\nSpringBoot核心组件：Starter、Actuator、AutoConfiguration、SpringBoot CLI\n\nSpringBoot集成MyBatis\n\nSpringBoot集成Redis\n\nSpringBoot实现多环境配置动态解析\n\nSpringBoot热部署实战\n\n## 8.Redis\n之前写过一篇关于Redis专栏，大家可以参考：[Redis专栏](https://blog.csdn.net/qq_35620342/category_11257165.html)\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/be011eb548384efdac8bade57ce7b0c5.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n## 9.消息队列\n这块我没有写相关文章，看大家是否需要，需要的话我后期可以写一个专栏。\n\n## 10.JVM\n![在这里插入图片描述](https://img-blog.csdnimg.cn/f5f88c3b34004b7e94f91812e5f760a9.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjIwMzQy,size_16,color_FFFFFF,t_70#pic_center)\n\n\n## 11.分布式基础\nCAP原理：C（Consistency一致性）A（Availability可用性）P（Partition tolerance分区容错）\n\nBASE理论：Basicly Available、Soft State、Eventual Consistency，也就是基本可用、软状态、最终一致性\n\n一致性算法：Paxos算法、Raft算法、一致性哈希算法、Gossip协议、ZAB协议等\n\n## 12.SpringCloud\n### Netflix\n\n\n（1）微服务注册中心 Eureka \n- 基础\nEureka Server构建使用\nEureka Client构建使用\nProvier和Consumer调用\n\n- 进阶\n服务注册流程\n服务续约流程\n服务下线流程\n\n- 面试\n多注册中心优劣势剖析\nEureka注册慢原因剖析\n自我保护模式剖析\n\n（2）负载均衡器 Ribbon\n- 基础\nRibbon架构图剖析\nRibbon环境构建\nRibbon调用\n\n- 进阶\nRibbon参数及使用\nRibbon负载均衡算法区别\nRibbon的IPing算法区别\n\n- 面试\nRibbon源码分析\nRibbon自定义负载均衡算法及实战场景\nRibbon ServerList使用场景\n\n（3）RPC跨服务调用 Feign\n- 基础\nFeign入门\nFeign参数绑定\n\n- 进阶\nFeign核心之Client\nFeign整合Ribbon实现负载均衡\nFeign整合Hystrix实现降级\n\n- 面试\nFeign自定义配置\nFeign调优核心之HttpClient\nFeign调优核心之请求压缩优化\n\n（4）熔断降级利器 Hystrix\n\n- 基础\nHystrix架构图剖析\nHystrix两种命令四种模式\n\n- 进阶\nHystrix隔离技术\nHystrix熔断机制\nHystrix监控机制和使用\n\n- 面试\nHystrix如何合理设置线程池数量\nHystrix参数全解析\nHystrix各项参数调优\n\n（5）网关 Zuul/Gateway\n\n- 基础\nAPI网关出现背景及其优缺点\nZuul/Gateway使用\nZuul/Gateway架构图解析\n\n- 进阶\nZuul/Gateway表达式\nFilter全生成周期\nZuul/Gateway整合Ribbon和Hystrix使用\n\n- 面试\n Zuul/Gateway之Filter源码\nZuul/Gateway自定义Filter\nZuul/Gateway安全实战\n\n这里我建议大家先把SpringCloud Netflix学完再去学SpringCloudAlibaba这样上手更快，也更简单。\n\n### Alibaba\nAlibaba Nacos：服务注册与配置中心\nSpringCloud Alibaba Sentinel：实现网关动态限流\n\n**大家有什么想要深入了解的知识点，可以评论区留言，点赞最多的技术，我会写一个专栏给大家深入剖析**\n\n学习网站在之前的文章中有写，大家可以看这篇文章。[【建议收藏】推荐12个堪称神器的学习网站](https://blog.csdn.net/qq_35620342/article/details/119678518)', 2, '面试题专栏', 'Java', 1, 0, 0, 0, '2021-09-29 18:21:19', '2021-09-29 18:21:19');
INSERT INTO `tb_blog` VALUES (5, '我把面试问烂了的⭐SpringBoot⭐总结了一下（带答案，万字总结，精心打磨，建议收藏）', 'springboot_interview', 'http://localhost:8888/upload/20210929_18225263.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容| 链接地址|\n|--|--|--|\n|  1| [Java基础知识面试题](https://blog.csdn.net/qq_35620342/article/details/119636436) |https://blog.csdn.net/qq_35620342/article/details/119636436|\n|2|[Java集合容器面试题](https://blog.csdn.net/qq_35620342/article/details/119947254)|https://blog.csdn.net/qq_35620342/article/details/119947254|\n|3|[Java并发编程面试题](https://blog.csdn.net/qq_35620342/article/details/119977224)|https://blog.csdn.net/qq_35620342/article/details/119977224|\n|4|[Java异常面试题](https://blog.csdn.net/qq_35620342/article/details/119977051)|https://blog.csdn.net/qq_35620342/article/details/119977051|\n|5|[JVM面试题](https://blog.csdn.net/qq_35620342/article/details/119948989)|https://blog.csdn.net/qq_35620342/article/details/119948989|\n|6|[Java Web面试题](https://blog.csdn.net/qq_35620342/article/details/119642114)|https://blog.csdn.net/qq_35620342/article/details/119642114|\n|7|[Spring面试题](https://blog.csdn.net/qq_35620342/article/details/119956512)|https://blog.csdn.net/qq_35620342/article/details/119956512|\n|8|[Spring MVC面试题](https://blog.csdn.net/qq_35620342/article/details/119965560)|https://blog.csdn.net/qq_35620342/article/details/119965560|\n|9|[Spring Boot面试题](https://blog.csdn.net/qq_35620342/article/details/120333717)|https://blog.csdn.net/qq_35620342/article/details/120333717|\n|10|[MyBatis面试题](https://blog.csdn.net/qq_35620342/article/details/119956541)|https://blog.csdn.net/qq_35620342/article/details/119956541|\n|11|Spring Cloud面试题|待分享|\n|12|[Redis面试题](https://blog.csdn.net/qq_35620342/article/details/119575020)|https://blog.csdn.net/qq_35620342/article/details/119575020|\n|13|[MySQL数据库面试题](https://blog.csdn.net/qq_35620342/article/details/119930887)|https://blog.csdn.net/qq_35620342/article/details/119930887|\n|14|RabbitMQ面试题|待分享|\n|15|Dubbo面试题|待分享|\n|16|Linux面试题|待分享|\n|17|Tomcat面试题|待分享|\n|18|ZooKeeper面试题|待分享|\n|19|Netty面试题|待分享|\n|20|数据结构与算法面试题|待分享|\n\n# 1.什么是 Spring Boot？\n\nSpring Boot （Boot 顾名思义，是引导的意思）框架是用于简化 Spring 应用从搭建到开发的过程。应用开箱即用，只要通过一个指令，包括命令行 java -jar 、SpringApplication 应用启动类 、 Spring Boot Maven 插件等，就可以启动应用了。另外，Spring Boot 强调只需要很少的配置文件，所以在开发生产级 Spring 应用中，让开发变得更加高效和简易。目前，Spring Boot 版本是 2.x 版本。\n\n# 2.Spring Boot 有哪些优点？\n\nSpring Boot 主要有如下优点：\n- 简化Spring初始搭建以及开发过程，在短时间内快速构建项目\n- SpringBoot集成了大量的常用第三方库，例如Redis、Mongodb、JPA等，编码非常简单\n- SpringBoot提供了丰富的starter，集成主流的开源产品，只需要少量配置或零配置即可\n- SpringBoot内嵌了容器，通过简单命令就可以启动\n\n# 3.为什么要用SpringBoot？\n- 为了解决java开发中的，繁多的配置、底下的开发效率，复杂的部署流程，和第三方技术集成难度大的问题，产生了SpringBoot。\n- SpringBoot 使用 “习惯优于配置”的理念让项目快速运行起来，使用SpringBoot很容易创建一个独立运行的jar，内嵌servlet容器\n- SpringBoot的核心功能一：独立运行Spring项目，SpringBoot可以以jar包的形式独立运行，运行一个SpringBoot项目只需要 java -jar xxx.jar 来运行\n- SpringBoot的核心功能二：内嵌servlet容器，可以内嵌tomcat，接天jetty，或者undertow，这样我们就可以不用war包形式部署项目\n- SpringBoot的核心功能三，提供starter简化maven配置，spring提供了一系列starter pom 来简化maven的依赖加载， 当使用了 spring-boot-starter-web时，会自动加载所需要的依赖包\n- SpringBoot的核心功能四：自动配置spring，springboot 会根据在类路径的jar包，类，为jar包中的类自动配置bean，这样会极大的减少使用的配置，会根据启动类所在的目录，自动配置bean\n\n# 4.Starter 组件\nStarter 是一组惯例依赖描述资源，可以包含在应用中。从 starter 中，您可以获得所需的所有 Spring 和相关技术的一站式支持，无须通过示例代码和复制粘贴来获取依赖。比如，如果您要使用 Spring 和 JPA 进行数据库访问，那么只需要在项目中包含 spring-boot-starter-data-jpa 依赖项即可。\n\nstarter 包含了许多您需要用于使项目快速启动和运行，并且需要一组受支持的可传递依赖关系的依赖。\n\n官方的所有 starter 都遵循类似的命名规则：spring-boot-starter-*，其中 * 是特定类型的应用。这个命名结构旨在帮助您找到 starter。许多 IDE 中 Maven 集成允许您按名称搜索依赖。例如，安装了 Eclipse 或者 STS 插件后，您可以简单地在 POM 编辑器中按下 ctrl-space 并输入 spring-boot-starter 来获取完整的列表。\n\n正如创建自己的 starter 章节所述，第三方的 starter 命名不应该以 spring-boot 开头，因为它是官方 Spring Boot 构件所保留的规则。例如，有一个第三方 starter 项目叫做 thirdpartyproject，它通常会命名为 thirdpartyproject-spring-boot-starter。\n\nSpring Boot 在 org.springframework.boot group 下提供了以下应用 starter：\n| 名称 | 描述 | POM |\n| --- | --- | --- |\n| spring-boot-starter | 核心 starter，包含自动配置支持、日志和 YAML | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter/pom.xml) |\n| spring-boot-starter-activemq | 提供 JMS 消息支持，使用 Apache ActiveMQ | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-activemq/pom.xml) |\n| spring-boot-starter-amqp | 提供 Spring AMQP 与 Rabbit MQ 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-amqp/pom.xml) |\n| spring-boot-starter-aop | 提供 Spring AOP 与 AspectJ 面向切面编程支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-aop/pom.xml) |\n| spring-boot-starter-artemis | 提供 JMS 消息服务支持，使用 Apache Artemis | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-artemis/pom.xml) |\n| spring-boot-starter-batch | 提供 Spring Batch 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-batch/pom.xml) |\n| spring-boot-starter-cache | 提供 Spring Framework 缓存支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-cache/pom.xml) |\n| spring-boot-starter-cloud-connectors | 使用 Spring Cloud Connectors 简单连接到类似 Cloud Foundry 和 Heroku 等云平台 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-cloud-connectors/pom.xml) |\n| spring-boot-starter-data-cassandra | 提供对 Cassandra 分布式数据库和 Spring Data Cassandra 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-cassandra/pom.xml) |\n| spring-boot-starter-data-cassandra-reactive | 提供对 Cassandra 分布式数据库和 Spring Data Cassandra Reactive 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-cassandra-reactive/pom.xml) |\n| spring-boot-starter-data-couchbase | 提供对 Couchbase 面向文档数据库和 Spring Data Couchbase 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-couchbase/pom.xml) |\n| spring-boot-starter-data-couchbase-reactive | 提供对 Couchbase 面向文档数据库和 Spring Data Couchbase Reactive 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-couchbase-reactive/pom.xml) |\n| spring-boot-starter-data-elasticsearch | 提供对 Elasticseach 搜索与分析引擎和 Spring Data Elasticsearch 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-elasticsearch/pom.xml) |\n| spring-boot-starter-data-jpa | 提供 Spring Data JPA 与 Hibernate 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-jpa/pom.xml) |\n| spring-boot-starter-data-ldap | 提供对 Spring Data LDAP 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-ldap/pom.xml) |\n| spring-boot-starter-data-mongodb | 提供对 MongoDB 面向文档数据库和 Spring Data MongoDB 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-mongodb/pom.xml) |\n| spring-boot-starter-data-mongodb-reactive | 提供对 MongoDB 面向文档数据库和 Spring Data MongoDB Reactive 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-mongodb-reactive/pom.xml) |\n| spring-boot-starter-data-neo4j | 提供对 Neo4j 图数据库与 SPring Data Neo4j 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-neo4j/pom.xml) |\n| spring-boot-starter-data-redis | 提供对 Redis 键值数据存储、Spring Data Redis 和 Lettuce 客户端的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-redis/pom.xml) |\n| spring-boot-starter-data-redis-reactive | 提供对 Redis 键值数据存储、Spring Data Redis Reactive 和 Lettuce 客户端的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-redis-reactive/pom.xml) |\n| spring-boot-starter-data-rest | 提供使用 Spring Data REST 通过 REST 暴露 Spring Data 资源库的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-rest/pom.xml) |\n| spring-boot-starter-data-solr | 提供对 Apache Solr 搜索平台与 Spring Data Solr 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-data-solr/pom.xml) |\n| spring-boot-starter-freemarker | 提供使用 Freemakrer 视图构建 MVC web 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-freemarker/pom.xml) |\n| spring-boot-starter-groovy-templates | 提供使用 Groovy 模板视图构建 MVC web 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-groovy-templates/pom.xml) |\n| spring-boot-starter-hateoas | 提供使用 Spring MVC 与Spring HATEOAS 构建基于超媒体的 RESTful web 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-hateoas/pom.xml) |\n| spring-boot-starter-integration | 提供对 Spring Integration 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-integration/pom.xml) |\n| spring-boot-starter-jdbc | 提供 JDBC 与 Tomcat JDBC 连接池的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jdbc/pom.xml) |\n| spring-boot-starter-jersey | 提供对使用 JAX-RS 与 Jersey 构建 RESTful web 应用的支持。[spring-boot-starter-web](https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-web) 的替代方案 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jersey/pom.xml) |\n| spring-boot-starter-jooq | 提供对使用 JOOQ 访问 SQL 数据库的支持。[spring-boot-starter-data-jpa](https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-data-jpa) 或 [spring-boot-starter-jdbc](https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#spring-boot-starter-jdbc) 的替代方案 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jooq/pom.xml) |\n| spring-boot-starter-json | 提供了读写 json 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-json/pom.xml) |\n| spring-boot-starter-jta-atomikos | 提供 Atomikos JTA 事务支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-atomikos/pom.xml) |\n| spring-boot-starter-jta-bitronix | 提供 Bitronix JTA 事务支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-bitronix/pom.xml) |\n| spring-boot-starter-jta-narayana | 提供 Narayana JTA 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-jta-narayana/pom.xml) |\n| spring-boot-starter-mail | 提供使用　Java Mail 与 Spring Framework 的邮件发送支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-mail/pom.xml) |\n| spring-boot-starter-mustache | 提供使用 Mustache 视图构建 web 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-mustache/pom.xml) |\n| spring-boot-starter-quartz | Quartz 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-quartz/pom.xml) |\n| spring-boot-starter-security | Spring Security 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-security/pom.xml) |\n| spring-boot-starter-test | 提供包含了 JUnit、Hamcrest 与 Mockito 类库的 Spring Boot 单元测试支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-test/pom.xml) |\n| spring-boot-starter-thymeleaf | 提供使用 Thymeleaf 视图构建 MVC web 应用的支持 | [pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-thymeleaf/pom.xml) |\n| spring-boot-starter-validation | 提供 Hibernate Validator 与 Java Bean Validation 的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-validation/pom.xml) |\n| spring-boot-starter-web | 提供使用 Spring MVC 构建 web（包含 RESTful）应用的支持，使用 Tomcat 作为默认嵌入式容器 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-web/pom.xml) |\n| spring-boot-starter-web-services | Spring Web Services 支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-web-services/pom.xml) |\n| spring-boot-starter-webflux | 提供使用 Spring Framework 的 Reactive Web 支持构建 WebFlux 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-webflux/pom.xml) |\n| spring-boot-starter-websocket | 提供使用 Spring Framework 的 WebSocket 支持构建 WebSocket 应用的支持 | [Pom](https://github.com/spring-projects/spring-boot/tree/v2.0.0.RELEASE/spring-boot-project/spring-boot-starters/spring-boot-starter-websocket/pom.xml) |\n\n# 5.@SpringBootApplication 注解\n@SpringBootApplication 注解用标注启动类，被标注的类为一个配置类，并会触发自动配置和 Starter 组件扫描。根据源码可得，该注解配置了 @SpringBootConfiguration、 @EnableAutoConfiguration 和 @ComponentScan 三个注解， @SpringBootConfiguration 注解又配置了 @EnableAutoConfiguration 。所以该注解的职责相当于结合了@Configuration, @EnableAutoConfiguration 和 @ComponentScan 三个注解功能。\n\n@SpringBootApplication 注解的职责如下：\n- 在被该注解修饰的类中，可以用 @Bean 注解来配置多个 Bean 。应用启动时，Spring 容器会加载 Bean 并注入到 Spring 容器。\n- 启动 Spring 上下文的自动配置。基于依赖和定义的 Bean 会自动配置需要的 Bean 和类。\n- 扫描被 @Configuration 修饰的配置类。也会扫描 Starter 组件的配置类，并启动加载其默认配置。\n\n# 6.SpringApplication 类\n大多数情况下，在 main 方法中调用 SpringApplication 类的静态方法 run(Class, String[]) ，用来引导启动 Spring 应用程序。默认情况下，该类的职责会执行如下步骤：\n- 创建应用上下文 ApplicationContext 实例\n- 注册 CommandLinePropertySource，将命令行参数赋值到 Spring 属性\n- 刷新应用上下文，加载所有单例\n- 触发所有 CommandLineRunner Bean\n\n在实际开发中如果需要自定义创建高级的配置，可以通过 run(Class, String[]) 方法的第二个参数，并以 String 数组的形式传入。这是 run 几个重载方法的 API 文档：\n\nAPI org.springframework.boot.SpringApplication\n- static run(Class<?>[] primarySources, String[] args)\n返回正在运行的应用上下文 ApplicationContext\n\n	参数：\n	primarySources 应用指定的主要类源，数组形式\n	args 应用参数\n\n- static run(Class<?> primarySource, String... args)\n返回正在运行的应用上下文 ApplicationContext\n\n	参数：\n	primarySource 应用指定的主要类源\n	args 应用参数\n\n- run(String... args)\n返回正在运行的应用上下文 ApplicationContext\n\n	参数：\n	args 应用参数\n\n# 7.JavaConfig\nSpring JavaConfig 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯Java 方法。因此它有助于避免使用 XML 配置。使用 JavaConfig 的优点在于：\n\n（1）面向对象的配置。由于配置被定义为 JavaConfig 中的类，因此用户可以充分利用 Java 中的面向对象功能。一个配置类可以继承另一个，重写它的@Bean 方法等。\n\n（2）减少或消除 XML 配置。基于依赖注入原则的外化配置的好处已被证明。但是，许多开发人员不希望在 XML 和 Java 之间来回切换。JavaConfig 为开发人员提供了一种纯 Java 方法来配置与 XML 配置概念相似的 Spring 容器。从技术角度来讲，只使用 JavaConfig 配置类来配置容器是可行的，但实际上很多人认为将JavaConfig 与 XML 混合匹配是理想的。\n\n（3）类型安全和重构友好。JavaConfig 提供了一种类型安全的方法来配置 Spring容器。由于 Java 5.0 对泛型的支持，现在可以按类型而不是按名称检索 bean，不需要任何强制转换或基于字符串的查找。\n\n# 8.Spring Boot 自动配置原理\n\n注解 @EnableAutoConfiguration, @Configuration, @ConditionalOnClass 就是自动配置的核心，\n\n@EnableAutoConfiguration 给容器导入META-INF/spring.factories 里定义的自动配置类。\n\n筛选有效的自动配置类。\n\n每一个自动配置类结合对应的 xxxProperties.java 读取配置文件进行自动配置功能\n\n# 9.Spring Boot 配置加载顺序\n使用 Spring Boot 会涉及到各种各样的配置，如开发、测试、线上就至少 3 套配置信息了。Spring Boot 可以轻松的帮助我们使用相同的代码就能使开发、测试、线上环境使用不同的配置。\n\n在 Spring Boot 里面，可以使用以下几种方式来加载配置。本章内容基于 Spring Boot 2.0 进行详解。\n\n1、properties文件；\n\n2、YAML文件；\n\n3、系统环境变量；\n\n4、命令行参数；\n\n等等……\n\n配置属性加载的顺序如下：\n```\n1、开发者工具 Devtools 全局配置参数；\n\n2、单元测试上的 @TestPropertySource 注解指定的参数；\n\n3、单元测试上的 @SpringBootTest 注解指定的参数；\n\n4、命令行指定的参数，如 java -jar springboot.jar --name=\"Java程序鱼\"；\n\n5、命令行中的 SPRING_APPLICATION_JSONJSON 指定参数, 如 java -Dspring.application.json=\'{\"name\":\"Java技术栈\"}\' -jar springboot.jar\n\n6、ServletConfig 初始化参数；\n\n7、ServletContext 初始化参数；\n\n8、JNDI参数（如 java:comp/env/spring.application.json）；\n\n9、Java系统参数（来源：System.getProperties()）；\n\n10、操作系统环境变量参数；\n\n11、RandomValuePropertySource 随机数，仅匹配：ramdom.*；\n\n12、JAR包外面的配置文件参数（application-{profile}.properties（YAML））\n\n13、JAR包里面的配置文件参数（application-{profile}.properties（YAML））\n\n14、JAR包外面的配置文件参数（application.properties（YAML））\n\n15、JAR包里面的配置文件参数（application.properties（YAML））\n\n16、@Configuration配置文件上 @PropertySource 注解加载的参数；\n\n17、默认参数（通过 SpringApplication.setDefaultProperties 指定）；\n```\n> 数字小的优先级越高，即数字小的会覆盖数字大的参数值，我们来实践下，验证以上配置参数的加载顺序。\n\n（1）在主应用程序中添加 Java 系统参数。\n\n```java\n@Bean\npublic CommandLineRunner commandLineRunner() {\n    return (args) -> {\n        System.setProperty(\"name\", \"javastack-system-properties\");\n    };\n}\n```\n（2）在 application.properties 文件中添加属性。\n```java\nname = javastack-application\n```\n\n（3）在 application-dev.properties 文件中添加属性。\n```\nname = javastack-application-dev\n```\n\n（4）添加测试类\n```java\n@RunWith(SpringRunner.class)\n@SpringBootTest(value = { \"name=javastack-test\", \"sex=1\" })\n@ActiveProfiles(\"dev\")\npublic class SpringBootBestPracticeApplicationTests {\n\n    @Value(\"${name}\")\n    private String name;\n\n    @Test\n    public void test() {\n        System.out.println(\"name is \" + name);\n    }\n\n}\n```\n运行 test 单元测试，程序输出：\n```\nname is javastack-test\n```\n根据以上参数动态调整，发现参数会被正确被覆盖。了解了 Spring Boot 各种配置的加载顺序，如果配置被覆盖了我们就知道是什么问题了。\n\n\n# 10.什么是 YAML？\n\nYAML 是一种人类可读的数据序列化语言。它通常用于配置文件。与属性文件相比，如果我们想要在配置文件中添加复杂的属性，YAML 文件就更加结构化，而且更少混淆。可以看出 YAML 具有分层配置数据。\n\n# 11.YAML 配置的优势\n\nYAML 现在可以算是非常流行的一种配置文件格式了，无论是前端还是后端，都可以见到 YAML 配置。那么 YAML 配置和传统的 properties 配置相比到底有哪些优势呢？\n\n- 配置有序，在一些特殊的场景下，配置有序很关键\n- 支持数组，数组中的元素可以是基本数据类型也可以是对象\n- 简洁\n\n相比 properties 配置文件，YAML 还有一个缺点，就是不支持 @PropertySource 注解导入自定义的 YAML 配置。\n\n# 12.Spring Boot 是否可以使用 XML 配置 ?\n\nSpring Boot 推荐使用 Java 配置而非 XML 配置，如果您一定要使用基于 XML 的配置，可以使用 @ImportResource 注解来加载 XML 配置文件。\n\n# 13.bootstrap & application\n用过 Spring Boot 的都知道在 Spring Boot 中有以下两种配置文件\nbootstrap (.yml 或者 .properties)\napplication (.yml 或者 .properties)\n\n为什么会有这两种配置文件呢？大家都清楚它们的区别和具体使用场景吗？\n\nbootstrap/ application 的区别：Spring Cloud 构建于 Spring Boot 之上，在 Spring Boot 中有两种上下文，一种是 bootstrap, 另外一种是 application, bootstrap 是应用程序的父上下文，也就是说 bootstrap 加载优先于 applicaton。bootstrap 主要用于从额外的资源来加载配置信息，还可以在本地外部配置文件中解密属性。这两个上下文共用一个环境，它是任何Spring应用程序的外部属性的来源。bootstrap 里面的属性会优先加载，它们默认也不能被本地相同配置覆盖。\n\n因此，对比 application 配置文件，bootstrap 配置文件具有以下几个特性。\n- boostrap 由父 ApplicationContext 加载，比 applicaton 优先加载\n- boostrap 里面的属性不能被覆盖\n\nbootstrap/ application 的应用场景：application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置。\n\nbootstrap 配置文件有以下几个应用场景：\n- 使用 Spring Cloud Config 配置中心时，这时需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息；\n- 一些固定的不能被覆盖的属性\n- 一些加密/解密的场景；\n\n# 14.Profile 多环境配置\n当应用程序需要部署到不同运行环境时，一些配置细节通常会有所不同，最简单的比如日志，生产日志会将日志级别设置为WARN或更高级别，并将日志写入日志文件，而开发的时候需要日志级别为DEBUG，日志输出到控制台即可。\n\n如果按照以前的做法，就是每次发布的时候替换掉配置文件，这样太麻烦了，Spring Boot的Profile就给我们提供了解决方案，命令带上参数就搞定。\n\n这里我们来模拟一下，只是简单的修改端口来测试\n\n在Spring Boot中多环境配置文件名需要满足application-{profile}.properties的格式，其中{profile}对应你的环境标识，比如：\n- application-dev.properties：开发环境\n- application-prod.properties：生产环境\n\n想要使用对应的环境，只需要在application.properties中使用`spring.profiles.active`属性来设置，值对应上面提到的{profile}，这里就是指dev、prod这2个。\n\n当然你也可以用命令行启动的时候带上参数：\n```\njava -jar xxx.jar --spring.profiles.active=dev\n```\n\n我给不同的环境添加不同的端口属性server.port，然后根据指定不同的spring.profiles.active来切换使用。各位可以自己试试。这里就不贴代码了。\n\n除了可以用profile的配置文件来分区配置我们的环境变量，在代码里，我们还可以直接用@Profile注解来进行配置，例如数据库配置，这里我们先定义一个接口\n```java\npublic  interface DBConnector { public  void  configure(); }\n```\n\n分别定义俩个实现类来实现它\n```java\n/**\n  * 测试数据库\n  */\n@Component\n@Profile(\"testdb\")\npublic class TestDBConnector implements DBConnector {\n    @Override\n    public void configure() {\n        System.out.println(\"testdb\");\n    }\n}\n/**\n * 生产数据库\n */\n@Component\n@Profile(\"devdb\")\npublic class DevDBConnector implements DBConnector {\n    @Override\n    public void configure() {\n        System.out.println(\"devdb\");\n    }\n}\n```\n\n通过在配置文件激活具体使用哪个实现类\n```\nspring.profiles.active=testdb\n```\n\n然后就可以这么用了\n```java\n@RestController\n@RequestMapping(\"/task\")\npublic class TaskController {\n\n    @Autowired DBConnector connector ;\n\n    @RequestMapping(value = {\"/\",\"\"})\n    public String hellTask(){\n\n        connector.configure(); //最终打印testdb     \n        return \"hello task !! myage is \" + myage;\n    }\n}\n```\n除了spring.profiles.active来激活一个或者多个profile之外，还可以用spring.profiles.include来叠加profile\n```\nspring.profiles.active: testdb  \nspring.profiles.include: proddb,prodmq\n```\n\n# 15.如何实现 Spring Boot 应用程序的安全性？\n默认情况下，如果 Spring Security 在 classpath 上，则 Web 应用程序是受保护的。Spring Boot 依赖 Spring Security 的内容协商策略来确定是使用 httpBasic 还是 formLogin。要给 Web 应用程序添加方法级别的安全保护，可以使用 @EnableGlobalMethodSecurity 注解设置。有关更多其他信息，您可以在[Spring Security 参考指南](https://docs.spring.io/spring-security/site/docs/5.1.2.RELEASE/reference/htmlsingle/#jc-method)中找到。\n\n默认的 UserDetailsS​​ervice 只有一个用户。用户名为 user，密码是随机的，在应用程序启动时会以 INFO 级别打印出来，如下所示：\n```\nUsing generated security password: 0ce03db6-5884-b28a-655b-53849950aedd\n```\n\n> 如果您对日志配置进行微调，请确保将 org.springframework.boot.autoconfigure.security 的级别设置为 INFO。否则，默认密码不会打印出来。\n\n您可以通过提供 spring.security.user.name 和 spring.security.user.password 来更改用户名和密码。\n\n您在 Web 应用程序中默认会获得以下基本功能：\n- 一个 UserDetailsS​​ervice（或 WebFlux 应用程序中的 ReactiveUserDetailsS​​ervice）bean，采用内存存储形式，有一个自动生成密码的用户（有关用户属性，请参阅 SecurityProperties.User）。\n- 用于整个应用程序（如果 actuator 在 classpath 上，则包括 actuator 端点）基于表单登录或 HTTP Basic 认证（取决于 Content-Type）。\n- 一个用于发布身份验证事件的 DefaultAuthenticationEventPublisher。\n\n您可以通过为其添加一个 bean 来提供不同的 AuthenticationEventPublisher。\n\n# 16.Spring Boot 中如何解决跨域问题 ?\n跨域资源共享（Cross-origin resource sharing，CORS）是大多数浏览器实现的一个 W3C 规范，其可允许您以灵活的方式指定何种跨域请求可以被授权，而不是使用一些不太安全和不太强大的方式（比如 IFRAME 或者 JSONP）。\n\nSpring MVC 从 4.2 版本起开始支持 CORS。您可在 Spring Boot 应用程序中使用 @CrossOrigin 注解配置控制器方法启用 CORS。\n```java\n@RestController\n@RequestMapping(\"/account\")\npublic class AccountController {\n\n    @CrossOrigin\n    @GetMapping(\"/{id}\")\n    public Account retrieve(@PathVariable Long id) {\n        // ...\n    }\n\n    @DeleteMapping(\"/{id}\")\n    public void remove(@PathVariable Long id) {\n        // ...\n    }\n}\n```\n默认情况下，@CrossOrigin允许：\n- 所有origins\n- 所有headers\n\n还可以通过注册一个 WebMvcConfigurer bean 并自定义 addCorsMappings(CorsRegistry) 方法来定义全局 CORS 配置：\n\n```java\n@Configuration\n@EnableWebMvc\npublic class WebConfig implements WebMvcConfigurer {\n\n    @Override\n    public void addCorsMappings(CorsRegistry registry) {\n\n        registry.addMapping(\"/api/**\")\n            .allowedOrigins(\"http://domain2.com\")\n            .allowedMethods(\"PUT\", \"DELETE\")\n            .allowedHeaders(\"header1\", \"header2\", \"header3\")\n            .exposedHeaders(\"header1\", \"header2\")\n            .allowCredentials(true).maxAge(3600);\n\n        // Add more mappings...\n    }\n}\n```\n\n# 17.前后端分离，如何维护Rest API接口文档 ?\n前后端分离开发日益流行，大部分情况下，我们都是通过 Spring Boot 做前后端分离开发，前后端分离一定会有接口文档，不然会前后端会深深陷入到扯皮中。一个比较笨的方法就是使用 word 或者 md 来维护接口文档，但是效率太低，接口一变，所有人手上的文档都得变。在 Spring Boot 中，这个问题常见的解决方案是 Swagger ，使用 Swagger 我们可以快速生成一个接口文档网站，接口一旦发生变化，文档就会自动更新，所有开发工程师访问这一个在线网站就可以获取到最新的接口文档，非常方便。\n\n# 18.什么是 CSRF 攻击？\n\nCSRF 代表跨站请求伪造。这是一种攻击，迫使最终用户在当前通过身份验证的Web 应用程序上执行不需要的操作。CSRF 攻击专门针对状态改变请求，而不是数据窃取，因为攻击者无法查看对伪造请求的响应。\n\n由于 Spring Boot 依赖 Spring Security 的默认值配置，因此默认情况下会启用 CSRF 保护。这意味着当使用默认安全配置时，需要 POST（shutdown 和 loggers 端点）、PUT 或 DELETE 的 actuator 端点将返回 403 禁止访问错误。\n\n> 我们建议仅在创建非浏览器客户端使用的服务时才完全禁用 CSRF 保护。\n\n有关 CSRF 保护的其他信息，请参阅[Spring Security 参考指南](https://docs.spring.io/spring-security/site/docs/5.1.2.RELEASE/reference/htmlsingle/#csrf) 。\n\n# 19.Spring Boot 中的监视器是什么？\n\nSpring boot actuator 是 spring 启动框架中的重要功能之一。Spring boot 监视器可帮助您访问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器模块公开了一组可直接作为 HTTP URL 访问的REST 端点来检查状态。\n\n# 20.Actuator 安全\n\n出于安全考虑，默认情况下禁用除 /health 和 /info 之外的所有 actuator。可用 management.endpoints.web.exposure.include 属性启用 actuator。\n\n如果 Spring Security 位于 classpath 上且没有其他 WebSecurityConfigurerAdapter，则除了 /health 和 /info 之外的所有 actuator 都由 Spring Boot 自动配置保护。如果您定义了自定义 WebSecurityConfigurerAdapter，则 Spring Boot 自动配置将不再生效，您可以完全控制 actuator 的访问规则。\n\n> 在设置 management.endpoints.web.exposure.include 之前，请确保暴露的 actuator 没有包含敏感信息和 / 或被防火墙保护亦或受 Spring Security 之类的保护。\n\n# 20.我们如何监视所有 Spring Boot 微服务？\n\nSpring Boot 提供监视器端点以监控各个微服务的度量。这些端点对于获取有关应用程序的信息（如它们是否已启动）以及它们的组件（如数据库等）是否正常运行很有帮助。但是，使用监视器的一个主要缺点或困难是，我们必须单独打开应用程序的知识点以了解其状态或健康状况。想象一下涉及 50 个应用程序的微服务，管理员将不得不击中所有 50 个应用程序的执行终端。为了帮助我们处理这种情况，我们将使用位于的开源项目。 它建立在 Spring Boot Actuator 之上，它提供了一个 Web UI，使我们能够可视化多个应用程序的度量。\n\n# 21.什么是 WebSockets？\n\nWebSocket 是一种计算机通信协议，通过单个 TCP 连接提供全双工通信信道。\n\n- WebSocket 是双向的 -使用 WebSocket 客户端或服务器可以发起消息发送。\n- WebSocket 是全双工的 -客户端和服务器通信是相互独立的。\n- 单个 TCP 连接 -初始连接使用 HTTP，然后将此连接升级到基于套接字的连接。然后这个单一连接用于所有未来的通信\n- Light -与 http 相比，WebSocket 消息数据交换要轻得多。\n\n# 22.什么是 Spring Data ?\n\nSpring Data 是 Spring 的一个子项目。用于简化数据库访问，支持NoSQL 和 关系数据存储。其主要目标是使数据库的访问变得方便快捷。Spring Data 具有如下特点：\n\nSpringData 项目支持 NoSQL 存储：\n\n- MongoDB （文档数据库）\n- Neo4j（图形数据库）\n- Redis（键/值存储）\n- Hbase（列族数据库）\n\nSpringData 项目所支持的关系数据存储技术：\n\n- JDBC\n- JPA\n\nSpring Data Jpa 致力于减少数据访问层 (DAO) 的开发量. 开发者唯一要做的，就是声明持久层的接口，其他都交给 Spring Data JPA 来帮你完成！Spring Data JPA 通过规范方法的名字，根据符合规范的名字来确定方法需要实现什么样的逻辑。\n\n# 23.什么是 Spring Batch？\n\nSpring Batch 作为 Spring 的子项目，是一款基于 Spring 的企业批处理框架。通过它可以构建出健壮的企业批处理应用。Spring Batch 不仅提供了统一的读写接口、丰富的任务处理方式、灵活的事务管理及并发处理，同时还支持日志、监控、任务重启与跳过等特性，大大简化了批处理应用开发，将开发人员从复杂的任务配置管理过程中解放出来，使他们可以更多地去关注核心的业务处理过程。\n\n# 24.模板引擎\n\n除了 REST web 服务之外，您还可以使用 Spring MVC 来服务动态 HTML 内容。Spring MVC 支持多种模板技术，包括 Thymeleaf、FreeMarker 和 JSP。当然，许多其他模板引擎也有自己的 Spring MVC 集成。\n\nSpring Boot 包含了以下的模板引擎的自动配置支持：\n- FreeMarker\n- Groovy\n- Thymeleaf\n- Mustache\n\n> 如果可以，请尽量避免使用 JSP，当使用了内嵌 servlet 容器，会有几个已知限制。\n\n当运行使用了内嵌 servlet 容器的 Spring Boot 应用程序时（打包为可执行归档文件），JSP 支持将存在一些限制。\n- 如果您使用 war 打包，在 Jetty 和 Tomcat 中可以正常工作，使用 java -jar 启动时，可执行的 war 可正常使用，并且还可以部署到任何标准容器。使用可执行 jar 时不支持 JSP。\n- Undertow 不支持 JSP。\n- 创建自定义的 error.jsp 页面不会覆盖默认错误处理视图，应该使用自定义错误页面来代替。\n\n当您使用这些模板引擎的其中一个并附带了默认配置时，您的模板将从 src/main/resources/templates 自动获取。\n\n> IntelliJ IDEA 根据您运行应用程序的方式来对 classpath 进行不同的排序。在 IDE 中通过 main 方法来运行应用程序将导致与使用 Maven 或 Gradle 或来以 jar 包方式引用程序的排序有所不同，可能会导致 Spring Boot 找不到 classpath 中的模板。如果您碰到到此问题，可以重新排序 IDE 的 classpath 来放置模块的 classes 和 resources 到首位。或者，您可以配置模板前缀来搜索 classpath 中的每一个 templates 目录，比如：classpath*:/templates/。\n\n\n\n# 25.ActiveMQ 支持\n\n当 ActiveMQ 在 classpath 上可用时，Spring Boot 也可以配置一个 ConnectionFactory。如果 broker 存在，则会自动启动并配置一个内嵌式 broker（前提是未通过配置指定 broder URL）。\n\n> 如果使用 spring-boot-starter-activemq，则提供了连接到 ActiveMQ 实例必须依赖或内嵌一个 ActiveMQ 实例，以及与 JMS 集成的 Spring 基础设施。\n\nActiveMQ 配置由 spring.activemq.* 中的外部配置属性控制。例如，您可以在 application.properties 中声明以下部分：\n```\nspring.activemq.broker-url=tcp://192.168.1.210:9876\nspring.activemq.user=admin\nspring.activemq.password=secret\n```\n默认情况下，CachingConnectionFactory 将原生的 ConnectionFactory 使用可由 spring.jms.* 中的外部配置属性控制的合理设置包装起来：\n```\nspring.jms.cache.session-cache-size=5\n```\n如果您更愿意使用原生池，则可以通过向 org.messaginghub:pooled-jms 添加一个依赖并相应地配置 JmsPoolConnectionFactory 来实现，如下所示：\n```\nspring.activemq.pool.enabled=true\nspring.activemq.pool.max-connections=50\n```\n> 有关更多支持的选项，请参阅 [ActiveMQProperties](https://github.com/spring-projects/spring-boot/blob/v2.1.1.RELEASE/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jms/activemq/ActiveMQProperties.java)。您还可以注册多个实现了 ActiveMQConnectionFactoryCustomizer 的的 bean，以进行更高级的自定义。\n\n默认情况下，ActiveMQ 会创建一个 destination（目标）（如果它尚不存在），以便根据提供的名称解析 destination。\n\n# 26.Kafka 支持\n\n通过提供 spring-kafka 项目的自动配置来支持 Apache Kafka。\n\nKafka 配置由 spring.kafka.* 中的外部配置属性控制。例如，您可以在 application.properties 中声明以下部分：\n```\nspring.kafka.bootstrap-servers=localhost:9092\nspring.kafka.consumer.group-id=myGroup\n```\n> 要在启动时创建主题（topic），请添加 NewTopic 类型的 Bean。如果主题已存在，则忽略该 bean。\n\n有关更多支持的选项，请参阅 [KafkaProperties](https://github.com/spring-projects/spring-boot/blob/v2.1.1.RELEASE/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/kafka/KafkaProperties.java)。\n\n# 27.Spring Boot项目如何热部署？\n\n这可以使用 DEV 工具来实现。通过这种依赖关系，您可以节省任何更改，嵌入式tomcat 将重新启动。Spring Boot 有一个开发工具（DevTools）模块，它有助于提高开发人员的生产力。Java 开发人员面临的一个主要挑战是将文件更改自动部署到服务器并自动重启服务器。开发人员可以重新加载 Spring Boot 上的更改，而无需重新启动服务器。这将消除每次手动部署更改的需要。Spring Boot 在发布它的第一个版本时没有这个功能。这是开发人员最需要的功能。DevTools 模块完全满足开发人员的需求。该模块将在生产环境中被禁用。它还提供 H2 数据库控制台以更好地测试应用程序。\n\n```\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-devtools</artifactId>\n</dependency>\n\n```\n\n# 28.Maven\nMaven 用户可以继承 spring-boot-starter-parent 项目以获取合适的默认值，父项目提供了以下功能：\n- Java 1.8 作为默认编译器级别。\n- 源代码使用 UTF-8 编码。\n- 依赖管理部分继承自 spring-boot-dependencies 的 POM，允许您省略常见依赖的 <version> 标签。\n合理的资源过滤。\n- 合适的插件配置（exec plugin、Git commit ID、shade）。\n- 针对 application.properties 和 application.yml 资源的合理过滤，包括特定 profile 的文件（例如 application-foo.properties 和 application-foo.yml）\n> 由于 application.properties 和 application.yml 文件接受 Spring 风格的占位符（${​...}），因此 Maven 过滤改为使用 @..@ 占位符（您可以使用 Maven 的 resource.delimiter 属性重写它）\n\n## 继承 Starter Parent\n要将项目配置继承 spring-boot-starter-parent，只需要按以下方式设置 parent：\n```\n<!-- 从 Spring Boot 继承默认配置 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.0.0.RELEASE</version>\n</parent>\n```\n> 您只需要在此依赖上指定 Spring Boot 的版本号。如果您要导入其它 starter，则可以放心地省略版本号。\n\n通过该设置，您还可以重写自己项目中的配置属性来覆盖个别依赖。例如，要升级到另一个 Spring Data 发行版本，您需要将以下内容添加到 pom.xml 文件中。\n```\n<properties>\n    <spring-data-releasetrain.version>Fowler-SR2</spring-data-releasetrain.version>\n</properties>\n```\n\n## 不使用父 POM\n不是每个人都喜欢从 spring-boot-starter-parent 继承 POM。您可能需要使用自己公司标准的父 POM，或者您可能只是希望明确地声明所有 Maven 配置。\n\n如果您不想使用 spring-boot-starter-parent，则仍然可以通过使用 scope=import 依赖来获得依赖管理（但不是插件管理）的好处：\n```\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <!-- 从 Spring Boot 导入依赖管理 -->\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-dependencies</artifactId>\n            <version>2.0.0.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n如上所述，上述示例设置不会让您使用属性来覆盖个别依赖。要达到相同的目的，需要在 spring-boot-dependencies 项之前在项目的 dependencyManagement 中添加一项。例如，要升级到另一个 Spring Data 发行版，您可以将以下元素添加到 pom.xml中：\n```\n<dependencyManagement>\n    <dependencies>\n        <!-- 覆盖 Spring Boot 提供的 Spring Data -->\n        <dependency>\n            <groupId>org.springframework.data</groupId>\n            <artifactId>spring-data-releasetrain</artifactId>\n            <version>Fowler-SR2</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-dependencies</artifactId>\n            <version>2.0.0.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n> 以上示例中，我们指定了一个 BOM，但是任何的依赖类型都可以用这个方法来重写。\n\n## 使用 Spring Boot Maven 插件\nSpring Boot 包括了一个 Maven 插件，它可以将项目打包成一个可执行 jar。如果要使用它，请将插件添加到您的 <plugins> 中：\n```\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n```\n> 如果您使用了 Spring Boot starter 的父 pom，则只需要添加插件。除非您要修改父级中定义的设置，否则不需要进行配置。\n\n\n# 29.Spring Boot 打成的 jar 和普通的 jar 有什么区别 ?\n\nSpring Boot 项目最终打包成的 jar 是可执行 jar ，这种 jar 可以直接通过 `java -jar xxx.jar` 命令来运行，这种 jar 不可以作为普通的 jar 被其他项目依赖，即使依赖了也无法使用其中的类。\n\nSpring Boot 的 jar 无法被其他项目依赖，主要还是他和普通 jar 的结构不同。普通的 jar 包，解压后直接就是包名，包里就是我们的代码，而 Spring Boot 打包成的可执行 jar 解压后，在 `\\BOOT-INF\\classes` 目录下才是我们的代码，因此无法被直接引用。如果非要引用，可以在 pom.xml 文件中增加配置，将 Spring Boot 项目打包成两个 jar ，一个可执行，一个可引用。\n\n# 30.运行 Spring Boot 有哪几种方式？\n\n- 打包用命令或者放到容器中运行\n\n- 用 Maven/ Gradle 插件运行\n\n- 直接执行 main 方法运行\n\n# 31.Spring Boot 需要独立的容器运行吗？\n\n可以不需要，Spring Boot 包含了对内嵌 Tomcat、Jetty 和 Undertow 服务器的支持。大部分开发人员只需简单地使用对应的 Starter 来获取完整的配置实例。默认情况下，内嵌服务器将监听 8080 上的 HTTP 请求。\n\n> 如果您选择在 CentOS 使用 Tomcat，请注意，默认情况下，临时目录用于储存编译后的 JSP、上传的文件等。当您的应用程序运行时发生了故障，该目录可能会被 tmpwatch 删除。为了避免出现该情况，您可能需要自定义 tmpwatch 配置，使 tomcat.*目录不被删除，或者配置 server.tomcat.basedir 让 Tomcat 使用其他位置。\n\n# 32.开启 Spring Boot 特性有哪几种方式？\n\n1）继承spring-boot-starter-parent项目\n\n2）导入spring-boot-dependencies项目依赖\n\n# 33.如何使用 Spring Boot 实现异常处理？\n\n默认情况下，Spring Boot 提供了一个使用了比较合理的方式来处理所有错误的 /error 映射，其在 servlet 容器中注册了一个全局错误页面。对于机器客户端而言，它将产生一个包含错误、HTTP 状态和异常消息的 JSON 响应。对于浏览器客户端而言，将以 HTML 格式呈现相同数据的 whitelabel 错误视图（可添加一个解析到 error 的 View 进行自定义）。要完全替换默认行为，您可以实现 ErrorController 并注册该类型的 bean，或者简单地添加一个类型为 ErrorAttributes 的 bean 来替换内容，但继续使用现用机制。\n\n> BasicErrorController 可以作为自定义 ErrorController 的基类，这非常有用，尤其是在您想添加一个新的内容类型（默认专门处理 text/html，并为其他内容提供后备）处理器的情况下。要做到这点，您只需要继承 BasicErrorController 并添加一个带有 produces 属性的 @RequestMapping 注解的公共方法，之后创建一个新类型的 bean。\n\n您还可以定义一个带有 @ControllerAdvice 注解的类来自定义为特定控制器或异常类型返回的 JSON 文档：\n```java\n@ControllerAdvice(basePackageClasses = AcmeController.class)\npublic class AcmeControllerAdvice extends ResponseEntityExceptionHandler {\n\n    @ExceptionHandler(YourException.class)\n    @ResponseBody\n    ResponseEntity<?> handleControllerException(HttpServletRequest request, Throwable ex) {\n        HttpStatus status = getStatus(request);\n        return new ResponseEntity<>(new CustomErrorType(status.value(), ex.getMessage()), status);\n    }\n\n    private HttpStatus getStatus(HttpServletRequest request) {\n        Integer statusCode = (Integer) request.getAttribute(\"javax.servlet.error.status_code\");\n        if (statusCode == null) {\n            return HttpStatus.INTERNAL_SERVER_ERROR;\n        }\n        return HttpStatus.valueOf(statusCode);\n    }\n\n}\n```\n以上示例中，如果同包下定义的控制器 AcmeController 抛出了 YourException，则将使用 CustomerErrorType 类型的 POJO 来代替 ErrorAttributes 做 JSON 呈现。\n\n## 自定义错误页面\n如果您想在自定义的 HTML 错误页面上显示给定的状态码，请将文件添加到 /error 文件夹中。错误页面可以是静态 HTML（添加在任意静态资源文件夹下) 或者使用模板构建。文件的名称应该是确切的状态码或者一个序列掩码。\n\n例如，要将 404 映射到一个静态 HTML 文件，文件夹结构可以如下：\n```\nsrc/\n +- main/\n     +- java/\n     |   + <source code>\n     +- resources/\n         +- public/\n             +- error/\n             |   +- 404.html\n             +- <other public assets>\n```\n使用 FreeMarker 模板来映射所有 5xx 错误，文件夹的结构如下：\n```\nsrc/\n +- main/\n     +- java/\n     |   + <source code>\n     +- resources/\n         +- templates/\n             +- error/\n             |   +- 5xx.ftl\n             +- <other templates>\n```\n对于更复杂的映射，您还通过可以添加实现了 ErrorViewResolver 接口的 bean 来处理：\n```\npublic class MyErrorViewResolver implements ErrorViewResolver {\n\n    @Override\n    public ModelAndView resolveErrorView(HttpServletRequest request,\n            HttpStatus status, Map<String, Object> model) {\n        // Use the request or status to optionally return a ModelAndView\n        return ...\n    }\n\n}\n```\n您还可以使用常规的 Spring MVC 功能，比如 @ExceptionHandler 方法和 @ControllerAdvice。之后，ErrorController 将能接收任何未处理的异常。\n\n## 映射到 Spring MVC 之外的错误页面\n对于不使用 Spring MVC 的应用程序，您可以使用 ErrorPageRegistrar 接口来直接注册 ErrorPages。抽象部分直接与底层的内嵌 servlet 容器一起工作，即使您没有 Spring MVC DispatcherServlet 也能使用。\n\n```java\n@Bean\npublic ErrorPageRegistrar errorPageRegistrar(){\n    return new MyErrorPageRegistrar();\n}\n\n// ...\n\nprivate static class MyErrorPageRegistrar implements ErrorPageRegistrar {\n\n    @Override\n    public void registerErrorPages(ErrorPageRegistry registry) {\n        registry.addErrorPages(new ErrorPage(HttpStatus.BAD_REQUEST, \"/400\"));\n    }\n\n}\n```\n> 如果您注册了一个 ErrorPage，它的路径最终由一个 Filter（例如，像一些非 Spring web 框架一样，比如 Jersey 和 Wicket）处理，则必须将 Filter 显式注册为一个 ERROR dispatcher，如下示例：\n```java\n@Bean\npublic FilterRegistrationBean myFilter() {\n    FilterRegistrationBean registration = new FilterRegistrationBean();\n    registration.setFilter(new MyFilter());\n    ...\n    registration.setDispatcherTypes(EnumSet.allOf(DispatcherType.class));\n    return registration;\n}\n```\n请注意，默认的 FilterRegistrationBean 不包含 ERROR 调度器（dispatcher）类型。\n\n当部署到 servlet 容器时，Spring Boot 使用其错误页面过滤器会将有错误状态的请求转发到相应的错误页面。如果尚未提交响应，则只能将请求转发到正确的错误页面。默认情况下，WebSphere Application Server 8.0 及更高版本在成功完成 servlet 的 service 方法后提交响应。您应该将 com.ibm.ws.webcontainer.invokeFlushAfterService 设置为 false 来禁用此行为。\n\n# 34.Spring Boot 中如何实现定时任务 ?\n\n定时任务也是一个常见的需求，Spring Boot 中对于定时任务的支持主要还是来自 Spring 框架。\n\n在 Spring Boot 中使用定时任务主要有两种不同的方式，一个就是使用 Spring 中的 @Scheduled 注解，另一个则是使用第三方框架 Quartz。\n\n使用 Spring 中的 @Scheduled 的方式主要通过 @Scheduled 注解来实现。\n\n使用 Quartz ，则按照 Quartz 的方式，定义 Job 和 Trigger 即可。', 2, '面试题专栏', 'SpringBoot,Spring', 1, 0, 0, 0, '2021-09-29 18:22:54', '2021-09-29 18:22:54');
INSERT INTO `tb_blog` VALUES (6, '我把问烂了的⭐SpringMVC面试题⭐总结了一下（带答案，万字总结，精心打磨，建议收藏）', 'springmvc_interview', 'http://localhost:8888/upload/20210929_18235973.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容| 链接地址|\n|--|--|--|\n|  1| [Java基础知识面试题](https://blog.csdn.net/qq_35620342/article/details/119636436) |https://blog.csdn.net/qq_35620342/article/details/119636436|\n|2|[Java集合容器面试题](https://blog.csdn.net/qq_35620342/article/details/119947254)|https://blog.csdn.net/qq_35620342/article/details/119947254|\n|3|[Java并发编程面试题](https://blog.csdn.net/qq_35620342/article/details/119977224)|https://blog.csdn.net/qq_35620342/article/details/119977224|\n|4|[Java异常面试题](https://blog.csdn.net/qq_35620342/article/details/119977051)|https://blog.csdn.net/qq_35620342/article/details/119977051|\n|5|[JVM面试题](https://blog.csdn.net/qq_35620342/article/details/119948989)|https://blog.csdn.net/qq_35620342/article/details/119948989|\n|6|[Java Web面试题](https://blog.csdn.net/qq_35620342/article/details/119642114)|https://blog.csdn.net/qq_35620342/article/details/119642114|\n|7|[Spring面试题](https://blog.csdn.net/qq_35620342/article/details/119956512)|https://blog.csdn.net/qq_35620342/article/details/119956512|\n|8|[Spring MVC面试题](https://blog.csdn.net/qq_35620342/article/details/119965560)|https://blog.csdn.net/qq_35620342/article/details/119965560|\n|9|[Spring Boot面试题](https://blog.csdn.net/qq_35620342/article/details/120333717)|https://blog.csdn.net/qq_35620342/article/details/120333717|\n|10|[MyBatis面试题](https://blog.csdn.net/qq_35620342/article/details/119956541)|https://blog.csdn.net/qq_35620342/article/details/119956541|\n|11|Spring Cloud面试题|待分享|\n|12|[Redis面试题](https://blog.csdn.net/qq_35620342/article/details/119575020)|https://blog.csdn.net/qq_35620342/article/details/119575020|\n|13|[MySQL数据库面试题](https://blog.csdn.net/qq_35620342/article/details/119930887)|https://blog.csdn.net/qq_35620342/article/details/119930887|\n|14|RabbitMQ面试题|待分享|\n|15|Dubbo面试题|待分享|\n|16|Linux面试题|待分享|\n|17|Tomcat面试题|待分享|\n|18|ZooKeeper面试题|待分享|\n|19|Netty面试题|待分享|\n|20|数据结构与算法面试题|待分享|\n\n# 1.什么是Spring MVC？\nSpring MVC是一种基于Java的实现了MVC设计模式的请求驱动类型的轻量级Web框架，使用MVC架构模式的思想，将web层进行职责解耦，把复杂的web应用分成逻辑清晰的几部分，简化我们日常开发，减少出错，方便组内开发人员之间的配合。\n\n# 2.Spring MVC的优点\n\n（1）可以支持各种视图技术,而不仅仅局限于JSP；\n\n（2）与Spring框架集成（如IoC容器、AOP等）；\n\n（3）清晰的角色分配：前端控制器(dispatcherServlet) , 请求到处理器映射（handlerMapping), 处理器适配器（HandlerAdapter), 视图解析器（ViewResolver）。\n\n（4） 支持各种请求资源的映射策略。\n\n# 3.Spring MVC关键组件？\n- 前端控制器：DispatcherServlet（不需要程序员开发）,由框架提供，在web.xml中配置。\n作用：接收请求，响应结果，相当于转发器，中央处理器。\n- 处理器映射器：HandlerMapping(不需要程序员开发),由框架提供。\n作用：根据请求的url查找Handler(处理器/Controller)，可以通过XML和注解方式来映射。\n- 处理器适配器：HandlerAdapter(不需要程序员开发),由框架提供。\n作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler。\n- 处理器：Handler(也称之为Controller，需要工程师开发)。\n注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler。\n作用：接受用户请求信息，调用业务方法处理请求，也称之为后端控制器。\n- 视图解析器：ViewResolver(不需要程序员开发)，由框架提供。\n作用：进行视图解析，把逻辑视图名解析成真正的物理视图。\n- 视图：View(需要前端工程师开发)。\n作用：把数据展现给用户的页面，View是一个接口，实现类支持不同的View技术（Jsp、Freemarker、Pdf等）\n\n# 4.什么是DispatcherServlet？\n\nSpring的MVC框架是围绕DispatcherServlet来设计的，它用来处理所有的HTTP请求和响应。\n\n# 5.什么是Spring MVC框架的控制器？\n\n控制器提供一个访问应用程序的行为，此行为通常通过服务接口实现。控制器解析用户输入并将其转换为一个由视图呈现给用户的模型。Spring用一个非常抽象的方式实现了一个控制层，允许用户创建多种用途的控制器。\n\n# 6.Spring MVC的控制器是不是单例模式,如果是,有什么问题,怎么解决？\n\n答：是单例模式,所以在多线程访问的时候有线程安全问题,不要用同步,会影响性能的,解决方案是在控制器里面不能写字段。\n\n# 7.Spring MVC的工作流程？\n![在这里插入图片描述](https://img-blog.csdnimg.cn/62dfd96281244e27852b60204852fc2f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n①用户发送请求到服务器，如果路径和我们配置的前端控制器映射路径匹配，服务器就将请求转交给前端控制器处理。\n② DispatcherServlet收到请求调用HandlerMapping处理器映射器（定义了请求到处理器之间的映射）（其实最后用的是RequestMappingHandlerMapping，他是HandlerMapping子类的实现，HandlerMapping有个抽象方法getHandler，可以获取处理器调用链）。\n③ 处理器映射器根据请求url找到具体的处理器，生成处理器对象及跟这个处理器相关的拦截器(二者组成HandlerExecutionChain处理器调用链 ),并将其一并返回给DispatcherServlet。 \n④DispatcherServlet通过HandlerAdapter处理器适配器（表单数据类型的校验、数据类型的转换都是处理器适配器做的，最终他会调用目标方法）调用处理器 。\n理解：DispatcherServlet通过HandlerAdapter处理器适配器（表单数据类型的校验、数据类型的转换都是处理器适配器做的，最终他会调用目标方法）调用处理器。\n⑤执行处理器(也就是Controller，也叫后端控制器)。 \n⑥Controller执行完成返回ModelAndView。\n⑦HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。\n⑧DispatcherServlet(调用处理视图方法，如果有异常就用异常解析器处理HandlerExceptionResolver，若没异常进行渲染视图)将ModelAndView传给ViewReslover视图解析器。\n⑨ViewReslover解析后返回具体View。\n⑩DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。 \n⑪DispatcherServlet对用户进行响应。\n\n# 8.MVC是什么？MVC设计模式的好处有哪些\n三层架构：\n1）界面层，用于显示数据和接收用户输入的数据，为用户提供一种交互式操作的界面\n2）业务逻辑层，它的关注点主要集中在业务规则的制定、业务流程的实现等与业务需求有关的系统设计\n3）数据访问层，其功能主要是负责数据库的访问\n\nMVC架构：\n1）Model：模型，将传输数据封装成一个完整的载体（Model）\n2）View：视图，html、jsp等\n3）Controller：控制器\n\n两者区别：\n很多人容易把三层模式与MVC模式混淆，三层与MVC的最不同的地方在于三层是没有Controller控制器的概念。虽然同样是架构级别的，三层与MVC相同的地方在于他们都有一个表现层，但是他们不同的地方在于其他的两个层。MVC没有把业务的逻辑访问看成两个层，这是采用三层架构或MVC搭建程序最主要的区别。当然了，在三层中也提到了Model概念，但是三层架构中Model的概念与MVC中Model的概念是不一样的，“三层” 中典型的Model层是以实体类构成的，而MVC里，则是由业务逻辑与访问数据组成的。\n\nMVC设计模式的好处\n- 分层设计，实现了业务系统各个组件之间的解耦，有利于业务系统的可扩展性，可维护性。\n- 有利于系统的并行开发，提升开发效率。\n\n# 9.注解原理是什么?\n\n注解本质是一个继承了Annotation的特殊接口，其具体实现类是Java运行时生成的动态代理类。我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象。通过代理对象调用自定义注解的方法，会最终调用AnnotationInvocationHandler的invoke方法。该方法会从memberValues这个Map中索引出对应的值。而memberValues的来源是Java常量池。\n\n# 10.Spring MVC常用的注解有哪些？\n@RequestMapping：是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。\n\n@RequestBody：注解实现接收http请求的json数据，将json转换为java对象。\n\n@ResponseBody：注解实现将conreoller方法返回对象转化为json对象响应给客户。\n\n# 12.@Controller注解的作用\n\n在Spring MVC 中，控制器Controller 负责处理由DispatcherServlet 分发的请求，它把用户请求的数据经过业务处理层处理之后封装成一个Model ，然后再把该Model 返回给对应的View 进行展示。在Spring MVC 中提供了一个非常简便的定义Controller 的方法，你无需继承特定的类或实现特定的接口，只需使用@Controller 标记一个类是Controller ，然后使用@RequestMapping 和@RequestParam 等一些注解用以定义URL 请求和Controller 方法之间的映射，这样的Controller 就能被外界访问到。此外Controller 不会直接依赖于HttpServletRequest 和HttpServletResponse 等HttpServlet 对象，它们可以通过Controller 的方法参数灵活的获取到。\n\n@Controller 用于标记在一个类上，使用它标记的类就是一个Spring MVC Controller 对象。分发处理器将会扫描使用了该注解的类的方法，并检测该方法是否使用了@RequestMapping 注解。@Controller 只是定义了一个控制器类，而使用@RequestMapping 注解的方法才是真正处理请求的处理器。单单使用@Controller 标记在一个类上还不能真正意义上的说它就是Spring MVC 的一个控制器类，因为这个时候Spring 还不认识它。那么要如何做Spring 才能认识它呢？这个时候就需要我们把这个控制器类交给Spring 来管理。有两种方式：\n\n*   在Spring MVC 的配置文件中定义MyController 的bean 对象。\n*   在Spring MVC 的配置文件中告诉Spring 该到哪里去找标记为@Controller 的Controller 控制器。\n\n# 13.@RequestMapping注解的作用\n@RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。\n\n@RequestMapping常用属性\n（1）value属性\n\n指定控制器的方法URI\n\n```java\n@Controller\n@RequestMapping(\"/hello\")\npublic class HelloController{\n    @RequestMapping(\"/hello.do\")\n    public void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n        response.getWriter().write(\"www.baidu.com\");\n    }\n}\n```\n如果类和方法上都指定value值，那么方法的最终方法路径为：http://localhost:8080/hello/hello.do \n\n（2）method属性\n\n 指定请求的method类型，可以接受GET,POST,PUT,DELETE等\n\n```java\n@RequestMapping(value = \"/hello.do\",method = RequestMethod.GET)\npublic void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n     response.getWriter().write(\"www.baidu.com\");\n}\n```\n（3）consumes、produces属性\n\nconsumes：指定处理请求的提交内容类型（Content-Type），例如application/json, text/html;\nproduces：指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回。\n\n```java\n@RequestMapping(value = \"/hello.do\",consumes = \"application/json\",produces = \"application/json\")\npublic void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n    response.getWriter().write(\"www.baidu.com\");\n}\n```\n（4）params、headers属性\n\nparams：指定request中必须包含某些参数值，才让该方法处理。\nheaders：指定request中必须包含某些指定的header值，才能让该方法处理请求。\n\nparams示例：\n```java\n@RequestMapping(value = \"/hello.do\",params = \"id=10\")\npublic void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n   response.getWriter().write(\"www.baidu.com\");\n}\n```\n\nheaders示例：\n```java\n@RequestMapping(value = \"/hello.do\",headers = \"Referer=http://www.baidu.com/\")\npublic void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n   response.getWriter().write(\"www.baidu.com\");\n}\n```\n\n\n# 14.@ResponseBody注解的作用\n\n作用： 该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区。\n\n使用时机：返回的数据不是html标签的页面，而是其他某种格式的数据时（如json、xml等）使用；\n\n# 15.@PathVariable和@RequestParam的区别\n\n@PathVariable是spring3.0的一个新功能：接收请求路径中占位符的值\n```java\n@Controller\n@RequestMapping(\"hello\")\npublic class HelloController {\n    /**\n     * 占位符映射\n     * 语法：@RequestMapping(value= user/{userId}/{userName}”)\n     * 请求路径：http://localhost:8080/hello/show/1/world\n     * @param id\n     * @param name\n     * @return\n     */\n    @RequestMapping(\"show/{id}/{name}\")\n    public ModelAndView test(@PathVariable(\"id\") Long id ,@PathVariable(\"name\") String name){\n        ModelAndView mv = new ModelAndView();\n        mv.addObject(\"msg\",\"占位符映射：id:\"+id+\";name:\"+name);\n        mv.setViewName(\"hello\");\n        return mv;\n    }\n}\n```\n\n@RequestParam：将请求参数绑定到你控制器的方法参数上（是SpringMVC中接收普通参数的注解）\n```java\n@Controller\n@RequestMapping(\"hello\")\npublic class HelloController {\n \n    /**\n     * 接收普通请求参数\n     * http://localhost:8080/hello/show?name=hello\n     * url参数中的name必须要和@RequestParam(\"name\")一致\n     * @return\n     */\n    @RequestMapping(\"show\")\n    public ModelAndView test(@RequestParam(\"name\")String name){\n        ModelAndView mv = new ModelAndView();\n        mv.setViewName(\"hello\");\n        mv.addObject(\"msg\", \"接收普通的请求参数：\" + name);\n        return mv;\n    }\n}\n```\n\n# 16.Spring MVC与Struts2区别\n- Struts2是类级别的拦截， 一个类对应一个request上下文，SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应,所以说从架构本身上SpringMVC就容易实现restful url,而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。\n\n- 由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量，而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码 读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。\n\n- 由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。\n\n-  拦截器实现机制上，Struts2有以自己的interceptor机制，SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。\n\n- SpringMVC的入口是servlet，而Struts2是filter（这里要指出，filter和servlet是不同的。以前认为filter是servlet的一种特殊），这就导致了二者的机制不同，这里就牵涉到servlet和filter的区别了。\n\n- SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可，而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。\n\n- SpringMVC验证支持JSR303，处理起来相对更加灵活方便，而Struts2验证比较繁琐，感觉太烦乱。\n\n- Spring MVC和Spring是无缝的。从这个项目的管理和安全上也比Struts2高（当然Struts2也可以通过不同的目录结构和相关配置做到SpringMVC一样的效果，但是需要xml配置的地方不少）。\n\n- 设计思想上，Struts2更加符合OOP的编程思想， SpringMVC就比较谨慎，在servlet上扩展。\n\n- SpringMVC开发效率和性能高于Struts2。\n- SpringMVC可以认为已经100%零配置。\n\n# 17.Spring MVC怎么样设定重定向和转发的？\n```java\n/**\n * 实现转发\n */\n@RequestMapping(\"/hello1.action\")\npublic String hello1(HttpServletRequest request){\n    request.setAttribute(\"name\", \"cjj\");\n    return \"forward:hello.action\";\n}\n\n/**\n * 实现重定向\n */\n@RequestMapping(\"/hello2.action\")\npublic String hello2(HttpServletRequest request){\n    request.setAttribute(\"name\", \"cjj\");\n    return \"redirect:/hello.action\";\n}\n```\n\n# 18.Spring MVC Post中文乱码\n在Spring MVC表单如果是Post方法提交中文内容时，会出现乱码，效果如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/d3826cc3356148ffaada9652e5f8e0a0.png)\n\n这时我们可以配置Spring MVC提供字符编码过滤器来解决问题。\n```xml\n<!--字符编码过滤器-->\n<filter>\n	<filter-name>characterEncodingFilter</filter-name>\n	<filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n	<init-param>\n		<!--指定转换的编码-->\n		<param-name>encoding</param-name>\n		<param-value>UTF-8</param-value>\n	</init-param>\n</filter>\n<filter-mapping>\n	<filter-name>characterEncodingFilter</filter-name>\n	<url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n注意：要记得加上encoding参数，并设置为UTF-8\n\n# 19.Spring MVC 异常处理机制\n在控制器的方法发生异常后，默认情况会显示Tomcat的500页面，这种用户体验并不好。如果我们在每个控制器方法自行捕获异常，显然又太繁琐。有没有好的异常处理办法呢？有的，就是Spring MVC的全局异常处理机制。Spring MVC提供了两种全局异常处理机制：\n- 定义异常类，实现HandlerExceptionResolver接口\n- 定义异常类，使用@ControllerAdvice+@ExceptionHandler注解\n\n下面看看实现步骤。\n\n（1）编写控制器，模拟异常\n```java\n@Controller\npublic class HelloController {\n\n    @RequestMapping(\"/hello\")\n    public String upload(HttpSession session, HttpServletResponse response) throws Exception {\n        //模拟异常\n        int i = 100/0;\n        return \"success\";\n    }\n}\n```\n（2）编写全局异常处理类\n\n全局异常类编写方式一\n```java\n/**\n * 方式一：自定义异常处理类\n */\npublic class MyCustomException1 implements HandlerExceptionResolver{\n    @Override\n    public ModelAndView resolveException(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) {\n        ModelAndView mv = new ModelAndView();\n        mv.addObject(\"errorMsg\",e.getMessage());\n        mv.setViewName(\"error\");\n        return mv;\n    }\n}\n```\n这种写法，我们需要实现HandlerExceptionResolver接口，然后实现resolveException方法，编写处理异常逻辑。\n\n全局异常类编写方式二\n```java\n/**\n * 方式二：自定义异常处理类\n */\n@ControllerAdvice\npublic class MyCustomException2{\n\n    @ExceptionHandler\n    public ModelAndView handlerError(Exception e){\n        ModelAndView mv = new ModelAndView();\n        mv.setViewName(\"error\");\n        mv.addObject(\"errorMsg\",e.getMessage());\n        return mv;\n    }\n\n}\n```\n第二种写法，直接在类上使用@ControllerAdvice，在异常处理方法上添加@ExceptionHandler注解。这种做法底层是AOP思想。\n\n（3）配置全局异常处理类\n方式一：\n```xml\n<!--创建自定义异常处理对象-->\n<bean class=\"com.exception.MyCustomException1\"/>\n```\n方式二：\n```xml\n<!--创建自定义异常处理对象-->\n<bean class=\"com.exception.MyCustomException2\"/>\n```\n（4）运行测试\n\n访问控制器方法，发生异常后经过全局异常处理类，跳转到error.jsp页面\n![在这里插入图片描述](https://img-blog.csdnimg.cn/de705423d6fa4238a9ce05b5180cb39d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n# 20.如果在拦截请求中，我想拦截get方式提交的方法,怎么配置?\n\n```java\n@RequestMapping(value = \"/hello.do\",method = RequestMethod.GET)\npublic void hello(HttpServletRequest request,HttpServletResponse response) throws IOException {\n     response.getWriter().write(\"www.baidu.com\");\n}\n```\n\n# 21.怎样在方法里面得到Request,或者Session？\n```java\n@Controller\npublic class TestController {\n	// Spring MVC会把request、session对象传入\n    @RequestMapping(\"/test\")\n    public void test(HttpServletRequest request,HttpSession session) {\n        ......\n    }\n}\n```\n\n# 22.请求参数接收\nSpring MVC支持对多种类型的请求参数进行封装\n- 基本类型\n- Pojo对象类型\n- 包装Pojo对象类型\n- List集合类型\n- Map集合类型\n\n## 基本参数类型\n\n（1）设计表单页面\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n</head>\n<body>\n<h2>基本类型参数封装</h2>\n<form action=\"/param.do\">\n    用户名：<input type=\"text\" name=\"name\"><br>\n    年龄：<input type=\"text\" name=\"age\"><br>\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n\n（2）编写控制器接收参数\n```java\n@Controller\npublic class ParamController {\n\n    @RequestMapping(\"/param.do\")\n    public String save(@RequestParam(\"name\") String name,\n                       @RequestParam(\"age\") Integer age){\n        System.out.println(\"用户名：\"+name);\n        System.out.println(\"年龄：\"+age);\n        return \"success\";\n    }\n}\n```\n\n这里要注意的是，控制器接收参数的形参名称必须和表单的name属性保持一致，否则会接收失败！\n\n（3）springmvc.xml配置\n```xml\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1.扫描Controller的包-->\n    <context:component-scan base-package=\"com.controller\"/>\n\n    <!-- 2.配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 2.1 页面前缀 -->\n        <property name=\"prefix\" value=\"/pages/\"/>\n        <!-- 2.2 页面后缀 -->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!-- 3.创建处理器适配器和处理器映射器-->\n    <mvc:annotation-driven/>\n</beans>\n```\n\n## Pojo参数封装\n之前我们接收参数的时候都是定义一个个的基本类型来接收，这样比较繁琐，Spring MVC提供了使用Pojo（或者称为JavaBean）类型来封装请求参数。\n\n（1）设计表单\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n</head>\n<body>\n<h2>Pojo类型参数封装</h2>\n<form action=\"/param.do\" method=\"post\">\n    用户名：<input type=\"text\" name=\"username\"><br>\n    年龄：<input type=\"text\" name=\"age\"><br>\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n（2）设计User对象封装表单数据\n```java\n/**\n * 用于封装表单数据\n */\npublic class User {\n    private String name;\n    private Integer age;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", age=\" + age +\n                \'}\';\n    }\n}\n```\n\n（3）编写Controller\n```java\n@Controller\npublic class ParamController {\n\n    @RequestMapping(\"/param.do\")\n    public String save(User user){\n        System.out.println(\"用户名：\"+user.getName());\n        System.out.println(\"年龄：\"+user.getAge());\n        return \"success\";\n    }\n}\n```\n\n（4）springmvc.xml配置\n```html\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1.扫描Controller的包-->\n    <context:component-scan base-package=\"com.controller\"/>\n\n    <!-- 2.配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 2.1 页面前缀 -->\n        <property name=\"prefix\" value=\"/pages/\"/>\n        <!-- 2.2 页面后缀 -->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!-- 3.创建处理器适配器和处理器映射器-->\n    <mvc:annotation-driven/>\n</beans>\n```\n\n## 包装Pojo对象类型\n在Spring MVC的应用过程中，我们在后端经过需要将表单数据封装在一个包装Pojo类型中，所谓包装Pojo类型，就是Pojo对象中包含另一个Pojo对象，如下所示：\n```java\npublic class User {\n    private String username;\n    private Integer age;\n    private Address address;//封装地址信息\n}\n```\n（1）设计表单\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n</head>\n<body>\n<h2>包装Pojo类型参数封装</h2>\n<form action=\"/param.do\" method=\"post\">\n    用户名：<input type=\"text\" name=\"name\"><br>\n    年龄：<input type=\"text\" name=\"age\"><br>\n    省份：<input type=\"text\" name=\"address.province\"><br>\n    城市：<input type=\"text\" name=\"address.city\"><br>\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n注意：这里封装用户的地址信息，name为address.province这种写法，这代表把数据封装到User对象->Address对象的province属性中。\n\n（2）设计包装Pojo对象\nAddress对象：\n```java\npublic class Address {\n    private String province;\n    private String city;\n\n    public String getProvince() {\n        return province;\n    }\n    public void setProvince(String province) {\n        this.province = province;\n    }\n    public String getCity() {\n        return city;\n    }\n    public void setCity(String city) {\n        this.city = city;\n    }\n\n    @Override\n    public String toString() {\n        return \"Address{\" +\n                \"province=\'\" + province + \'\\\'\' +\n                \", city=\'\" + city + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n\nUser对象：\n```java\npublic class User {\n    private String username;\n    private Integer age;\n    private Address address;//封装地址信息\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n    \n	public Address getAddress() {\n        return address;\n    }\n\n    public void setAddress(Address address) {\n        this.address = address;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", age=\" + age +\n                \", address=\" + address +\n                \'}\';\n    }\n}\n```\n\n## List集合参数封装\n在之前Spring MVC使用包装Pojo类型一文中，我们是一个Address对象来接收一个地址信息，如果有多个地址信息怎么呢？这时我们可以使用List集合来封装。\n\n（1）设计表单\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n</head>\n<body>\n<h2>List集合类型参数封装</h2>\n<form action=\"/param.do\" method=\"post\">\n    用户名：<input type=\"text\" name=\"username\"><br>\n    年龄：<input type=\"text\" name=\"age\"><br>\n    省份1：<input type=\"text\" name=\"address[0].province\"><br>\n    城市1：<input type=\"text\" name=\"address[0].city\"><br>\n    省份2：<input type=\"text\" name=\"address[1].province\"><br>\n    城市2：<input type=\"text\" name=\"address[1].city\"><br>\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n\n注意：这里的name比较特殊：address[0].province，代表给User对象->List<Address>集合->第一个Address对象的province属性赋值\n\n（2）设计Pojo对象\n\nAddress对象：\n\n```java\npublic class Address {\n    private String province;\n    private String city;\n\n    public String getProvince() {\n        return province;\n    }\n    public void setProvince(String province) {\n        this.province = province;\n    }\n    public String getCity() {\n        return city;\n    }\n    public void setCity(String city) {\n        this.city = city;\n    }\n\n    @Override\n    public String toString() {\n        return \"Address{\" +\n                \"province=\'\" + province + \'\\\'\' +\n                \", city=\'\" + city + \'\\\'\' +\n                \'}\';\n    }\n}\n```\n\nUser对象：\n```java\npublic class User {\n    private String name;\n    private Integer age;\n\n    private List<Address> address;//这里使用List集合接收表单多个地址信息\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n    \n	public List<Address> getAddress() {\n        return address;\n    }\n    public void setAddress(List<Address> address) {\n        this.address = address;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", age=\" + age +\n                \", address=\" + address +\n                \'}\';\n    }\n\n}\n```\n（3）编写Controller\n```java\n@Controller\npublic class ParamController {\n\n    @RequestMapping(\"/param.do\")\n    public String save(User user){\n        System.out.println(\"用户名：\"+user.getUsername());\n        System.out.println(\"年龄：\"+user.getAge());\n        //遍历所有地址信息\n        for(Address addr:user.getAddress()){\n            System.out.println(addr);\n        }\n        return \"success\";\n    }\n}\n```\n\n（4）springmvc.xml配置\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1.扫描Controller的包-->\n    <context:component-scan base-package=\"com.controller\"/>\n\n    <!-- 2.配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 2.1 页面前缀 -->\n        <property name=\"prefix\" value=\"/pages/\"/>\n        <!-- 2.2 页面后缀 -->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!-- 3.创建处理器适配器和处理器映射器-->\n    <mvc:annotation-driven/>\n</beans>\n```\n\n## Spring MVC 自定义类型转换\nSpring MVC默认情况下可以对基本类型进行类型转换，例如可以将String转换为Integer,Double,Float等。但是Spring MVC并不能转换日期类型（java.util.Date），如果希望把字符串参数转换为日期类型，必须自定义类型转换器。接下来讲解如何自定义类型转换器。\n\n（1）设计表单\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n</head>\n<body>\n<h2>自定义类型转换</h2>\n<form action=\"/param.do\" method=\"post\">\n    用户名：<input type=\"text\" name=\"username\"><br>\n    生日：<input type=\"text\" name=\"birthday\"><br>\n    <input type=\"submit\" value=\"提交\">\n</form>\n</body>\n</html>\n```\n\n（2）设计Pojo\n\nUser对象：\n```java\npublic class User {\n    private String name;\n    private Date birthday;//这里接收的是java.util.Date类型\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Date getBirthday() {\n        return birthday;\n    }\n\n    public void setBirthday(Date birthday) {\n        this.birthday = birthday;\n    }\n\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"name=\'\" + name + \'\\\'\' +\n                \", birthday=\" + birthday +\n                \'}\';\n    }\n}\n```\n\n（3）编写日期类型转换器\n```java\npublic class StringToDateConverter implements Converter<String,Date>{\n    @Override\n    public Date convert(String source) {\n        Date date = null;\n        try {\n            //使用SimpleDateFormat对页面字符串日期转换为java.util.Date类型\n            date = new SimpleDateFormat(\"yyyy-MM-dd\").parse(source);\n        } catch (ParseException e) {\n            e.printStackTrace();\n        }\n        return date;\n    }\n}\n```\n注意：Spring MVC的自定义类型转换器必须实现Converter接口\n\n（4）配置自定义类型转换器\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1.扫描Controller的包-->\n    <context:component-scan base-package=\"com.controller\"/>\n\n    <!-- 2.配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 2.1 页面前缀 -->\n        <property name=\"prefix\" value=\"/pages/\"/>\n        <!-- 2.2 页面后缀 -->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!-- 3.创建处理器适配器和处理器映射器-->\n    <mvc:annotation-driven conversion-service=\"conversionService\"/>\n\n    <!--4.配置自定义类型转换器-->\n    <!--4.1 创建类型转换器对象-->\n    <bean id=\"stringToDateConverter\" class=\"com.converter.StringToDateConverter\"/>\n\n    <!--4.2 把新建的类型转换器对象加入到工厂中-->\n    <bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\">\n        <property name=\"converters\">\n            <set>\n                <ref bean=\"stringToDateConverter\"/>\n            </set>\n        </property>\n    </bean>\n</beans>\n```\n\n（5）编写Controller\n```java\n@Controller\npublic class ParamController {\n\n    @RequestMapping(\"/param.do\")\n    public String save(User user){\n        System.out.println(\"用户名：\"+user.getUsername());\n        System.out.println(\"生日：\"+user.getBirthday());\n        return \"success\";\n    }\n}\n```\n\n# 23.Spring MVC 控制器返回值\nSpring MVC的控制器方法返回值可以支持多种写法，每种写法的场景和效果都不一样。下面分别来看看每种返回值的使用。\n\n- 普通字符串\n- 转发字符串\n- 重定字符串\n- void\n- ModelAndView\n- Java对象\n- JSON数据\n\n## 普通字符串\n返回普通字符串这种情况比较常见，主要用在我们处理完业务逻辑后，需要跳转到应用的其他页面。\n\n代码示例：\n```java\n/**\n * 1)字符串 - 普通字符串（代表页面名称，不是完整路径，最后经过视图解析器的解析）\n *    优势：写法简单\n *    劣势：只能转发到视图解析器指定的特定目录\n */\n@RequestMapping(\"/string\")\npublic String string(){\n    System.out.println(\"普通字符串....\");\n    //这里返回页面名称，必须经过视图解析器解析的！！！\n    return \"index\";\n}\n```\n\n## 转发字符串\n普通字符串，只能转发到视图解析器指定前缀的目录下的页面，如果想转发到视图解析器目录以外的页面，这时可以使用转发字符串的写法。\n\n代码示例\n```java\n/**\n * 2)字符串 - 转发字符串\n *     转发字符串格式：\n *        forward:完整页面的路径      例如：forward:/pages/index.jsp\n *\n *    优势：更加灵活，可以转到本项目下的任何页面，可以传递request域对象数据\n *    劣势：写法稍复杂\n */\n@RequestMapping(\"/forward\")\npublic String forward(){\n    System.out.println(\"转发字符串....\");\n    return \"forward:/index.html\";\n}\n```\n\n## 重定向字符串\n如果希望使用重定向的方式跳转页面，这时可以使用重定向字符串完成。\n\n代码示例：\n```java\n/**\n * 3)字符串 - 重定向字符串\n *     重定向字符串格式：\n *        redirect:完整页面的路径      例如：redirect:/pages/index.jsp\n *\n *    优势：很灵活，可以重定向到项目内和项目以外的页面\n *    劣势：写法稍复杂，不能转发requesy域对象数据\n */\n@RequestMapping(\"/redirect\")\npublic String redirect(){\n    System.out.println(\"重定向字符串....\");\n    return \"redirect:http://www.baidu.com\";\n}\n```\n\n## 返回空\n一般我们在文件下载的时候，就不需要控制器方法返回任何内容，所以设置为void即可。\n\n代码示例：\n```java\n/**\n * 4）返回void\n *    用于文件下载\n */\n@RequestMapping(\"/void\")\npublic void returnVoid(HttpServletResponse response){\n    System.out.println(\"void....\");\n\n    //模拟文件下载\n    //1.读取需要下载的文件\n    File file = new File(\"e:/spring.jpg\");\n\n    //2.构建文件输入流\n    try {\n        InputStream in = new FileInputStream(file);\n\n        //3.获取文件输出流（从response对象获取）\n        OutputStream out = response.getOutputStream();\n\n        //4.边读边写\n        byte[] buf = new byte[1024];\n        int len = 0;\n\n        while( (len = in.read(buf))!=-1  ){ \n            out.write(buf,0,len);\n        }\n\n        //5.流资源关闭\n        out.close();\n        in.close();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    return;\n}\n```\n\n## ModelAndView\nSpring MVC提供了ModelAndView对象，该对象既可以存储数据到request域，也可以设置视图。其实Spring MVC任何处理器适配器最终执行完控制器后，都会返回ModelAndView对象。所以这是一个比较底层的对象。\n\n代码示例：\n```java\n/**\n * 5)ModelAndView: 封装了Model数据和视图数据的对象\n */\n@RequestMapping(\"/mv\")\npublic ModelAndView mv(){\n    ModelAndView mv = new ModelAndView();\n    //设置模型数据\n    mv.addObject(\"model\",\"一点教程网\");\n    //设置视图数据\n    mv.setViewName(\"index\");\n    return mv;\n}\n```\n\n## 返回Java对象 \n这里返回的Java对象，可能是普通JavaBean，也可以是List或Map集合等。一般希望把控制器的返回Java对象转换为Json字符串，才需要返回Java对象。\n\n## 返回JSON数据\n我们在开发中后端经常需要接受来自于前端传递的Json字符串数据，怎么把Json字符串转换为Java对象呢？后端也经常需要给前端返回Json字符串，怎么把Java对象数据转换为Json字符串返回呢？接下来我们看看如何使用@RequestBody和@ResponseBody注解。\n\n（1）导入jackson支持包\n\nSpring MVC默认是无法实现Json数据转换功能的，需要额外导入Jackson包来支持Json数据转换。\n\npom.xml配置：\n```xml\n<!-- jackson支持包 -->\n<dependency>\n  <groupId>com.fasterxml.jackson.core</groupId>\n  <artifactId>jackson-core</artifactId>\n  <version>2.9.5</version>\n</dependency>\n<dependency>\n  <groupId>com.fasterxml.jackson.core</groupId>\n  <artifactId>jackson-annotations</artifactId>\n  <version>2.9.5</version>\n</dependency>\n<dependency>\n  <groupId>com.fasterxml.jackson.core</groupId>\n  <artifactId>jackson-databind</artifactId>\n  <version>2.9.5</version>\n</dependency>\n```\n\n（2）页面传递Json到后端\n\n编写json.jsp，使用jQuery实现ajax异步请求后端Controller，同时发送Json字符串对象\n\njson.jsp内容如下：\n```html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n    <script src=\"/js/jquery-3.3.1.min.js\"></script>\n</head>\n<body>\n<script>\n    //页面加载完毕\n    $(function(){\n        //点击按钮，发送post请求，传递json参数\n        $(\"#btn\").click(function(){\n            $.ajax({\n                //设置请求类型\n                type:\'post\',\n                //请求路径\n                url:\'/json\',\n                //传递json参数\n                data: \'{\"id\":268,\"name\":\"小红\",\"age\":18}\',\n                //指定参数类型（如果json参数格式，必须设置为json类型）\n                contentType: \'application/json;charset=utf-8\',\n                //该方法接收后台返回的数据格式\n                dataType: \'json\',\n                //处理方法\n                success:function(result){\n                    alert(result.id+\'--\'+result.name+\'--\'+result.age);\n                }\n\n            });\n        });\n    });\n\n</script>\n\n<input type=\"button\" value=\"演示Json字符串与Java对象转换\" id=\"btn\">\n</body>\n</html>\n```\n\n（3）后端处理Json数据\n\n编写JsonController，这里用到两个关键注解@RequestBody和@ResponseBody。\n- @RequestBody：完成页面Json字符串转换为后端Java对象\n- @ResponseBody：完成后端Java对象转换为前端Json字符串\n\nJsonController代码如下：\n```java\n@Controller\npublic class JsonController {\n\n    /**\n     * 1) 接收前台传递json字符串格式 @RequestBody: 把json字符串转为Java对象\n     * 2) 后台Java对象转换json字符串： @ResponseBody\n     */\n    @RequestMapping(\"/json\")\n    @ResponseBody\n    public User json(@RequestBody User user){\n        System.out.println(\"前端发送的数据：\"+user);\n        //后台返回json字符串给前端\n        user.setId(368);\n        user.setName(\"小苍\");\n        user.setAge(20);\n        return user;\n    }\n}\n```\n\nUser对象：\n```java\npublic class User {\n    private Integer id;\n    private String name;\n    private Integer age;\n    public Integer getId() {\n        return id;\n    }\n\n    public void setId(Integer id) {\n        this.id = id;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n    @Override\n    public String toString() {\n        return \"User{\" +\n                \"id=\" + id +\n                \", name=\'\" + name + \'\\\'\' +\n                \", age=\" + age +\n                \'}\';\n    }\n}\n```\n\n（4）springmvc.xml配置\n```java\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\">\n\n    <!-- 1.扫描Controller的包-->\n    <context:component-scan base-package=\"com.controller\"/>\n\n    <!-- 2.配置视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <!-- 2.1 页面前缀 -->\n        <property name=\"prefix\" value=\"/pages/\"/>\n        <!-- 2.2 页面后缀 -->\n        <property name=\"suffix\" value=\".jsp\"/>\n    </bean>\n\n    <!-- 3.创建处理器适配器和处理器映射器-->\n    <mvc:annotation-driven/>\n\n    <!--静态资源处理-->\n    <mvc:default-servlet-handler/>\n</beans>\n```\n\n# 24.怎么样把ModelMap里面的数据放入Session里面？\n\n答：可以在类上面加上@SessionAttributes注解,里面包含的字符串就是要放入session里面的key。\n\n# 25.Spring MVC里面拦截器是怎么写的\n\n有两种写法,一种是实现HandlerInterceptor接口，另外一种是继承适配器类，接着在接口方法当中，实现处理逻辑；然后在Spring MVC的配置文件中配置拦截器即可：\n\n```\n\n<mvc:interceptors>\n    \n    <bean id=\"myInterceptor\" class=\"com.action.MyHandlerInterceptor\"></bean>\n    \n    <mvc:interceptor>\n       <mvc:mapping path=\"/modelMap.do\" />\n       <bean class=\"com.action.MyHandlerInterceptorAdapter\" />\n    </mvc:interceptor>\n</mvc:interceptors>\n\n```', 2, '面试题专栏', 'SpringMVC', 1, 0, 0, 0, '2021-09-29 18:24:00', '2021-09-29 18:24:00');
INSERT INTO `tb_blog` VALUES (7, 'SpringBoot 2.X 基础教程：快速入门', 'springboot1', 'http://localhost:8888/upload/20210929_18293613.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容|\n|--|--|\n|1|[面试题专栏](https://blog.csdn.net/qq_35620342/category_11278274.html)|\n|2|[Redis专栏](https://blog.csdn.net/qq_35620342/category_11257165.html)|\n| 3| [SpringBoot专栏](https://blog.csdn.net/qq_35620342/category_11374491.html) |\n| 3| [SpringBoot专栏更新计划](https://note.youdao.com/s/3kw4z10n) |\n\n# 一、简介\n如果我们需要搭建一个 Spring Web 项目的时候需要怎么做呢？\n1）配置 web.xml，加载 Spring 和 Spring mvc\n2）配置数据库连接、配置 Spring 事务\n3）配置加载配置文件的读取，开启注解\n4）配置日志文件\n…\n配置完成之后部署 Tomcat 调试\n…\n\n配置非常繁琐，如何解决呢？Spring Boot 让我们的 Spring 应用变的更轻量化。我们不必像以前那样繁琐的构建项目、打包应用、部署到 Tomcat 等应用服务器中来运行我们的业务服务。通过Spring Boot 实现的服务，只需要依靠一个 Java 类，把它打包成 jar，并通过 **java -jar** 命令就可以运行起来。这一切相较于传统Spring应用来说，已经变得非常的轻便、简单。\n\nSpring Boot 主要有如下优点：\n- 简化 Spring 初始搭建以及开发过程，在短时间内快速构建项目\n- SpringBoot 集成了大量的常用第三方库，例如Redis、Mongodb、JPA等，编码非常简单\n- SpringBoot 提供了丰富的 starter ，集成主流的开源产品，只需要少量配置或零配置即可\n- SpringBoot 内嵌了容器，通过简单命令就可以启动\n\n# 二、初始化Spring Boot项目\n构建一个Sping Boot的Maven项目，强烈推荐Spring Initializr,它从本质上来说就是一个Web应用程序，它能为你生成Spring Boot项目结构。\n\nSpring Initializr 有两种用法：\n- 使用 Spring Initializr （http://start.spring.io）页面创建\n- 使用IntelliJ IDEA创建\n\n## 1、使用Spring Initializr 页面创建\n第一步：进入 http://start.spring.io 页面\n![在这里插入图片描述](https://img-blog.csdnimg.cn/16d86b560deb4ad19efc41af72ba2db9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n本文将实现一个Http接口，所以选择了一个Web组件。\n\n第二步：点击 GENERATE 按钮，下载项目压缩包\n\n第三步：先解压缩，然后导入到工程里去\n- 菜单中选择File –> New –> Project from Existing Sources...\n![在这里插入图片描述](https://img-blog.csdnimg.cn/84eb063e9bbc4eae8ab0bc4bc6edcc8d.png)\n- 选择解压后的项目文件夹，点击OK\n- 点击 Import project from external model 并选择Maven，然后一直Next\n![在这里插入图片描述](https://img-blog.csdnimg.cn/189ea9c3bf3b4c96b62e90f0ab3d6b36.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n## 2、使用IntelliJ IDEA创建\n第一步：菜单中选择File –> New –> Project\n![在这里插入图片描述](https://img-blog.csdnimg.cn/044c834011774bfd9cbb7b2ad5936fd2.png)\n第二步：选择Spring Initializr\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2b70f2e8824646d7b3d4175eacee8e04.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/122bfb2b0d8c4e34a0264fde1c428fda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/d4c77affdcac4db4bfb915efe7506da7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n# 三、项目结构\n![在这里插入图片描述](https://img-blog.csdnimg.cn/1735ac31334b4f42acdeef49c615f726.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_14,color_FFFFFF,t_70,g_se,x_16)\n如上图所示，Spring Boot 的基础结构共三个文件:\n- <font color=\"#F7803B\"> **src/main/java** </font> 程序开发以及主程序入口\n- <font color=\"#F7803B\"> **src/main/resources** </font> 配置文件\n- <font color=\"#F7803B\"> **src/test/java** </font> 测试程序\n\n生成的Chapter1Application和Chapter1ApplicationTests类都可以直接运行来启动当前创建的项目，由于目前该项目未配合任何数据访问或Web模块，程序会在加载完Spring之后结束运行。\n\n# 四、pom.xml解析\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.5.4</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n    <groupId>com.fish</groupId>\n    <artifactId>chapter1</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>chapter1</name>\n    <description>SpringBoot第一章节</description>\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n如上所示，主要有四个部分：\n- 项目元数据：groupId、artifactId、version、name、description等\n- parent：Spring Boot 父级依赖，<font color=\"#E96900\"> **spring-boot-starter-parent** </font> 是一个特殊 Starter，它提供了有用的 Maven 默认配置。此外它还提供了依赖管理功能，您可以忽略这些依赖的版本（version）标签。\n- dependencies：项目具体依赖，这里包含了<font color=\"#E96900\"> **spring-boot-starter-web** </font>用于实现HTTP接口，<font color=\"#E96900\"> **spring-boot-starter-test** </font>用于编写单元测试的依赖包。\n- build：构建配置部分，默认使用了<font color=\"#E96900\"> **spring-boot-maven-plugin** </font>（Spring Boot Maven插件），配合 <font color=\"#E96900\"> **spring-boot-starter-parent** </font> 就可以把Spring Boot 应用打包成 JAR 来直接运行。\n\n# 五、编写一个HTTP接口\n```java\npackage com.fish.chapter1.controller;\n\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class TestController {\n  @RequestMapping(\"/test\")\n  public String test() {\n    return \"test\";\n  }\n}\n\n```\n\n# 六、配置端口号\napplication.properties文件加入下面这行配置\n```\nserver.port=8080\n```\n\n# 七、应用入口类\n```java\npackage com.fish.chapter1;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class Chapter1Application {\n\n	public static void main(String[] args) {\n		SpringApplication.run(Chapter1Application.class, args);\n	}\n\n}\n```\n@SpringBootApplication是Sprnig Boot项目的核心注解，主要目的是开启自动配置。后续讲解原理的时候再深入介绍。\n\n启动主程序，然后浏览器地址栏输入：http://localhost:8080/test，可以看到页面返回：test\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2ee9a2e6815d4408a920d683ed1fbdb9.png)\n# 八、单元测试\n```java\npackage com.fish.chapter1;\n\nimport com.fish.chapter1.controller.TestController;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.http.MediaType;\nimport org.springframework.test.context.web.WebAppConfiguration;\nimport org.springframework.test.web.servlet.MockMvc;\nimport org.springframework.test.web.servlet.request.MockMvcRequestBuilders;\nimport org.springframework.test.web.servlet.setup.MockMvcBuilders;\n\nimport static org.hamcrest.Matchers.equalTo;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.content;\nimport static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;\n\n@SpringBootTest(classes={Chapter1Application.class})\n@WebAppConfiguration\nclass Chapter1ApplicationTests {\n\n	private MockMvc mvc;\n\n	@BeforeEach\n	public void setUp() throws Exception {\n		mvc = MockMvcBuilders.standaloneSetup(new TestController()).build();\n	}\n\n	@Test\n	public void test() throws Exception {\n		mvc.perform(MockMvcRequestBuilders.get(\"/test\").accept(MediaType.APPLICATION_JSON))\n			.andExpect(status().isOk())\n			.andExpect(content().string(equalTo(\"test1\")));\n	}\n\n}\n```\n> 注意引入下面内容，让status、content、equalTo函数可用，否则会报错，提示status()、content()、equalTo()方法不存在。\n\nSpringBoot2.X 默认集成的是 JUnit5，JUnit5 中支持lambda表达式，语法简单且代码不冗余。用法和 JUnit4有些差别，如果不适应的小伙伴，可以切换到JUnit4。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2c64aaeaaef84af8bd6ba2e96ed25679.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n测试通过，如果我们把equalTo改成test1会是怎样？\n```java\n@Test\npublic void test() throws Exception {\n		mvc.perform(MockMvcRequestBuilders.get(\"/test\").accept(MediaType.APPLICATION_JSON))\n			.andExpect(status().isOk())\n			.andExpect(content().string(equalTo(\"test1\")));\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/4fae954d2df349ad85d599ee6a5d2183.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n会报错，预期值test1，实际值test。\n\n单元测试常用注解\n- @BeforeEach：在每个单元测试方法执行前都执行一遍\n- @BeforeAll：在每个单元测试方法执行前执行一遍（只执行一次）\n- @DisplayName(\"Demo测试\")：用于指定单元测试的名称\n- @Disabled：当前单元测试置为无效，即单元测试时跳过该测试\n- @RepeatedTest(n)：重复性测试，即执行n次\n- @ParameterizedTest：参数化测试，\n- @ValueSource(ints = {1, 2, 3})：参数化测试提供数据\n\n# 九、源码\n本文的相关例子可以查看下面仓库中的 <font color=\"#E96900\"><strong>chapter1</strong></font>  目录：\n\nGitee：https://gitee.com/hezhiyuan007/spring-boot-study\nGithub：https://github.com/java-fish-0907/spring-boot-study', 1, 'SpringBoot专栏', 'SpringBoot', 1, 0, 0, 0, '2021-09-29 18:29:38', '2021-09-29 18:29:38');
INSERT INTO `tb_blog` VALUES (8, 'SpringBoot2.X基础教程：配置文件详解', 'springboot2', 'http://localhost:8888/upload/20210929_18303760.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n| 序号 |  内容|\n|--|--|\n|1|[面试题专栏](https://blog.csdn.net/qq_35620342/category_11278274.html)|\n|2|[Redis专栏](https://blog.csdn.net/qq_35620342/category_11257165.html)|\n| 3| [SpringBoot专栏](https://blog.csdn.net/qq_35620342/category_11374491.html) |\n| 3| [SpringBoot专栏更新计划](https://note.youdao.com/s/3kw4z10n) |\n\n@[TOC](文章目录)\n\n</font>\n\n<hr style=\" border:solid; width:100px; height:1px;\" color=#000000 size=1\">\n\n# 一、简介\nSpring Boot 的核心是自动配置（或者叫默认配置），通过自动配置大大减少Spring项目的配置编写。但是在实际开发中，我们仍然需要根据需求来适当修改某些必要的参数配置，这时Spring Boot提供了两种格式的配置方便开发者进行修改。\n- applicaiton*.properties\n- application*.yml（或者application*.yaml）\n\n# 二、properties\n\n## 自定义属性\n我们除了可以在 Spring Boot 的配置文件中设置各个 Starter 模块中预定义的配置属性，也可以在配置文件中定义一些我们需要的自定义属性。比如在 application.properties 中添加：\n```\nblog.id=1\nblog.title=SpringBoot\nblog.author=fish\n```\n\n然后，在应用中我们可以通过@Value注解来加载这些自定义的参数，比如：\n```java\n@Data\n@Component\npublic class Blog {\n    @Value(\"${blog.id}\")\n    private Long id;\n    @Value(\"${blog.title}\")\n    private String title;\n    @Value(\"${blog.author}\")\n    private String author;\n}\n\n```\n\n大家有没有发现一个问题，如果一个对象属性太多，一个一个绑定到属性字段上是不是太麻烦，如何解决呢？\n```java\n@Data\n@Component\n@ConfigurationProperties(prefix = \"blog\")\npublic class Blog2 {\n  private Long id;\n  private String title;\n  private String author;\n}\n```\n这里配置完还需要在 Spring Boot 启动类加上@EnableConfigurationProperties 并指明要加载哪个bean\n```java\n@EnableConfigurationProperties({Blog2.class})\n@SpringBootApplication\npublic class Chapter2Application {\n\n	public static void main(String[] args) {\n		SpringApplication.run(Chapter2Application.class, args);\n	}\n\n}\n```\n\n## 参数间引用\n在application.properties中的各个参数之间也可以直接引用来使用，就像下面的设置：\n```\nblog.id=1\nblog.title=SpringBoot\nblog.author=fish\nblog.desc=${blog.author} wrote an article about ${blog.title}\n```\n\n```java\n@RestController\npublic class TestController {\n  @Autowired\n  private Blog2 blog2;\n\n  @RequestMapping(\"/test2\")\n  public String test2() {\n    return blog2.toString();\n  }\n}\n\n@Data\n@Component\n@ConfigurationProperties(prefix = \"blog\")\npublic class Blog2 {\n  private Long id;\n  private String title;\n  private String author;\n  private String desc;\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/65415da0dc8f4b659b77bbc55c968492.png)\n## 自定义配置文件地址\n有时候我们不希望把所有配置都放在 application.properties 里面，这时候我们可以另外定义一个，这里我明取名为 blog.properties ,路径跟也放在 src/main/resources 下面。\n```\ncustom.blog.id=2\ncustom.blog.title=SpringBoot custom config\ncustom.blog.author=fish\ncustom.blog.desc=${blog.author} wrote an article about ${blog.title}\n```\n\n```java\n@RestController\npublic class TestController {\n  @Autowired\n  private CustomBlog customBlog;\n\n  @RequestMapping(\"/test3\")\n  public String test3() {\n    return customBlog.toString();\n  }\n}\n\n@Data\n@Component\n@ConfigurationProperties(prefix = \"custom.blog\")\n@PropertySource(\"classpath:blog.properties\")\npublic class CustomBlog {\n  private Long id;\n  private String title;\n  private String author;\n  private String desc;\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/d986b615486849efbd1b6acbf92d4d8a.png)\n\n## 外部配置\nSpringBoot 可以使用命令 java -jar 命令来启动 SpringBoot 应用，该命令除了启动应用之外，还可以在命令行中来指定应用的参数，比如：java -jar 项目名.jar --server.port=8081，直接以命令行的方式，来设置 server.port 属性，另启动应用的端口设为 8081。\n\n可以看出，命令行中连续的两个减号--就是对application.properties中的属性值进行赋值的标识。所以java -jar 项目名.jar --server.port=8081 等价于在 application.properties 中添加属性server.port=8081。\n如果你怕命令行有风险，可以使用 SpringApplication.setAddCommandLineProperties(false) 禁用它。\n\n实际上，Spring Boot 应用程序有多种设置途径，Spring Boot 能从多重属性源获得属性，包括如下几种：\n- 在您的主目录（当 devtools 被激活，则为 ~/.spring-boot-devtools.properties）中的 Devtools 全局设置属性。\n- 在测试中使用到的 @TestPropertySource 注解。\n- 在测试中使用到的 properties 属性，可以是 @SpringBootTest 和用于测试应用程序某部分的测试注解。\n- 命令行参数。\n- 来自 SPRING_APPLICATION_JSON 的属性（嵌入在环境变量或者系统属性【system propert】中的内联 JSON）。\n- ServletConfig 初始化参数。\n- ServletContext 初始化参数。\n- 来自 java:comp/env 的 JNDI 属性。\n- Java 系统属性（System.getProperties()）。\n- 操作系统环境变量。\n- 只有 random.* 属性的 RandomValuePropertySource。\n- 在已打包的 jar 外部的指定 profile 的应用属性文件（application-{profile}.properties 和 YAML 变量）。\n- 在已打包的 jar 内部的指定 profile 的应用属性文件（application-{profile}.properties 和 YAML 变量）。\n- 在已打包的 jar 外部的应用属性文件（application.properties 和 YAML 变量）。\n- 在已打包的 jar 内部的应用属性文件（application.properties 和 YAML 变量）。\n- 在 @Configuration 类上的 @PropertySource 注解。\n- 默认属性（使用 SpringApplication.setDefaultProperties 指定）。\n\n这里列表按组优先级排序，也就是说，任何在高优先级属性源里设置的属性都会覆盖低优先级的相同属性，列如我们上面提到的命令行属性就覆盖了application.properties 的属性。\n\n> 在我平时工作中，用的比较多的方式是YAML、application.properties、jar命令行，其他的都很少用\n\n## 优先级\n我们创建一个 Spring Boot 工程时，默认 resources 目录下就有一个 application.properties 文件，可以在 application.properties 文件中进行项目配置，但是这个文件并非唯一的配置文件，在 Spring Boot 中，一共有 4 个地方可以存放 application.properties 文件。\n- 当前项目根目录下的 config 目录下\n- 当前项目的根目录下\n- resources 目录下的 config 目录下\n- resources 目录下\n\n加载优先级：当前项目根目录下的 config 目录下 > 当前项目的根目录下 > resources 目录下的 config 目录下 > resources 目录下\n\n> 也就是说，src/main/resources/config 下 application.properties 覆盖 src/main/resources 下application.properties 中相同的属性\n\n## 多环境配置\n当应用程序需要部署到不同运行环境时，一些配置细节通常会有所不同，例如日志级别、数据源、各种密码等等，如果按照以前的做法，就是每次发布的时候替换掉配置文件，这样太麻烦了，如何解决呢？\n\n在 Spring Boot 中多环境配置文件名需要满足 application-{profile}.properties 的格式，其中{profile}对应你的环境标识，比如：\n- application-dev.properties：开发环境\n- application-test.properties：测试环境\n- application-pre.properties：灰度环境\n- application-prod.properties：生产环境\n\n想要使用对应的环境，只需要在application.properties中使用spring.profiles.active属性来设置，值对应上面提到的{profile}，例如：spring.profiles.active=dev 就会加载 application-dev.properties 配置文件内容。\n\n至于哪个具体的配置文件会被加载，需要在application.properties文件中通过spring.profiles.active属性来设置，其值对应配置文件中的{profile}值。如：spring.profiles.active=test就会加载application-test.properties配置文件内容。\n\n当然您也可以用命令行启动的时候带上参数：\n```\njava -jar 项目名称.jar --spring.profiles.active=dev\n```\napplication.properties\n```\nspring.profiles.active=dev\n```\napplication-dev.properties\n```\nblog.id=3\nblog.title=SpringBoot profiles dev config\nblog.author=fish\nblog.desc=${blog.author} wrote an article about ${blog.title}\n```\n\napplication-pro.properties\n```\nblog.id=4\nblog.title=SpringBoot profiles pro config\nblog.author=fish\nblog.desc=${blog.author} wrote an article about ${blog.title}\n```\n\n```java\n@RestController\npublic class TestController {\n\n  @Autowired\n  private Blog blog;\n\n  @RequestMapping(\"/test\")\n  public String test() {\n    return blog.toString();\n  }\n}\n\n@Data\n@Component\npublic class Blog {\n    @Value(\"${blog.id}\")\n    private Long id;\n    @Value(\"${blog.title}\")\n    private String title;\n    @Value(\"${blog.author}\")\n    private String author;\n    @Value(\"${blog.desc}\")\n    private String desc;\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/c31079e485c24130a8df8f1313fbbf08.png)\n# 三、YAML\nYAML采用的配置格式不像properties的配置那样以单纯的键值对形式来表示，而是以类似大纲的缩进形式来表示。比如：下面的一段YAML配置信息\n```\nblog:\n  id: 1\n  title: SpringBoot\n  author: fish\n```\n其他知识点和 properties 几乎一样，只是配置方式稍有不同，在这里YAML的使用我就不重复阐述了。\n\n注意点：\n（1）无法使用 @PropertySource 注解加载 YAML 文件。因此，如果您需要以这种方式加载值，请使用属性文件（properties）。\n（2）SpringBoot 2.4版本之前，我们在 YAML 配置文件中，使用spring.profiles来定义不同环境的标识，而在2.4版本升级之后，我们需要将spring.profiles配置用spring.config.activate.on-profile替代。\n\n> SpringBoot 2.4 版本对配置文件加载机制做了很多变化，有兴趣的小伙伴可以去 Spring 官网查看。\n\n# 四、源码\n本文的相关例子可以查看下面仓库中的 <font color=\"#E96900\"><strong>chapter2</strong></font>  目录：\n- Gitee：https://gitee.com/hezhiyuan007/spring-boot-study\n- Github：https://github.com/java-fish-0907/spring-boot-study', 1, 'SpringBoot专栏', 'SpringBoot', 1, 0, 0, 0, '2021-09-29 18:30:39', '2021-09-29 18:30:39');
INSERT INTO `tb_blog` VALUES (9, 'SpringBoot2.X基础教程：SpringBoot整合Thymeleaf', 'springboot3', 'http://localhost:8888/upload/20210929_18314299.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n# 前言\n\n对于Web项目来说，前后端分离模式是目前最为流行的，目前前端框架非常完善，前后端分离方案也非常成熟。前后端分离可以帮助Web类产品的开发团队更好的拆分任务，以及让开发人员更加聚焦在某一端的开发技术之上。但是据我了解，小部分中小型公司的管理后台前后端是不分离的，而在前后端不分的开发中，我们就会需要用到Thymeleaf。\n\n接下来，我们就来具体讲讲在Spring Boot应用中，如何使用Thymeleaf模板引擎开发Web页面类的应用。\n\n# 一、静态文件\n当使用Spring Boot来开发一个完整的系统时，我们往往需要用到前端页面，这就不可或缺地需要访问到静态资源，比如图片、css、js等文件。\n\nSpring Boot使用 WebMvcAutoConfiguration 中的配置各种属性, 默认为我们提供了静态资源处理。如果需要特殊处理的再通过配置进行修改。\n\nSpringBoot 框架默认提供的静态资源目录的位置需放置于 classpath下，且要求了命名的规范，目录名应遵守的命名规范如下：\n- /static\n- /public\n- /resources\n- /META-INF/resources\n\n# 二、模板引擎\n除了 REST web 服务之外，您还可以使用 Spring MVC 来服务动态 HTML 内容。Spring MVC 支持多种模板技术，包括 Thymeleaf、FreeMarker 和 JSP。当然，许多其他模板引擎也有自己的 Spring MVC 集成。\n\nSpring Boot支持多种模版引擎包括：\n- FreeMarker\n- Groovy\n- Thymeleaf(官方推荐)\n- Mustache\n\nJSP技术Spring Boot官方是不推荐的，原因有四：\n- tomcat 只支持 war 的打包方式，不支持可执行的 jar。\n- Jetty 嵌套的容器不支持 jsp。\n- Undertow 不支持 JSP。\n- 创建自定义 error.jsp 页面不会覆盖错误处理的默认视图，而应该使用自定义错误页面\n\n当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径，具体如何修改，可在后续各模板引擎的配置属性中查询并修改。\n\n# 三、Thymeleaf模板引擎\n\nThymeleaf是一款用于渲染 XML/XHTML/HTML5 内容的模板引擎，适用于 Web 和独立环境的现代服务器端 Java 模板引擎，它跟 Velocity、FreeMarker 类似的模板引擎，它可以完全替代 JSP 。相较与其他的模板引擎，它有如下三个特点：\n- Thymeleaf 在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。这是由于它支持 html 原型，然后在 html 标签里增加额外的属性来达到模板+数据的展示方式。浏览器解释 html 时会忽略未定义的标签属性，所以 Thymeleaf 的模板可以静态地运行；当有数据返回到页面时，Thymeleaf 标签会动态地替换掉静态内容，使页面动态显示。\n- Thymeleaf 开箱即用的特性。它提供标准和 Spring 标准两种方言，可以直接套用模板实现 JSTL、 OGNL表达式效果，避免每天套模板、改 Jstl、改标签的困扰。同时开发人员也可以扩展和创建自定义的方言。\n- Thymeleaf 提供 Spring 标准方言和一个与 SpringMVC 完美集成的可选模块，可以快速的实现表单绑定、属性编辑器、国际化等功能。\n\n# 四、引入依赖\n```\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-thymeleaf</artifactId>\n</dependency>\n```\n\n# 五、编写controller\n在前面的几篇文章中，我们都是使用了 @RestController 来处理请求，返回的内容为 JSON 对象，那么如果需要渲染 html 页面，要如何实现呢？\n```java\n@Controller\npublic class TestController {\n\n  /**\n   * 方案一\n   * @param model\n   * @return\n   */\n  @GetMapping(\"index1\")\n  public String index(Model model) {\n    model.addAttribute(\"id\", \"1\");\n    model.addAttribute(\"title\", \"SpringBoot Thymeleaf\");\n    model.addAttribute(\"author\", \"Java程序鱼\");\n    return \"index1\";\n  }\n\n  /**\n   * 方案二\n   * @return\n   */\n  @GetMapping(\"index2\")\n  public Object index2() {\n    ModelAndView modelAndView = new ModelAndView(\"/index2\");\n\n    modelAndView.addObject(\"id\", \"2\");\n    modelAndView.addObject(\"title\", \"SpringBoot Thymeleaf2\");\n    modelAndView.addObject(\"author\", \"Java程序鱼\");\n    return modelAndView;\n  }\n\n  /**\n   * 方案三\n   * @param modelMap\n   * @return\n   */\n  @GetMapping(\"index3\")\n  public String index3(ModelMap modelMap) {\n    modelMap.addAttribute(\"id\", \"3\");\n    modelMap.addAttribute(\"title\", \"SpringBoot Thymeleaf3\");\n    modelMap.addAttribute(\"author\", \"Java程序鱼\");\n    return \"index3\";\n  }\n}\n```\n\n# 六、编写html\n在 src/main/resources/templates 下创建index1.html、index2.html、index3.html三个文件，代码都一样。\n```\n<!DOCTYPE html>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n    <title>index1</title>\n</head>\n<body>\n    <th th:text=\"${id}\">id</th>\n    <th th:text=\"${title}\">title</th>\n    <th th:text=\"${author}\">author</th>\n</body>\n</html>\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/5fae153480134fb5b526aa15dc536c3b.png)\n\n# 七、语法\n\n## th:each\nThymeleaf 中使用 th:each 来进行 for 循环遍历\n\n```java\n@Controller\npublic class BlogController {\n\n  @GetMapping(\"each\")\n  public String each(Model model) {\n    ArrayList<Blog> list = new ArrayList<>();\n    list.add(new Blog(1, \"each1\", \"java程序鱼1\"));\n    list.add(new Blog(2, \"each2\", \"java程序鱼2\"));\n    list.add(new Blog(3, \"each3\", \"java程序鱼3\"));\n\n    model.addAttribute(\"list\", list);\n    return \"each\";\n  }\n}\n```\n\n【each.html】\n```\n<body>\n	<table>\n	    <thead>\n	    <tr>\n	        <th>ID</th>\n	        <th>标题</th>\n	        <th>作者</th>\n	    </tr>\n	    </thead>\n	    <tbody>\n	    <tr th:each=\"item:${list}\">\n	        <td th:text=\"${item.id}\"></td>\n	        <td th:text=\"${item.title}\"></td>\n	        <td th:text=\"${item.author}\"></td>\n	    </tr>\n	    </tbody>\n	</table>\n</body>\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/b65703419a154a5589860873f3aafa61.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_19,color_FFFFFF,t_70,g_se,x_16)\n## th:if\nThymeleaf 中使用 th:if 和 th:unless 属性进行条件判断，th:if 是表达式中的条件成立显示内容，th:unless 是表达式中的条件不成立才显示内容。\n```java\n@Controller\npublic class BlogController {\n  @GetMapping(\"if\")\n  public String ifHtml(Model model) {\n    model.addAttribute(\"id\", 1);\n    return \"if\";\n  }\n}\n```\n【if.html】\n```\n<body>\n    <div th:if=\"${id == 1}\">th:if id==1</div>\n    <div th:if=\"${id != 1}\">th:if id!=1</div>\n\n    <div th:unless=\"${id == 1}\">th:unless id==1</div>\n    <div th:unless=\"${id != 1}\">th:unless id!=1</div>\n</body>\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/7f1d2a868f134b97a76ecf8010f757b5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_17,color_FFFFFF,t_70,g_se,x_16)\n## th:replace&th:include\nth:include，布局标签，替换内容到引入的文件\nth:replace，布局标签，替换整个标签到引入的文件\n\n我们在开发中需要把通用的部分都提取出来，例如文章的头部和底部，把文章的头部和底部弄成单独的页面，然后让其他页面包含头部和底部，这就是代码复用思维。\n\n【include.html】\n```\n<!DOCTYPE html>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Thymeleaf include</title>\n</head>\n<body>\n    <!--  语法说明  \"::\"前面是模板文件名，后面是选择器 -->\n    <div class=\"commonHead\" th:replace=\"commonHead::commonHead\"></div>\n    博客正文\n    <div class=\"commonFooter\" th:replace=\"commonFooter::commonFooter\"></div>\n</body>\n</html>\n```\n\n【commonFooter.html】\n```\n<!DOCTYPE html>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>通用代码-底部</title>\n</head>\n<body>\n    <div class=\"commonFooter\" th:fragment=\"commonFooter\">\n        博客的底部\n    </div>\n</body>\n</html>\n```\n【commonHead.html】\n```\n<!DOCTYPE html>\n<html xmlns:th=\"http://www.thymeleaf.org\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>通用代码-头部</title>\n</head>\n<body>\n    <div class=\"commonHead\" th:fragment=\"commonHead\">\n        博客的头部\n    </div>\n</body>\n</html>\n```\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/9f0f700b7a0e45d7a834620d4080c1af.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_19,color_FFFFFF,t_70,g_se,x_16)\n\n# 八、Thymeleaf的默认参数配置\n在application.properties中可以配置thymeleaf模板解析器属性\n```\n# THYMELEAF (ThymeleafAutoConfiguration)\n#开启模板缓存（默认值：true）\nspring.thymeleaf.cache=true \n#Check that the template exists before rendering it.\nspring.thymeleaf.check-template=true \n#检查模板位置是否正确（默认值:true）\nspring.thymeleaf.check-template-location=true\n#Content-Type的值（默认值：text/html）\nspring.thymeleaf.content-type=text/html\n#开启MVC Thymeleaf视图解析（默认值：true）\nspring.thymeleaf.enabled=true\n#模板编码\nspring.thymeleaf.encoding=UTF-8\n#要被排除在解析之外的视图名称列表，用逗号分隔\nspring.thymeleaf.excluded-view-names=\n#要运用于模板之上的模板模式。另见StandardTemplate-ModeHandlers(默认值：HTML5)\nspring.thymeleaf.mode=HTML5\n#在构建URL时添加到视图名称前的前缀（默认值：classpath:/templates/）\nspring.thymeleaf.prefix=classpath:/templates/\n#在构建URL时添加到视图名称后的后缀（默认值：.html）\nspring.thymeleaf.suffix=.html\n#Thymeleaf模板解析器在解析器链中的顺序。默认情况下，它排第一位。顺序从1开始，只有在定义了额外的TemplateResolver Bean时才需要设置这个属性。\nspring.thymeleaf.template-resolver-order=\n#可解析的视图名称列表，用逗号分隔\nspring.thymeleaf.view-names=\n```\n更多Thymeleaf的页面语法，可以访问[Thymeleaf的官方文档](https://www.thymeleaf.org/)来深入学习使用。\n\n# 九、源码\n本文的相关例子可以查看下面仓库中的 <font color=\"#E96900\"><strong>chapter3</strong></font>  目录：\n- Gitee：https://gitee.com/hezhiyuan007/spring-boot-study\n- Github：https://github.com/java-fish-0907/spring-boot-study', 1, 'SpringBoot专栏', 'SpringBoot', 1, 0, 0, 0, '2021-09-29 18:31:43', '2021-09-29 18:31:43');
INSERT INTO `tb_blog` VALUES (10, 'SpringBoot2.X基础教程：SpringBoot整合JdbcTemplate【附源码】', 'springboot4', 'http://localhost:8888/upload/20210929_18325475.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n# 前言\n\nJdbcTemplate 是 Spring 自带的 JDBC 模板组件，底层实现了对 JDBC 的封装，我们可以借助 JdbcTemplate 来执行所有数据库操作，例如插入、更新、删除和从数据库中检索数据，并且有效避免直接使用 jdbc 带来的繁琐编码。\n\nJdbcTemplate主要提供以下五种类型的方法：\n- execute方法：可以用于执行任何SQL语句，一般用于执行DDL语句。\n- update、batchUpdate方法：用于执行新增、修改、删除等语句。\n- query方法及queryForXXX方法：用于执行查询相关的语句。\n- call方法：用于执行数据库存储过程和函数相关的语句。\n\n当然，在大部分情况下，我们都会直接使用更加强大的持久化框架来访问数据库，比如MyBatis、Hibernate 或者 Spring Data JPA，我们这里讲解 JdbcTemplate 的整合，只是想让家更加了解底层原理。\n\n# 一、准备数据表\n```\nCREATE TABLE `spring_boot`.`article`  (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `title` varchar(255) NULL COMMENT \'文章标题\',\n  `author` varchar(255) NULL COMMENT \'作者\',\n  PRIMARY KEY (`id`)\n) COMMENT = \'文章表\';\n```\n\n# 二、引入依赖\n```\n<dependencies>\n	<!-- MySQL 依赖 -->\n	<dependency>\n		<groupId>mysql</groupId>\n		<artifactId>mysql-connector-java</artifactId>\n		<scope>runtime</scope>\n	</dependency>\n	\n	<!-- Spring JDBC 依赖 -->\n	<dependency>\n		<groupId>org.springframework.boot</groupId>\n		<artifactId>spring-boot-starter-jdbc</artifactId>\n	</dependency>\n	\n	<!-- Spring Web 依赖 -->\n	<dependency>\n		<groupId>org.springframework.boot</groupId>\n		<artifactId>spring-boot-starter-web</artifactId>\n	</dependency>\n</dependencies>\n```\n\n# 三、配置数据源\n```\nspring.datasource.url = jdbc:mysql://139.196.20.xxx:3306/spring_boot?useUnicode=true&characterEncoding=utf-8\nspring.datasource.username = root\nspring.datasource.password = 123456\nspring.datasource.driver-class-name = com.mysql.cj.jdbc.Driver\n```\n\n> 因为 Spring Boot 2.5.4 默认使用了MySQL 8.0.26 的驱动，所以这里采用com.mysql.cj.jdbc.Driver，而不是老的com.mysql.jdbc.Driver。\n\n# 四、编写领域对象\n```java\n@Data\n@NoArgsConstructor\npublic class Blog {\n  private Integer id;\n  private String title;\n  private String author;\n}\n```\n\n这里我们使用Lombok，需要在IDEA里安装Lombok插件，不然会报错，get、set方法找不到。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/63efbb7fd69e4266ac96af93d08ae19e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n\n# 五、新增\nJdbcTemplate 中，除了查询有几个 API 之外，增删改统一都使用 update 来操作，自己来传入 SQL 即可。\n\nupdate 方法的返回值就是 SQL 执行受影响的行数。\n\n```java\n@RestController\npublic class BlogController {\n\n  @Autowired\n  public BlogService blogService;\n\n  /**\n   * 新增一篇文章\n   *\n   * @param blog 文章实体类\n   * @return\n   */\n  @PostMapping(value = \"/create\")\n  public Object create(@RequestBody Blog blog) {\n    if (StringUtils.isBlank(blog.getTitle())) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章标题\");\n    }\n    if (StringUtils.isBlank(blog.getAuthor())) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章作者\");\n    }\n    return blogService.create(blog);\n  }\n}\n\n@Service\npublic class BlogServiceImpl implements BlogService {\n\n  @Autowired\n  private JdbcTemplate jdbcTemplate;\n\n  @Override\n  public Object create(Blog blog) {\n    int count = jdbcTemplate.update(\"insert into article(title, author) values(?, ?)\", blog.getTitle(), blog.getAuthor());\n    if (count > 0) {\n      return ResponseUtil.ok(\"插入成功\");\n    } else {\n      return ResponseUtil.fail(ResultEnums.SERIOUS.getCode(), \"插入失败\");\n    }\n  }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/296b69ba11ff4a178b4c277ef687f36c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n# 六、修改\n```java\n@RestController\npublic class BlogController {\n\n  @Autowired\n  public BlogService blogService;\n\n  /**\n   * 通过id修改文章\n   *\n   * @param blog\n   * @return\n   */\n  @PostMapping(value = \"/updateById\")\n  public Object updateById(@RequestBody Blog blog) {\n    if (StringUtils.isBlank(blog.getTitle())) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章标题\");\n    }\n    if (StringUtils.isBlank(blog.getAuthor())) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章作者\");\n    }\n    return blogService.updateById(blog);\n  }\n}\n\n@Service\npublic class BlogServiceImpl implements BlogService {\n\n  @Autowired\n  private JdbcTemplate jdbcTemplate;\n\n  @Override\n  public Object updateById(Blog blog) {\n    int count = jdbcTemplate.update(\"update article set title=?,author=? where id=?\", blog.getTitle(), blog.getAuthor(), blog.getId());\n    if (count > 0) {\n      return ResponseUtil.ok(\"修改成功\");\n    } else {\n      return ResponseUtil.fail(ResultEnums.SERIOUS.getCode(), \"修改失败\");\n    }\n  }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/16f62da878ad495caa793e3742edcf39.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n# 七、查询\n```java\n@RestController\npublic class BlogController {\n\n  @Autowired\n  public BlogService blogService;\n\n  /**\n   * 查询所有文章\n   *\n   * @return\n   */\n  @GetMapping(value = \"/getAll\")\n  public List<Blog> getAll() {\n    return blogService.getAll();\n  }\n\n\n  /**\n   * 通过标题查询文章\n   *\n   * @param title\n   * @return\n   */\n  @GetMapping(value = \"/getByTitle\")\n  public Object getByTitle(String title) {\n    if (StringUtils.isBlank(title)) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章标题\");\n    }\n    return blogService.getByTitle(title);\n  }\n}\n\n@Service\npublic class BlogServiceImpl implements BlogService {\n\n  @Autowired\n  private JdbcTemplate jdbcTemplate;\n\n  @Override\n  public List<Blog> getAll() {\n    return jdbcTemplate.query(\"select * from article\", new BeanPropertyRowMapper<>(Blog.class));\n  }\n\n  @Override\n  public List<Blog> getByTitle(String title) {\n  	// 如果不会Lambda表达式的小伙伴可以看下面的代码\n    return jdbcTemplate.query(\"select * from article where title = ?\", (resultSet, i) -> {\n      Blog blog = new Blog();\n      blog.setId(resultSet.getInt(\"id\"));\n      blog.setTitle(resultSet.getString(\"title\"));\n      blog.setAuthor(resultSet.getString(\"author\"));\n      return blog;\n    }, title);\n  }\n\n  @Override\n  public List<Blog> getByTitle(String title) {\n  	// 照顾到有小伙伴不会Lambda表达式，我这里把另一种方案也写出来\n    return jdbcTemplate.query(\"select * from article where title = ?\", new RowMapper<Blog>() {\n      @Override\n      public Blog mapRow(ResultSet resultSet, int i) throws SQLException {\n        Blog blog = new Blog();\n        blog.setId(resultSet.getInt(\"id\"));\n        blog.setTitle(resultSet.getString(\"title\"));\n        blog.setAuthor(resultSet.getString(\"author\"));\n        return blog;\n      }\n    }, title);\n  }\n\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/36ce8afe88c94b83976914d0441fea10.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/5e7f76a665ad484c95f9cf95c0528374.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n# 八、删除\n删除也是使用 update API，传入你的 SQL 即可\n```java\n@RestController\npublic class BlogController {\n\n  @Autowired\n  public BlogService blogService;\n  \n  /**\n   * 通过ID删除文章\n   *\n   * @param id\n   * @return\n   */\n  @PostMapping(value = \"/deleteById\")\n  public Object deleteById(Integer id) {\n    if (null == id || 0 == id.longValue()) {\n      return ResponseUtil.fail(ResultEnums.BAD_ARGUMENT_VALUE.getCode(), \"请输入文章id\");\n    }\n    return blogService.deleteById(id);\n  }\n}\n\n@Service\npublic class BlogServiceImpl implements BlogService {\n\n  @Autowired\n  private JdbcTemplate jdbcTemplate;\n  \n  @Override\n  public Object deleteById(Integer id) {\n    int count = jdbcTemplate.update(\"delete from article where id=?\", id);\n    if (count > 0) {\n      return ResponseUtil.ok(\"删除成功\");\n    } else {\n      return ResponseUtil.fail(ResultEnums.SERIOUS.getCode(), \"删除失败\");\n    }\n  }\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/b013b6da80c74e32a065ec7746af8ed3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n\n更多其他数据访问操作的使用请参考：[JdbcTemplate API](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/jdbc/core/JdbcTemplate.html)\n\n> 彩蛋，很多小伙伴会发现一个问题，项目启动一段时间放那里不动，然后在访问接口时，就会报错，这和我们使用的数据源有关（Hikari），在后面《数据源详解》章节我会教大家如何解决。\n\n# 九、源码\n本文的相关例子可以查看下面仓库中的 <font color=\"#E96900\"><strong>chapter4</strong></font>  目录：\n- Gitee：https://gitee.com/hezhiyuan007/spring-boot-study\n- Github：https://github.com/java-fish-0907/spring-boot-study', 1, 'SpringBoot专栏', 'SpringBoot', 1, 0, 0, 0, '2021-09-29 18:32:56', '2021-09-29 18:32:56');
INSERT INTO `tb_blog` VALUES (11, 'SpringBoot2.X基础教程：SpringBoot整合JdbcTemplate多数据源【附源码】', 'springboot5', 'http://localhost:8888/upload/20210929_1833578.png', '个人主页: [Java程序鱼](https://blog.csdn.net/qq_35620342 \"Java程序鱼\")\n\n如果文章对你有帮助，**欢迎关注、点赞、收藏（一键三连）和订阅专栏**\n\n微信号：hzy1014211086，想加入技术交流群的小伙伴可以加我好友，群里会分享学习资料、学习方法\n\n# 前言\n\n多数据源配置也算是一个常见的开发需求，Spring 和 SpringBoot 中，对此都有相应的解决方案，不过一般来说，如果有多数据源的需求，我还是建议首选分布式数据库中间件 MyCat、ShardingSphere 去解决相关问题。\n\n# 一、引入依赖\n```\n<dependencies>\n	<!-- MySQL 依赖 -->\n	<dependency>\n		<groupId>mysql</groupId>\n		<artifactId>mysql-connector-java</artifactId>\n		<scope>runtime</scope>\n	</dependency>\n	\n	<!-- Spring JDBC 依赖 -->\n	<dependency>\n		<groupId>org.springframework.boot</groupId>\n		<artifactId>spring-boot-starter-jdbc</artifactId>\n	</dependency>\n	\n	<!-- Spring Web 依赖 -->\n	<dependency>\n		<groupId>org.springframework.boot</groupId>\n		<artifactId>spring-boot-starter-web</artifactId>\n	</dependency>\n</dependencies>\n```\n\n\n# 二、配置&初始化数据源\n接下来，在 application.properties 中配置数据源，不同于上篇文章，这里的数据源需要配置两个，如下：\n```java\nspring.datasource.master.jdbc-url = jdbc:mysql://139.196.20.xxx:3306/spring_boot1?useUnicode=true&characterEncoding=utf-8\nspring.datasource.master.username = root\nspring.datasource.master.password = 123456\nspring.datasource.master.driver-class-name = com.mysql.cj.jdbc.Driver\n\nspring.datasource.slave.jdbc-url = jdbc:mysql://139.196.20.xxx:3306/spring_boot2?useUnicode=true&characterEncoding=utf-8\nspring.datasource.slave.username = root\nspring.datasource.slave.password = 123456\nspring.datasource.slave.driver-class-name = com.mysql.cj.jdbc.Driver\n```\n\n这里通过 master 和 slave 对数据源进行了区分，但是加了 master 和 slave 之后，<font color=\"#E96900\"><strong>这里的配置就没法被 SpringBoot 自动加载了</strong></font> （因为前面的 key 变了），需要我们自己去加载 DataSource 了，此时，需要自己配置一个 DataSourceConfig，用来提供两个 DataSource Bean，如下：\n```java\n@Configuration\npublic class DataSourceConfiguration {\n\n    @Primary\n    @Bean\n    @ConfigurationProperties(prefix = \"spring.datasource.master\")\n    public DataSource masterDataSource() {\n        return DataSourceBuilder.create().build();\n    }\n\n    @Bean\n    @ConfigurationProperties(prefix = \"spring.datasource.slave\")\n    public DataSource slaveDataSource() {\n        return DataSourceBuilder.create().build();\n    }\n\n    @Bean\n    public JdbcTemplate masterJdbcTemplate(@Qualifier(\"masterDataSource\") DataSource masterDataSource) {\n        return new JdbcTemplate(masterDataSource);\n    }\n\n    @Bean\n    public JdbcTemplate slaveJdbcTemplate(@Qualifier(\"slaveDataSource\") DataSource slaveDataSource) {\n        return new JdbcTemplate(slaveDataSource);\n    }\n\n}\n```\n这里提供了两个 Bean， @ConfigurationProperties(prefix = \"spring.datasource.master\") 表示使用 spring.datasource.master 前缀的数据库配置去创建一个 DataSource，这样配置之后，我们就有了两个不同的 DataSource，然后再用这两个不同的 DataSource 去创建两个不同的 JdbcTemplate。\n\n每一个 JdbcTemplate 的创建都需要一个 DataSource，由于 Spring 容器中现在存在两个 DataSource，默认使用类型查找，会报错，因此加上 @Qualifier 注解，表示按照名称查找。这里创建了两个 JdbcTemplate 实例，分别对应了两个 DataSource。\n\n# 三、准备测试数据\n创建spring_boot1、spring_boot2两个数据库\n\nspring_boot1\n```\nCREATE TABLE `spring_boot1`.`article`  (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `title` varchar(255) NULL COMMENT \'文章标题\',\n  `author` varchar(255) NULL COMMENT \'作者\',\n  PRIMARY KEY (`id`)\n) COMMENT = \'文章表\';\n\nINSERT INTO `spring_boot1`.`article`(`id`, `title`, `author`) VALUES (1, \'master\', \'Java程序鱼\');\n```\n\nspring_boot2\n```\nCREATE TABLE `spring_boot2`.`article`  (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `title` varchar(255) NULL COMMENT \'文章标题\',\n  `author` varchar(255) NULL COMMENT \'作者\',\n  PRIMARY KEY (`id`)\n) COMMENT = \'文章表\';\n\nINSERT INTO `spring_boot2`.`article`(`id`, `title`, `author`) VALUES (1, \'slave\', \'Java程序鱼\');\n```\n\n# 四、核心代码\n```java\n@RestController\npublic class BlogController {\n\n  @Autowired\n  public BlogService blogService;\n\n  /**\n   * 查询所有文章(master数据源)\n   *\n   * @return\n   */\n  @GetMapping(value = \"/getAllByMasterDatabase\")\n  public List<Blog> getAllByMasterDatabase() {\n    return blogService.getAllByMasterDatabase();\n  }\n\n  /**\n   * 查询所有文章(slave数据源)\n   *\n   * @return\n   */\n  @GetMapping(value = \"/getAllBySlaveDatabase\")\n  public List<Blog> getAllBySlaveDatabase() {\n    return blogService.getAllBySlaveDatabase();\n  }\n\n}\n\n@Service\npublic class BlogServiceImpl implements BlogService {\n\n  @Resource(name = \"masterJdbcTemplate\")\n  JdbcTemplate masterJdbcTemplate;\n\n  @Resource(name = \"slaveJdbcTemplate\")\n  JdbcTemplate slaveJdbcTemplate;\n\n  @Override\n  public List<Blog> getAllByMasterDatabase() {\n    return masterJdbcTemplate.query(\"select * from article\", new BeanPropertyRowMapper<>(Blog.class));\n  }\n\n  @Override\n  public List<Blog> getAllBySlaveDatabase() {\n    return slaveJdbcTemplate.query(\"select * from article\", new BeanPropertyRowMapper<>(Blog.class));\n  }\n\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/27540b148443414989b31c5642184336.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/12ed8b0184814eb9a4c7e06b82af698b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBASmF2Yeeoi-W6j-mxvA==,size_20,color_FFFFFF,t_70,g_se,x_16)\n\n# 五、源码\n本文的相关例子可以查看下面仓库中的 <font color=\"#E96900\"><strong>chapter5</strong></font>  目录：\n- Gitee：https://gitee.com/hezhiyuan007/spring-boot-study\n- Github：https://github.com/java-fish-0907/spring-boot-study', 1, 'SpringBoot专栏', 'SpringBoot', 1, 1, 0, 0, '2021-09-29 18:33:58', '2021-09-29 18:33:58');
COMMIT;

-- ----------------------------
-- Table structure for tb_blog_category
-- ----------------------------
DROP TABLE IF EXISTS `tb_blog_category`;
CREATE TABLE `tb_blog_category` (
  `category_id` int NOT NULL AUTO_INCREMENT COMMENT '分类表主键',
  `category_name` varchar(50) NOT NULL COMMENT '分类的名称',
  `category_icon` varchar(50) NOT NULL COMMENT '分类的图标',
  `category_rank` int NOT NULL DEFAULT '1' COMMENT '分类的排序值 被使用的越多数值越大',
  `is_deleted` tinyint NOT NULL DEFAULT '0' COMMENT '是否删除 0=否 1=是',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`category_id`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_blog_category
-- ----------------------------
BEGIN;
INSERT INTO `tb_blog_category` VALUES (1, 'SpringBoot专栏', '/admin/dist/img/category/spring-boot.png', 6, 0, '2021-09-29 17:49:17');
INSERT INTO `tb_blog_category` VALUES (2, '面试题专栏', '/admin/dist/img/category/interview.png', 7, 0, '2021-09-29 17:49:27');
INSERT INTO `tb_blog_category` VALUES (3, 'Redis专栏', '/admin/dist/img/category/redis.png', 1, 0, '2021-09-29 17:49:47');
INSERT INTO `tb_blog_category` VALUES (4, 'MySQL专栏', '/admin/dist/img/category/mysql.png', 1, 0, '2021-09-29 17:49:56');
COMMIT;

-- ----------------------------
-- Table structure for tb_blog_comment
-- ----------------------------
DROP TABLE IF EXISTS `tb_blog_comment`;
CREATE TABLE `tb_blog_comment` (
  `comment_id` bigint NOT NULL AUTO_INCREMENT COMMENT '主键id',
  `blog_id` bigint NOT NULL DEFAULT '0' COMMENT '关联的blog主键',
  `commentator` varchar(50) NOT NULL DEFAULT '' COMMENT '评论者名称',
  `email` varchar(100) NOT NULL DEFAULT '' COMMENT '评论人的邮箱',
  `website_url` varchar(50) NOT NULL DEFAULT '' COMMENT '网址',
  `comment_body` varchar(200) NOT NULL DEFAULT '' COMMENT '评论内容',
  `comment_create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '评论提交时间',
  `commentator_ip` varchar(20) NOT NULL DEFAULT '' COMMENT '评论时的ip地址',
  `reply_body` varchar(200) NOT NULL DEFAULT '' COMMENT '回复内容',
  `reply_create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '回复时间',
  `comment_status` tinyint NOT NULL DEFAULT '0' COMMENT '是否审核通过 0-未审核 1-审核通过',
  `is_deleted` tinyint DEFAULT '0' COMMENT '是否删除 0-未删除 1-已删除',
  PRIMARY KEY (`comment_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Table structure for tb_blog_tag
-- ----------------------------
DROP TABLE IF EXISTS `tb_blog_tag`;
CREATE TABLE `tb_blog_tag` (
  `tag_id` int NOT NULL AUTO_INCREMENT COMMENT '标签表主键id',
  `tag_name` varchar(100) NOT NULL COMMENT '标签名称',
  `is_deleted` tinyint NOT NULL DEFAULT '0' COMMENT '是否删除 0=否 1=是',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`tag_id`)
) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_blog_tag
-- ----------------------------
BEGIN;
INSERT INTO `tb_blog_tag` VALUES (1, 'Spring', 0, '2021-09-29 17:51:06');
INSERT INTO `tb_blog_tag` VALUES (2, 'SpringMVC', 0, '2021-09-29 17:51:12');
INSERT INTO `tb_blog_tag` VALUES (3, 'MyBatis', 0, '2021-09-29 17:51:17');
INSERT INTO `tb_blog_tag` VALUES (4, 'SpringBoot', 0, '2021-09-29 17:51:23');
INSERT INTO `tb_blog_tag` VALUES (5, 'Java基础', 0, '2021-09-29 17:51:36');
INSERT INTO `tb_blog_tag` VALUES (6, 'Java Web', 0, '2021-09-29 17:51:42');
INSERT INTO `tb_blog_tag` VALUES (7, 'Redis', 0, '2021-09-29 17:53:13');
INSERT INTO `tb_blog_tag` VALUES (8, 'MySQL', 0, '2021-09-29 17:53:18');
INSERT INTO `tb_blog_tag` VALUES (9, 'Nginx', 0, '2021-09-29 17:53:23');
INSERT INTO `tb_blog_tag` VALUES (10, 'RabbitMQ', 0, '2021-09-29 17:53:30');
INSERT INTO `tb_blog_tag` VALUES (11, 'ElasticSearch', 0, '2021-09-29 17:53:38');
INSERT INTO `tb_blog_tag` VALUES (12, 'JVM', 0, '2021-09-29 17:53:54');
INSERT INTO `tb_blog_tag` VALUES (13, '面试题', 0, '2021-09-29 18:14:52');
INSERT INTO `tb_blog_tag` VALUES (14, 'Java', 0, '2021-09-29 18:21:19');
COMMIT;

-- ----------------------------
-- Table structure for tb_blog_tag_relation
-- ----------------------------
DROP TABLE IF EXISTS `tb_blog_tag_relation`;
CREATE TABLE `tb_blog_tag_relation` (
  `relation_id` bigint NOT NULL AUTO_INCREMENT COMMENT '关系表id',
  `blog_id` bigint NOT NULL COMMENT '博客id',
  `tag_id` int NOT NULL COMMENT '标签id',
  `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '添加时间',
  PRIMARY KEY (`relation_id`)
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_blog_tag_relation
-- ----------------------------
BEGIN;
INSERT INTO `tb_blog_tag_relation` VALUES (1, 1, 8, '2021-09-29 18:14:52');
INSERT INTO `tb_blog_tag_relation` VALUES (2, 1, 13, '2021-09-29 18:14:52');
INSERT INTO `tb_blog_tag_relation` VALUES (3, 2, 12, '2021-09-29 18:18:17');
INSERT INTO `tb_blog_tag_relation` VALUES (4, 3, 7, '2021-09-29 18:20:14');
INSERT INTO `tb_blog_tag_relation` VALUES (5, 4, 14, '2021-09-29 18:21:19');
INSERT INTO `tb_blog_tag_relation` VALUES (6, 5, 4, '2021-09-29 18:22:55');
INSERT INTO `tb_blog_tag_relation` VALUES (7, 5, 1, '2021-09-29 18:22:55');
INSERT INTO `tb_blog_tag_relation` VALUES (8, 6, 2, '2021-09-29 18:24:00');
INSERT INTO `tb_blog_tag_relation` VALUES (9, 7, 4, '2021-09-29 18:29:38');
INSERT INTO `tb_blog_tag_relation` VALUES (10, 8, 4, '2021-09-29 18:30:39');
INSERT INTO `tb_blog_tag_relation` VALUES (11, 9, 4, '2021-09-29 18:31:43');
INSERT INTO `tb_blog_tag_relation` VALUES (12, 10, 4, '2021-09-29 18:32:56');
INSERT INTO `tb_blog_tag_relation` VALUES (13, 11, 4, '2021-09-29 18:33:58');
COMMIT;

-- ----------------------------
-- Table structure for tb_config
-- ----------------------------
DROP TABLE IF EXISTS `tb_config`;
CREATE TABLE `tb_config` (
  `config_name` varchar(100) NOT NULL DEFAULT '' COMMENT '配置项的名称',
  `config_value` varchar(200) NOT NULL DEFAULT '' COMMENT '配置项的值',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`config_name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_config
-- ----------------------------
BEGIN;
INSERT INTO `tb_config` VALUES ('footerAbout', 'Java程序鱼', '2018-11-11 20:33:23', '2021-09-29 08:47:17');
INSERT INTO `tb_config` VALUES ('footerCopyRight', 'Java程序鱼', '2018-11-11 20:33:31', '2021-09-29 08:47:17');
INSERT INTO `tb_config` VALUES ('footerICP', '湘ICP备2021012404号', '2018-11-11 20:33:27', '2021-09-29 08:47:17');
INSERT INTO `tb_config` VALUES ('footerPoweredBy', 'https://gitee.com/hezhiyuan007/blog', '2018-11-11 20:33:36', '2021-09-29 08:47:17');
INSERT INTO `tb_config` VALUES ('footerPoweredByURL', 'https://gitee.com/hezhiyuan007/blog', '2018-11-11 20:33:39', '2021-09-29 08:47:17');
INSERT INTO `tb_config` VALUES ('websiteDescription', '致力于探讨Java生态的知识点，内容覆盖MySQL、Redis、JVM、分布式服务治理、微服务、性能调优、源码剖析。', '2018-11-11 20:33:04', '2021-09-29 08:47:13');
INSERT INTO `tb_config` VALUES ('websiteIcon', '/admin/dist/img/favicon.jpeg', '2018-11-11 20:33:11', '2021-09-29 08:47:13');
INSERT INTO `tb_config` VALUES ('websiteLogo', '/admin/dist/img/fish.jpeg', '2018-11-11 20:33:08', '2021-09-29 08:47:13');
INSERT INTO `tb_config` VALUES ('websiteName', 'Java程序鱼', '2018-11-11 20:33:01', '2021-09-29 08:47:13');
INSERT INTO `tb_config` VALUES ('yourAvatar', '/admin/dist/img/fish.jpeg', '2018-11-11 20:33:14', '2021-09-29 08:47:15');
INSERT INTO `tb_config` VALUES ('yourEmail', 'hezhiyuan0907@163.com', '2018-11-11 20:33:17', '2021-09-29 08:47:15');
INSERT INTO `tb_config` VALUES ('yourName', 'java程序鱼', '2018-11-11 20:33:20', '2021-09-29 08:47:15');
COMMIT;

-- ----------------------------
-- Table structure for tb_link
-- ----------------------------
DROP TABLE IF EXISTS `tb_link`;
CREATE TABLE `tb_link` (
  `link_id` int NOT NULL AUTO_INCREMENT COMMENT '友链表主键id',
  `link_type` tinyint NOT NULL DEFAULT '0' COMMENT '友链类别 0-友链 1-推荐 2-个人网站',
  `link_name` varchar(50) NOT NULL COMMENT '网站名称',
  `link_url` varchar(100) NOT NULL COMMENT '网站链接',
  `link_description` varchar(100) NOT NULL COMMENT '网站描述',
  `link_rank` int NOT NULL DEFAULT '0' COMMENT '用于列表排序',
  `is_deleted` tinyint NOT NULL DEFAULT '0' COMMENT '是否删除 0-未删除 1-已删除',
  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '添加时间',
  PRIMARY KEY (`link_id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_link
-- ----------------------------
BEGIN;
INSERT INTO `tb_link` VALUES (1, 0, 'Java程序鱼', 'https://www.devspace.cn', '致力于探讨Java生态的知识点', 0, 0, '2021-09-29 16:50:22');
COMMIT;

-- ----------------------------
-- Table structure for tb_test
-- ----------------------------
DROP TABLE IF EXISTS `tb_test`;
CREATE TABLE `tb_test` (
  `id` bigint NOT NULL AUTO_INCREMENT COMMENT '主键',
  `test_info` varchar(50) NOT NULL COMMENT '测试内容',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of tb_test
-- ----------------------------
BEGIN;
INSERT INTO `tb_test` VALUES (1, 'SpringBoot-MyBatis测试');
COMMIT;

SET FOREIGN_KEY_CHECKS = 1;
